<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:dc="http://purl.org/dc/elements/1.1/">
  <channel>
    <title>norswap</title>
    <description></description>
    <link>https://norswap.com</link>
    <atom:link href="https://norswap.com/atom.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>2022 Update</title>
      <description>
      <![CDATA[
        <p>This blog has been rather less active than it should have been.</p>
        <p>I, however, have been busy, working at <a href="https://optimism.io">Optimism</a> on
        <a href="https://dev.optimism.io/introducing-optimism-bedrock/">Bedrock</a> and <a href="https://medium.com/ethereum-optimism/cannon-cannon-cannon-introducing-cannon-4ce0d9245a03">Cannon</a>.</p>
        <p>A lot of the action has instead been on <a href="https://twitter.com/norswap/">my Twitter</a>. See in particular <a href="https://twitter.com/norswap/status/1501920423662997504">this
        thread</a> collecting the biggest hits.</p>
        <p>For discoverability and archival purpose, I&#39;ve ported some of these tweet
        threads on the block, backdated to the original date. Here they are:</p>
        <ul>
        <li><a href="/zk-vs-optimistic">ZK Rollups vs Optimistic Rollups</a></li>
        <li><a href="/cannon-intro">How Cannon Works</a></li>
        <li><a href="/djed-stable">Design of the $DJED Stablecoin</a></li>
        <li><a href="/velodrome-liquidity">Velodrome and why it&#39;s a superior system for incentivizing liquidity</a></li>
        <li><a href="/amm-meditations">AMM Meditations üçÉ</a></li>
        </ul>
      ]]>
      </description>
      <pubDate>2022-10-24T16:00:00.000Z</pubDate>
      <link>https://norswap.com/2022-update</link>
      <guid isPermaLink="true">https://norswap.com/2022-update</guid>
    </item>
    <item>
      <title>Optimism Bedrock vs Arbitrum Nitro</title>
      <description>
      <![CDATA[
        <p>This is a really nerdy breakdown of the differences between <a href="https://github.com/ethereum-optimism/optimism/blob/develop/specs/overview.md">Optimism Bedrock üóø</a> and <a href="https://github.com/OffchainLabs/nitro">Arbitrum Nitro üöÄ</a>.</p>
        <p>This is all sourced from my reading of the <a href="https://github.com/OffchainLabs/nitro/blob/master/docs/Nitro-whitepaper.pdf">Nitro whitepaper</a>, and my intimate sensual knowledge of the Bedrock design.</p>
        <p>This actually started a Twitter thread, but grew way way too big for that.</p>
        <p>This gets very technical. If you want to follow &amp; get confused, I recommend referring to the <a href="https://github.com/ethereum-optimism/optimism/blob/develop/specs/overview.md">Bedrock overview</a> and <a href="https://twitter.com/norswap/status/1552454352316547076">my presentation on our Cannon fault proof system</a>, and of course the <a href="https://github.com/OffchainLabs/nitro/blob/master/docs/Nitro-whitepaper.pdf">Nitro whitepaper</a>.</p>
        <p><strong>With this out of the way, let&#39;s dive in!</strong></p>
        <p>First of all, the whitepaper is great and was a pleasure to read. I recommend checking it out for all interested.</p>
        <p>Going into this, my impression was that Bedrock and Nitro share roughly the same architecture, with some smaller differences.</p>
        <p>The paper by and large confirms this. Still, there are quite a few differences, including a few I didn&#39;t expect. These are what this thread is about!</p>
        <h1 id="a-fixed-vs-variable-block-time">(A) Fixed vs variable block time</h1>
        <p>One of the most interesting and consequential things is that Nitro will work like the current version of Optimism, which has one block per transaction, and variable time between blocks.</p>
        <p>We moved away from this because it was a departure from how Ethereum works, and a pain point for devs. Bedrock will have &quot;real&quot; blocks with a fixed block time of 2 seconds.</p>
        <p>Irregular block times make quite a few common contracts wonky, because they keep time using blocks instead of the timestamp. This notably includes the Masterchef contract for distributing LP rewards that originated with Sushiswap.</p>
        <p>I&#39;m not sure why these contracts keep the time with blocks instead of timestamps! Ethereum miners have some leeway in manipulating timestamps, but clients will by default not build upon blocks that are too far away from the wallclock time (15s in Geth), so no problem.</p>
        <p>Anyway, on Optimism this caused the <a href="https://stargate.finance/">StargateFinance</a> incentives to run out months ahead of other chains, because they didn&#39;t account for this peculiarity!</p>
        <p>The &quot;one block per transaction&quot; model has other issues. First, it&#39;s a lot of overhead for storing the chain (one block header per tx). Second, it means the state root needs to be updated after each individual transaction.</p>
        <p>Updating the state root is a pretty expensive operation, whose cost is amortized when done over multiple transactions.</p>
        <h1 id="b-geth-as-a-library-or-as-the-execution-engine">(B) Geth as a library or as the execution engine</h1>
        <p>Nitro uses Geth &quot;as a library&quot; which is minimally modified with hooks to call the proper functionality.</p>
        <p>In Bedrock, a minimally modified Geth runs standalone as the &quot;execution engine&quot; which receives instructions from the rollup node in the same way the execution layer receives instructions from the consensus layer in Eth2. We even use the exact same API!</p>
        <p>This has some important consequences. First we‚Äôre able to use other clients than Geth, applying a similar minimal diff on top of them. This is not just theory, we already have <a href="https://github.com/protolambda/erigon/tree/optimism">Erigon</a> pretty much ready.</p>
        <p>Second, this lets us reuse the whole Geth (or other client) stack, include at the networking layer, which enables things like peer discovery and state sync, without almost any additional dev work.</p>
        <h1 id="c-state-storage">(C) State storage</h1>
        <p>Nitro keeps some state (&quot;the state of ArbOS&quot;) inside a special account (itself stored within the Arbitrum&#39;s chain state), using a special memory layout to map keys to storage slots.</p>
        <p>(This is purely architecture, with no user impact.)</p>
        <p>Bedrock doesn&#39;t really have much state in that sense, and what little it has is stored in ordinary EVM contracts (to be fair, you could implement the ArbOS state layout using the EVM, though that&#39;s not what I think they are doing).</p>
        <p>When determining/executing the next L2 block, a Bedrock replica looks at:</p>
        <ul>
        <li>the header of the head of the L2 chain</li>
        <li>data read from L1</li>
        <li>some data in EVM contract on the L2 chain, currently only the L1 fee parameters</li>
        </ul>
        <p>In Bedrock, nodes can crash and immediately gracefully restart. They don&#39;t need to maintain an extra databases, because all the necessary information can be found in L1 and L2 blocks. I assume Nitro works the same (the architecture makes this possible).</p>
        <p>It&#39;s however apparent that Nitro does a little more bookkeeping work than Bedrock.</p>
        <h1 id="d-l1-to-l2-message-inclusion-delay">(D) L1 to L2 message inclusion delay</h1>
        <p>Nitro processes L1 to L2 messages (what we call &quot;deposited transactions&quot; or just &quot;deposits&quot;) with a 10 minutes delay. On Bedrock, they should usually be with a small confirmation depth of a few blocks (maybe 10 L1 blocks, so about 2 minutes).</p>
        <p>We do also have a parameter called &quot;sequencer drift&quot; that allows the timestamp of an L2 block to drift ahead of its L1 origin (L1 block that marks the end of the L1 block range from which batches and deposits are derived).</p>
        <p>We still have to decide the final value but we&#39;re leaning towards 10 minutes also, meaning the worst case is 10 minutes. However, this parameter is meant to ensure liveness of the L2 chain during temporary loss of connection to L1.</p>
        <p>Usually however, deposits will be included immediately after the confirmation depth.</p>
        <p>The Nitro paper mentions that this 10 minutes delay is to avoid the deposits from disappearing on L1 due to a re-org. This made me curious about an aspect that the paper does <em>not</em> talk about, and which is: how does the L2 chain handles L1 re-org. I think the answer is it doesn&#39;t.</p>
        <p>This isn&#39;t unreasonable: post-merge there is an L1 finality delay of about 12 minutes. So if it&#39;s okay for deposits to lag 10/12 minutes behind, then this design works.</p>
        <p>Because Bedrock tracks closer to L1, we need to handle L1 re-orgs by re-orging L2 if needed. The confirmation depth should avoid this happening too often.</p>
        <p>Another minor difference there is that if the Nitro sequencer does not include a deposit after 10 minutes, you can &quot;force include&quot; it via an L1 contract call.</p>
        <p>On Bedrock, this is not necessary: it&#39;s invalid to have an L2 block without including the deposits of its L1 origin.</p>
        <p>And because L2 can only be 10 minutes (sequencer drift) ahead of the origin, a chain that does not include deposits after 10 minutes is invalid, will be rejected by validators and challengeable by the fault proof mechanism.</p>
        <h1 id="e-l1-to-l2-messages-retry-mechanism">(E) L1-to-L2 messages retry mechanism</h1>
        <p>Nitro implements &quot;retryable tickets&quot; for L1-to-L2 messages. Say you&#39;re bridging, the L1 part of the tx could work (locking your tokens) but the L2 part could fail. So you need to be able to retry the L2 part (maybe with some more gas) or you&#39;ve lost your tokens.</p>
        <p>Nitro implements this in the ArbOS part of the node. In Bedrock, this is all done in Solidity itself.</p>
        <p>If you use our L1 cross-domain messenger contracts to send a transaction to L2, the transaction lands in our L2 cross-domain messenger which will record its hash, making it retryable. Nitro works the same way, it&#39;s just implemented in the node.</p>
        <p>We also expose a lower-level way to do deposits, via our L1 Optimism Portal contract.</p>
        <p>This doesn&#39;t give you the safety net of the L2 cross-domain messenger retry mechanism, but on the flip side, it means you can implement your own app-specific retry mechanism in Solidity. Pretty cool!</p>
        <h1 id="f-l2-fee-algorithm">(F) L2 fee algorithm</h1>
        <p>On both systems, fees have an L2 part (the execution gas, similar to Ethereum) and an L1 part (cost of L1 calldata). For its L2 fee, Nitro uses a bespoke system, while Bedrock re-uses EIP-1559. Nitro has to do this because they have the aforementioned 1 tx/block system.</p>
        <p>We still have to tune the EIP-1559 parameters to make it work well with the 2 second block time. Today, Optimism charges a low &amp; flat L2 fee (the L1 fee is 99% of the price anyway). I think we might have surge pricing too, but it never kicks in in practice.</p>
        <p>An advantage of reusing EIP-1559 is that it should make it marginally easier for wallets and other tools to compute fees.</p>
        <p>The Nitro gas-metering formula is pretty elegant though, and they seem to have put a lot of thought in it.</p>
        <h1 id="g-l1-fee-algorithm">(G) L1 fee algorithm</h1>
        <p>What about L1 fees? This is a bigger difference. Bedrock uses backward-looking L1 basefee data. This data is pretty fresh, because it is delivered via the same mechanism as deposits (i.e. it&#39;s almost instant).</p>
        <p>Because there&#39;s still a risk that the L1 fee will spike, we charge a small multiplier of the expected cost.</p>
        <p>Fun fact: this multiplier (which we have lowered multiple times since launching the chain) is where all the current sequencer revenue come from! With EIP-4844, this will shrink, and revenues will come from (UX-preserving) MEV extraction instead.</p>
        <p>Nitro does something rather much more complicated. I don&#39;t claim to understand all the intricacies of it, but the basic gist is that they have a control system that gets feedback from how much fees were actually paid on L1.</p>
        <p>This means sending transaction back from L1 to L2 with this data. If the sequencer underpaid, it can start charging users less going forward. If it overpaid, it can start charging users more.</p>
        <p>As an aside, you may wonder why we need to transmit fee data from L1 to L2. It&#39;s because we want the fee scheme to be part of the protocol, and open to challenge by fault proofs. Otherwise, rogue sequencers could DoS the chain by setting arbitrarily high fees!</p>
        <p>Finally, transaction batches are compressed in both systems. Nitro charges the L1 fee based on an estimation of how well the transaction will compress. Bedrock currently doesn&#39;t do this, though we plan to.</p>
        <p>Not doing this worsens the perverse incentive to cache data in L2 storage, leading to problematic state growth.</p>
        <h1 id="h-fault-proof-instruction-set">(H) Fault proof instruction set</h1>
        <p>Fault/fraud proofs! Quite a few differences between what Nitro does and how Cannon (the fault proof system we&#39;re currently implementing to sit on top of Bedrock) will work.</p>
        <p>Bedrock compiles to the MIPS instruction set architecture (ISA), Nitro compiles to WASM. They seem to do quite a few more transformation on the output than we do, owing to compiling to a subset of WASM which they call WAVM.</p>
        <p>For instance, they replace floating point (FP) operations by library calls. I suspect that they didn&#39;t want to implement the gnarly FP operations in their on-chain interpreter. We do this too, but the Go compiler takes care of it for us!</p>
        <p>Another example: unlike most ISA that only has jumps, WASM has proper (potentially nested) control flow (if-else, while, etc). The conversion from WASM to WAVM removes this to go back to jumps, again probably for the sake of interpreter simplicity.</p>
        <p>They also compile a mix of Go, C &amp; Rust to WAVM (in different &quot;modules&quot;), while we do Go only. Apparently WAVM allows &quot;the languages&#39; memory management not to interfere&quot;, which I interpret as each WAVM module getting its own heap.</p>
        <p>Something I&#39;m curious about: how they deal with concurrency and garbage collection. We&#39;re able to avoid concurrency fairly easily in minigeth (our stripped down geth) so maybe that part is easy (more on how Bedrock and Nitro use geth at the end of this article).</p>
        <p>However, one of the only transformation we do on MIPS is to patch out garbage collection calls. This is because garbage collection uses concurrency in Go, and concurrency and fault proofs don&#39;t go well together. Does Nitro do the same thing?</p>
        <h1 id="i-bisection-game-structure">(I) Bisection game structure</h1>
        <p>The Bedrock fault proof will work on a run of minigeth that verifies the validity of a state root (actually an <a href="https://github.com/ethereum-optimism/optimism/blob/ab7ed0d43d77d2fd6723d0f4b9b056daca94071f/specs/proposals.md#l2-output-root-proposals-specification">output root</a>) posted to L1. Such state roots are not posted frequently, and a such encompass the validation of many blocks/batches.</p>
        <p>The bisection game in Cannon is played on the execution trace of this (long) run.</p>
        <p>In Nitro, on the other hand, state roots are posted with each set of batches (<em>RBlock</em>) posted to L1.</p>
        <p>The bisection game in Nitro is split in two parts. First find the first state root that challenger and defender disagreee on. Then, find the first WAVM instruction they disagree on in the validator run (which only validates a single transaction).</p>
        <p>The trade-off is more hashing during Nitro execution (see (A) above), but less hashing during the fault proof: each step in the bisection game over an execution trace requires submitting a Merkle root of the memory.</p>
        <p>Structure the fault proof like this also reduces the concern that memory will balloon in the validator, potentialy exceeding the 4G memory limit we currently have for running MIPS.</p>
        <p>This isn&#39;t a hard problem to fix, but we need to be careful in Bedrock, whereas there is probably no chance that validating a single transaction can ever approach the limit.</p>
        <h1 id="j-preimage-oracle">(J) Preimage oracle</h1>
        <p>The validator software used for fault proofs need to read data from L1 and L2. Because it will ultimately &quot;run&quot; on L1 (though only a single instruction), the L2 itself needs to be accessed via L1 - via the state roots &amp; block hashes posted to L1.</p>
        <p>How do you read from the state or chain (whether L1 or L2)?</p>
        <p>A Merkle root node is a hash of its children, so if you can request a preimage, you can traverse the whole state tree. Similarly, you can traverse the whole chain backwards by requesting the preimage of a block header. (Each block header contains the hash of its parent.)</p>
        <p>When executing on-chain, these preimages can be presupplied to the WAVM/MIPS interpreter in advance. (When executing off-chain, you can read the L2 state directly!)</p>
        <p>(Note that you only ever need to access one such preimage, because on-chain you only execute one instruction!)</p>
        <p>So that&#39;s how you read from L2, both on Nitro and Bedrock.</p>
        <p>You need to do something similar for L1 however. Because transaction batches are stored in L1 calldata, which is not accessible from L1 smart contracts.</p>
        <p>Nitro stores the hashes of its batches in an L1 contract (which is why their &quot;Sequencer Inbox&quot; is a contract and not an EOA like for Bedrock). So they at least need to do that, I&#39;m not sure why it wasn&#39;t mentionned.</p>
        <p>In Bedrock, we don&#39;t even store the batches hash (leading to some gas savings). Instead, we walk back the L1 chain using the L1 block headers, then walk down the transaction Merkle root to find the batches in the calldata.</p>
        <p>(Again, on-chain, at most a single preimage needs to be supplied.)</p>
        <p>Section 4.1 ends with a paragraph that reminds us that <a href="https://twitter.com/EdFelten/status/1488632545457618952">Arbitrum invented the &quot;hash oracle trick&quot;</a>. Credit where credit is due. Insecurity shouldn&#39;t be a reason to forget about the Arbitrum team&#39;s contributions!</p>
        <h1 id="k-large-preimages">(K) Large preimages</h1>
        <p>The paper also tells us that the fixed upper bound for an L2 preimage is 110kb, but does not quote the figure for L1.</p>
        <p>In Cannon, we have something called &quot;the large preimage problem&quot;, because one of the potential preimage to invert is the receipts preimage, which contains all the data emitted by Solidity events (&quot;logs&quot; at the EVM level).</p>
        <p>In the receipts, all the log data is concatenated together. This means an attacker could emit a ton of logs, and create an incredibly large preimage.</p>
        <p>We need to read logs because we use them to store deposits (L2-to-L1 messages). This is not strictly necessary: Nitro avoids the issue by storing a hash of the message (it&#39;s more complicated than this, but the end result is the same).</p>
        <p>We don&#39;t store a hash because of the significant cost to compute and store it. Around 20k gas to store and 6 gas per 32 bytes to compute. An average transaction is about 500 bytes, making a batch of 200 transactions cost about 20k gas to hash as well. At 2k$ ETH and 40 gwei basefee, the extra hashing and storage costs 3.2$. At 5k$ ETH and 100 gwei that&#39;s 20$.</p>
        <p>Our current plan to solve the large preimage problem is to use a simple zk-proof to prove the value of some bytes within the preimage (since that&#39;s all an instruction needs to access in practice).</p>
        <h1 id="l-batches--state-roots">(L) Batches &amp; state roots</h1>
        <p>Nitro ties batches with state roots very strongly. They post a set of batches in an <em>RBlock</em> which also contains a state root.</p>
        <p>Bedrock on the other hands posts its batches separately from the state roots. The key advantage is again reduced cost to posting batches (no need to interact with a contract or store data). This lets us post batches more often, and state roots less often.</p>
        <p>Another consequence is that with Nitro, should an RBlock be challenged, the transactions it contains will not be replayed on the new chain (new correct state roots).</p>
        <p>In Bedrock, we&#39;re currently debating what to do in the case where a state root gets successfully challenged: replay old transactions on top of the new state roots, or full rollback? (The current implementation implies a full rollback, but it‚Äôs likely to be changed before fault proofs are rolled out.)</p>
        <h1 id="m-misc">(M) Misc</h1>
        <p>Smaller, less consequential differences:</p>
        <p><strong>(i)</strong> Nitro allows individual transactions posted by the sequencer to be &quot;garbage&quot; (invalid signatures, etc). To minimize the changes to Geth, we always throw out batches that contain any garbage.</p>
        <p>The sequencer is always able to find those in advance, so lingering garbage entails either misbheaviour or bug. The sequencer runs the same code as the fault proof, so their definitions of what&#39;s invalid should be identical.</p>
        <p><strong>(ii)</strong> Nitro introduces precompile contracts, notably for L2-to-L1 message passing. We currently don&#39;t use any precompiles, preferring them &quot;pre-deploys&quot;, i.e. actual EVM contracts that exist at special addresses from the genesis block.</p>
        <p>Turns out we can do what we need just fine in the EVM, and this makes the node logic slightly simpler. We&#39;re not religiously opposed to precompiles though, maybe we&#39;ll need one at some point.</p>
        <p><strong>(iii)</strong> The Nitro fault proof does a d-way dissection. The proof-of-concept Cannon implementation uses a bisection, but we&#39;ll probably move to a d-way dissection too.</p>
        <p>There is a very nice formula in the paper that explains the optimal value of <em>d</em> based on fixed and variable costs. I wish they had included concrete examples of how they estimate these costs in practice however!</p>
        <h1 id="coda">Coda</h1>
        <p>No grand conclusion! Or rather: draw your own :)</p>
        <p>If you enjoyed this, follow me <a href="https://twitter.com/norswap">on Twitter</a> for
        more of the same and be notified of new articles.</p>
      ]]>
      </description>
      <pubDate>2022-10-01T16:00:00.000Z</pubDate>
      <link>https://norswap.com/bedrock-vs-nitro</link>
      <guid isPermaLink="true">https://norswap.com/bedrock-vs-nitro</guid>
    </item>
    <item>
      <title>AMM Meditations üçÉ</title>
      <description>
      <![CDATA[
        <p>This was originally a <a href="https://twitter.com/norswap/status/1548122970903654411">tweet thread</a> that I have reproduced here for
        discoverability and archive purposes (the copy was done on 25 October 2022).</p>
        <p>I&#39;ve only slightly reformatted the text (mostly links), otherwise this is the
        original version.</p>
        <hr>
        <p>1/ I wonder how many people realize a volatile-vs-stable AMM position is an
        anti-leveraged position whose value varies with the square root of the change in
        price of the volatile asset. (In exchange for this reduced exposure, you get
        yield.)</p>
        <p>2/ If the price of ETH is multiplied by X (e.g. X=4 or X=1/4), the value of an
        ETH-USD position will be multiplied by sqrt(X) (e.g. 2 or 1/2).</p>
        <p>3/ Why? Because of the x*y=k equation. Assuming x is the volatile and y is the
        stable: If x is multipled by X (selling a bunch of the volatile), y must be
        divided by X such that x*X*y/X=k.</p>
        <p>4/ The price of the volatile is given by y/x. After selling the volatile:
        (y/X)/(x*X) = (y/x)/X^2.</p>
        <p>The value of the LP position is initially 2*y. After selling the volatile:
        2*y/X.</p>
        <p>So the price is divided X^2, but the LP position value only by X.</p>
        <p>5/ However, the impermanent loss is only (1 + X)/2 - sqrt(X), because only half
        of the initial LP position&#39;s value was in the volatile asset.</p>
        <p>(This number is a multiplier of initial LP position value.)</p>
        <p>6/ How bad does impermanent loss get?</p>
        <p>On the up side, ~2.5% for a 50% price increase, ~8.5% for a 2x, 50% for a 4x.</p>
        <p>On the down side, ~4.2% for a 50% price decrease (halving), 12.5% for a 75%
        decrease (price divided by 4).</p>
        <p>7/ Notice the asymmetry: you lose less on the down side, but that&#39;s because you
        can never lose more than 50% of the initial LP value (if you held and the
        volatile went to 0, you&#39;d be left with 50c on the dollar).</p>
        <p>8/ You can ask google <a href="https://www.google.com/search?q=(1%2BX)/2%20-%20sqrt(X)">to plot this function</a> btw (make sure to zoom out
        the plot).</p>
        <p>9/ Note that these numbers are slightly different (larger) than what you&#39;d get
        with a calculator like <a href="https://baller.netlify.app">https://baller.netlify.app</a>,
        because they&#39;re multiplier (%) of the initial LP position value, whereas the
        calculator gives you a % of the asset value if held.</p>
        <p>10/ Anyway, what do these numbers mean? It means that if you expect that the
        price could move 4x up or down, you should be getting 50% APY. In a world where
        $ETH can do that, so can most tokens.</p>
        <p>11/ But who&#39;s getting that? Maybe if you&#39;re lucky and you&#39;re super early to a
        good project. Otherwise LPing on a inflationary shitcoin that is slowly or
        not-so-slowly going to 0 ‚Äî but then you have another problem.</p>
        <p>12/ LPing a a volatile-stable pair is a a sucker&#39;s game, and I do not get why
        people do it.</p>
        <p>UniV3 was going to fix this, but <a href="https://twitter.com/0xdoug/status/1512296324036759557">it&#39;s not clear anybody is consistently beating
        impermanent loss in ETH-USDC</a> (500M+ TVL).</p>
        <p>13/ On the other hand, stock market (order book) market makers consistently make
        money. On-chain liquidity that does not rely on off-chain agents IS NOT A SOLVED
        ISSUE.</p>
      ]]>
      </description>
      <pubDate>2022-07-15T16:00:00.000Z</pubDate>
      <link>https://norswap.com/amm-meditations</link>
      <guid isPermaLink="true">https://norswap.com/amm-meditations</guid>
    </item>
    <item>
      <title>Velodrome and why it&#39;s a superior system for incentivizing liquidity</title>
      <description>
      <![CDATA[
        <p>This was originally a <a href="https://twitter.com/norswap/status/1533991540896321536">tweet thread</a> that I have reproduced here for
        discoverability and archive purposes (the copy was done on 24 October 2022).</p>
        <p>I&#39;ve only slightly reformatted the text (mostly links), otherwise this is the
        original version.</p>
        <hr>
        <p>1/54üßµ Thread on <a href="https://twitter.com/VelodromeFi">@VelodromeFi</a> and why it&#39;s a superior system for incentivizing
        liquidity.</p>
        <p>2/ Liquidity is super important for project tokens. A lack of liquidity makes
        the token price too volatile. It also prevents investors for exiting, which
        makes them wary to invest in the first place.</p>
        <p>3/ (And more cynically, such a liquidity pool also doubles as another use case
        for the token, to prevent excessive selling.)</p>
        <p>4/ The problem is that, for unpegged pairs, being a liquidity provider (LP)
        sucks, because of impermanent loss (IL). Price goes up? You would have been
        better holding and not LPing. Price goes down? Same thing.</p>
        <p>5/ As an LP, you are the counterparty of adversely selected trades. You end up
        owning more tokens when price decreases, and less tokens when price increases.</p>
        <p>6/ The IL numbers are not egregious, but can easily outpace fee APY. You can
        play with this app to get a sense:
        <a href="https://baller.netlify.app/">https://baller.netlify.app/</a></p>
        <p>7/ For this reason, projects need to incentivize liquidity. Usually, this is
        done by bestowing tokens on LPs, to increase APY and make IL risk worthwhile.</p>
        <p>8/ In this context, Velodrome and its predecessors/competitiors (<a href="https://twitter.com/CurveFinance">@CurveFinance</a> +
        <a href="https://twitter.com/ConvexFinance">@ConvexFinance</a>, <a href="https://twitter.com/solidlyexchange">@solidlyexchange</a>) offer two things:</p>
        <ol>
        <li>A marketplace for liquidity: no need to roll you own pools &amp; incentive logic,
        easy to advertise to prospective LPs</li>
        </ol>
        <p>9/</p>
        <ol start="2">
        <li>The opportunity to purchase 1$ worth of incentive for less than 1$ worth of
        project token.</li>
        </ol>
        <p>10/ How does that work? Every voting period (one week for Velodrome), token
        rewards ($VELO) are emitted and distributed amongst the LPs of the liquidity
        pools on velodrome.</p>
        <p>11/ The amount of rewards per pool is decided by a vote. A pool receives an
        amount of reward proportional to its share of the total vote. To vote, users
        have to lock their $VELO (for up to 4 years, longer locks beget more voting
        power).</p>
        <p>12/ Multiple strategies are possible. Projects can just acquire $VELO directly
        and lock it: this lets them direct a stream of future emissions to their pools.
        The point being for the price paid for $VELO will be less than the value of all
        future emissions.</p>
        <p>13/ This can also be good if projects are more confident about the future price
        of $VELO than of their own token&#39;s. Instead of printing more and more token for
        liquidity rewards (creating a death spiral), they can simply rely on the
        emissions.</p>
        <p>14/ Alternatively, they can &quot;bribe&quot; existing lockers for their votes, by
        assigning them rewards in their project tokens. This can be appealing to
        projects, even early on, because they don&#39;t need to sell a big chunk of project
        token at once to finance the purchase of $VELO.</p>
        <p>15/ Here too, there is a possibility to get 1$ of $VELO LP reward for less than
        1$ of project token bribe.</p>
        <p>To make a profit (and ignoring at the moment fees and rebases), lockers want to
        earn more per locked $VELO than the dilution created by the $VELO emissions.</p>
        <p>16/ Each emitted $VELO dilutes holders by (1 / (oldTotalSupply + 1)). So the
        minimum non-dilutive bribe per $VELO bribed is (veloPrice * veloEmitted * (1 /
        (oldTotalSupply + 1)).</p>
        <p>17/ If every $VELO was locked and its vote was bribe-sensitive, you&#39;d have to
        bribe one $VELO worth per $VELO emitted.</p>
        <p>The key to capital efficiency for projects here is that not all $VELO is locked
        (only ~50% atm, I expect this to increase).</p>
        <p>18/ Furthermore, not every locker is bribe-sensitive: project that bought $VELO
        to incentivize their pool will not vote on other pools.</p>
        <p>Also $VELO locked for less than 4 years does not get maximum voting power.</p>
        <p>19/ Therefore, in the worst/best case (depending on whose perpective you adopt),
        projects get a discount by diluting non locked $VELO, bribe-insensitive $VELO,
        and (to a smaller extent) short-duration $VELO lockers.</p>
        <p>20/ We should also mention that $VELO lockers also benefit from a &quot;rebase&quot;:
        token accrued every voting period that are supposed to protect them from
        dilution. The rebase amount for each voting period is given by this formula:</p>
        <p>21/ (veVELO.totalSupply √∑ VELO.totalsupply)¬≥ √ó 0.5 √ó Emissions</p>
        <p>So if half of all $VELO is locked, lockers will collectively received 1/16
        (6.25%) of all emissions as extra $VELO. This would be 36% at 90% locked and 50%
        at 100% locked.</p>
        <p>22/ Why do I say &quot;supposed&quot; above? Well <a href="https://twitter.com/norswap/status/1498358050620514304">just like in OlympusDAO</a>, rebases just
        make you run in place faster.</p>
        <p>However, they do have the net effect of diluting non-locked $VELO faster
        compared to locked $VELO.</p>
        <p>23/ Note that bribe-insensitive $VELO lockers (usually projects) are not
        necessarily worse for wear: as stated above, the purchasing assumption was that
        the total value of future emissions would exceed the initial purchase price.</p>
        <p>24/ $VELO non-lockers could also be alright, assuming they are $VELO LPs (the
        only other use case for $VELO at the moment) and that sufficient emissions are
        directed toward their pool.</p>
        <p>25/ The (veloPrice * veloEmitted * (1 / (oldTotalSupply + 1)) formula (which
        actually needs to be adjusted for the rebase!) from above merely represents a
        level of interest for bribes.</p>
        <p>26/ This level is not particularly an attractor however. Prices could be lower
        if there too much emissions compared to projects appetite for liquidity rewards.</p>
        <p>If that&#39;s not the case, the bribes total should be higher as projects compete
        for these emissions.</p>
        <p>27/ In fact, if the demand for incentives outpaces the $VELO emissions, this
        should in theory drive the bribe per $VELO emitted close to the price of $VELO.
        Or even slightly above ‚Äî as there is value in the convience of a turnkey
        liquidity mining solution.</p>
        <p>28/ Note here that $VELO being locked has an impact. If it wasn&#39;t, then bribes
        being below the level of interest above for too long (because demand for
        liquidity reward is too low) would cause people to sell $VELO.</p>
        <p>29/ A falling $VELO price cause the total values of emissions to fall, which
        would bring it back towards demand.</p>
        <p>That system would be self-regulating, which the current one isn&#39;t because of the
        lock. I&#39;m not sure which one is actually better for the long-term price of the
        token!</p>
        <p>30/ So we&#39;ve just described a system where projects save money, lockers make
        money and LPs (include $VELO LPs) make money.</p>
        <p>Have we broken financial common sense? Is this a good old ponzu? Who foots the
        bill?</p>
        <p>31/ For one, users via fees, which accrue to the lockers. But that&#39;s far from
        the whole story in the short/medium-term.</p>
        <p>Instead I think most of these profits come from the value of the $VELO token
        itself.</p>
        <p>32/ Just like $BTC (or in fact $USD) are not &quot;backed&quot; by anything, so is $VELO.
        i.e. there is no redemption guarantee beyond what you can get on the market
        (within the limitation of available liquidity, underscoring again why this is so
        important).</p>
        <p>33/ Instead, a good tokenomics analysis must look at reflective loops,
        especially under extreme conditions.</p>
        <p>34/ So what could go wrong? The price could tank. (e.g. as a bear market rolls
        around)</p>
        <p>35/ One bad thing about $VELO (and $CRV) is that its cashflows are mostly
        effectively denominated in $VELO. i.e. the willingness of projects to bribe is
        proportional to the market value of of emissions. So when the $VELO price tanks,
        so should bribes.</p>
        <p>36/ The iron rule (in a rational world...) is that the total value of bribes
        should never exceed the value of $VELO emitted through the vote of bribed
        lockers (+ a small premium representing the usefulness of the service, and
        eventually some inertia).</p>
        <p>37/ Now if the total bribe value is lower than the emitted $VELO (through bribed
        lockers), then the total bribe value does not need to decrease.</p>
        <p>However I would rate this unlikely in the long term, if we consider a situation
        where the price just decreased significantly.</p>
        <p>38/ (Somewhat similarly, projects saving money on accumulated $VELO depends on
        the value of all future emissions.)</p>
        <p>39/ This is somewhat mitigated by the fact that fees are independent of $VELO
        price. This could help moderate downdrafts, or at least help establish a price
        zone where $VELO is &quot;cheap&quot;.</p>
        <p>40/ This is a place where Velodrome (&amp; Solidly) markedly improve on Curve, as
        the fees accruing to the lockers brings price-independent value to the token.</p>
        <p>41/ As an interesting data point, over the past 14 days, <a href="https://dune.com/rplust/Vote-Locked-Convex-Token-(vlCVX)-Bribes">Votium bribes for
        Convex lockers</a> were ~7.6M while <a href="https://dune.com/mrblock_buidl/Curve.fi">total curve fees</a>
        were ~1.1M.</p>
        <p>42/ Another moderating force on the downside is that projects may be driven to
        accumulate when the price decreases.</p>
        <p>Why would they do this?</p>
        <p>43/ For one, the original thesis remains unchanged: since emissions are
        denominated in $VELO, the savings remains similar given a flat price.</p>
        <p>(And even better if they anticipate the price slump to be temporary.)</p>
        <p>44/ The second reason is that the drop in price likely saturated the bribe
        capacity it wasn&#39;t already (see &quot;iron rule&quot; above). Emissions can no longer be
        purchased without overspending. Accumulating $VELO is the only avenue left to
        secure discounted liquidity rewards.</p>
        <p>45/ (In this case, by amortizing the initial purchase over time via the value of
        future emissions.)</p>
        <p>46/ So as you can see, there are some moderating factors on the downside, and no
        downwards spiral type effects.</p>
        <p>47/ However I don&#39;t love that returns are mostly $VELO denominated. This means
        that outside of periods of very low price (where fees effectively set a floor)
        and periods of accumulation, the price is mostly beholden to external forces
        (macro &amp; cycles).</p>
        <p>48/ That being said, it&#39;s quite possible that we are entering one such period of
        accumulation as Velodrome just launched and Optimism is growing rapidly.</p>
        <p>49/ There are many other interesting things I&#39;d love to think &amp; talk about on
        the subject of Velodrome (e.g. how $VELO is locked as veNFT and what that
        entails, or what a Convex-style layer could look like), but this is already
        super long, so I&#39;ll stop here.</p>
        <p>50/ I hope I did convince you that Velodrome is a good liquidity incentive
        system, and that it at least deserves your attention!</p>
        <p>51/ Obviously, none of this is financial advice. Don&#39;t trust what a random
        internet stranger has to say, validate.</p>
        <p>Disclaimers: I have small positions in both $VELO and $CRV/$CVX. I also worked
        with the Velodrome team in my capacity as an OP Labs employee.</p>
        <p>52/ A few useful links to conclude:</p>
        <ul>
        <li><a href="https://twitter.com/jpn_memelord/status/1533080509462487049">Dune dashboard with TVL &amp; usage metrics</a></li>
        <li><a href="https://vfat.tools/optimism/velodrome/">vfat Velodrome farming calculator</a></li>
        <li><a href="https://docs.velodrome.finance/tokenomics#emission-schedule">Emission schedule</a></li>
        </ul>
      ]]>
      </description>
      <pubDate>2022-06-06T16:00:00.000Z</pubDate>
      <link>https://norswap.com/velodrome-liquidity</link>
      <guid isPermaLink="true">https://norswap.com/velodrome-liquidity</guid>
    </item>
    <item>
      <title>Design of the $DJED Stablecoin</title>
      <description>
      <![CDATA[
        <p>This was originally a <a href="https://twitter.com/norswap/status/1526004123811794944">tweet thread</a> that I have reproduced here for
        discoverability and archive purposes (the copy was done on 24 October 2022).</p>
        <p>I&#39;ve only slightly reformatted the text (mostly links), otherwise this is the
        original version.</p>
        <hr>
        <p>1/16/ Earlier this week, <a href="https://twitter.com/liamihorne">@liamihorne</a> asked if anybody knew about the
        design of the $DJED &quot;algorithmic&quot; stablecoin from @COTInetwork</p>
        <p>I was curious, so I gave it a look...</p>
        <p>2/ The stablecoin is not so much algorithmic as it is overcollateralized in a
        way that separates minting from collateralization.</p>
        <p>3/ On the minting side, users can mint $DJED (stable) for collateral at 100%
        capital efficiency, if the supply is at least 400% collateralized (otherwise,
        you can&#39;t mint). In this case, the collateral is $ADA, so if $ADA is worth 100$,
        you get 100 $DJED back per $ADA.</p>
        <p>4/ On the collateralization side, users can mint $SHEN for $ADA. As I
        understand, $SHEN represents ownership of the $ADA held by the protocol on top
        of 100% $DJED collateralization, and can be redeemed for that underlying.</p>
        <p>5/ To preserve stability, $SHEN cannot be redeemed when the collateralization
        ration (CR) falls under 400%. It also cannot be minted when CR is over 800% (to
        avoid dilution of existing holders).</p>
        <p>6/ This design is perfectly safe (as far as my basic understanding goes): the
        stablecoin is overcollateralized, and if you fall below 400% CR, $SHEN holder
        can&#39;t remove collateral.</p>
        <p>7/ At that point it would take a 75% $ADA price drop for $DJED to be
        uncollateralized. I must also assume the $ADA can be liquidated if approaching
        100% CR (potentially pretty bad for $ADA price if the protocol is successful).</p>
        <p>8/ Additionally, every action from this point onward can only improve the CR:</p>
        <ul>
        <li>If users redeem $DJED for $ADA, CR goes up.</li>
        <li>If users mint $SHEN, CR goes up.</li>
        </ul>
        <p>So quite the opposite of a death spiral.</p>
        <p>9/ For users, this is just a fairly unremakable overcollateralized stablecoin.
        One exception: if you&#39;re a whale, you can get a lot of stables for your $ADA
        without incurring slippage.</p>
        <p>10/ There is also an argument that this avoids liquidaton cascades. I&#39;m not
        entirely convinced, since you still have the problem in extreme cases (which is
        when cascades occur) when you approach 100% CR.</p>
        <p>11/ For $SHEN minters ‚Äî if I&#39;m understanding is correct ‚Äî you&#39;re essentially
        levered long $ADA. If $ADA goes up, you own your share of the &gt; 100% pot when
        you joined + what passes into this pot due to price increase.</p>
        <p>12/ e.g. if people bought $DJED for $ADA at 100$, and $ADA goes up to $200, then
        only half the original $ADA is necessary to collateralize the $DJED at 100%, the
        other half passes to the part of the collateral that can be redeemed by $SHEN
        holders.</p>
        <p>13/ On the flip side, if $ADA drops, you&#39;re bearing not only the losses of the &gt;
        100% pot, but also the losses of the $ADA that uses to 100% collateralize the
        $DJED.</p>
        <p>14/ $SHEN minters also have a claim to (some of?) the fees generated by the
        protocol.</p>
        <p>15/ Something interesting is that due to the fact that $SHEN cannot be redeemed
        &lt; 400% CR, you probably can buy it at a discount on an AMM at that time (the
        discount accouting for the lack of liquidity). This is actually a good thing
        that promotes recollateralization.</p>
      ]]>
      </description>
      <pubDate>2022-05-15T16:00:00.000Z</pubDate>
      <link>https://norswap.com/djed-stable</link>
      <guid isPermaLink="true">https://norswap.com/djed-stable</guid>
    </item>
    <item>
      <title>How Cannon Works</title>
      <description>
      <![CDATA[
        <p>This was originally a <a href="https://twitter.com/norswap/status/1502085000967061504">tweet thread</a> that I have reproduced here for
        discoverability and archive purposes (the copy was done on 23 October 2022).</p>
        <p>I&#39;ve only slightly reformatted the text (mostly links), otherwise this is the
        original version.</p>
        <hr>
        <p>With the Cannon bug bounty out, it&#39;s time for me to take my best stab at
        describing what it is, and how it works.</p>
        <p>Cannon is our next-gen EVM-equivalent fault proof system. It&#39;s what will keep
        your funds secure when you use Optimism. Read to know more!</p>
        <p><img src="op-cannon.png" alt=""></p>
        <p>1/44 What to expect?</p>
        <ul>
        <li>Recap on optimistic rollups / fault proofs</li>
        <li>Short history of fault proofs at Optimism</li>
        <li>Most thorough explanation of Cannon (fault proofs?) to ever grace Twitter ‚Äî quite technical, but approachable</li>
        <li>My longest twitter thread to date</li>
        </ul>
        <p>LET&#39;S FUCKING GO</p>
        <p>2/ Optimistic rollups in brief: users send txs to sequencer. Sequencer executes
        transactions and creates L2 blocks. It also (a) &quot;rolls up&quot; transaction into
        batches submitted to L1 (as calldata) and (b) submits output hashes (which we&#39;ll
        equate to L2 block hashes here) to L1.</p>
        <p>3/ Validators follow the L1 chain, get txs from batches, re-execute them, and
        compare the resulting block hashes to the ones submitted by the sequencer.</p>
        <p>If there&#39;s a mismatch, they challenge the incorrect block hash via a <em>fault
        proof</em>. This is where Cannon comes in.</p>
        <p>4/ (I&#39;m simplifying on purpose here, you can also send L1-to-L2 and L2-to-L1
        txs, such as deposits and withdrawals. But this is isn&#39;t crucial to this
        explanation.)</p>
        <p>5/ A rollups&#39; fault proof system is a way to prove on the L1 chain (i.e.
        <em>trustlessly</em>) that processing the txs from an L2 block doesn&#39;t yield the block
        whose hash was submitted by the sequencer.</p>
        <p>6/ (Crucially, the L2 block includes the state root: a hash of the L2 state
        after executing the txs in the block. This will typically be apple of discord.)</p>
        <p>7/ The easiest way to perform a fault proof is to re-execute the whole block on
        L1. This is what Optimism&#39;s previous fault system attempted to do.</p>
        <p>Unfortunately, this system had many issues.</p>
        <p>8/ To keep costs manageable, every block carried a single transaction. This
        would have had very bad consequences for the scalability of the rollup in the
        long term. Not to mention, it&#39;s very different from how L1 does things.</p>
        <p>9/ Second, <a href="https://en.wikipedia.org/wiki/Interpreter_(computing)">interpreting</a> EVM bytecode onchain is just too expensive.</p>
        <p>This led to the original OVM: a system to deploy L2 bytecode as L1 bytecode.</p>
        <p>10/ The original OVM design works well for simple things, but not when &quot;context&quot;
        is needed. For instance, you can&#39;t translate the L2 NUMBER opcode (returning
        block height) to the L1 NUMBER opcode! These opcodes needed to be translated
        into calls to special contracts.</p>
        <p>11/ Similar issues played out for things like L2 contract calls.</p>
        <p>Replacing opcodes &amp; calls by larger EVM routines &amp; contract calls also meant
        that the max size of contracts on L2 was smaller the max L1 contract size!</p>
        <p>12/ (And indirectly this also caused the choice of requiring a patched Solidity
        compiler. Though it must be said other designs were possible there.)</p>
        <p>13/ The original OVM design was a good first attempt, but it was also clear it
        wasn&#39;t a good long term solution.</p>
        <p>14/ After the team (h/t <a href="https://twitter.com/karl_dot_tech">@karl_dot_tech</a> <a href="https://twitter.com/ben_chain">@ben_chain</a>) &amp;
        <a href="https://twitter.com/realgeorgehotz">@realGeorgeHotz</a> came up with the idea for Cannon, it was decided to
        drop the old fault proof system to start from a sane foundation. This was the
        OVM 2.0 re-genesis.</p>
        <p>15/ (I wasn&#39;t at Optimism at that time and wasn&#39;t consulted, but these names are
        pretty terrible. The OVM 1.0 (just like Arbitrum&#39;s AVM) is only a VM in the most
        abstract sense ‚Äî it&#39;s a modified instruction set translated to run on the EVM.
        The OVM 2.0 is not a VM in any sense.)</p>
        <p>16/ So how does Cannon prove a [txs ‚Üí block hash] mismatch if it does not
        execute the whole block on chain?</p>
        <p>The solution is in two parts:</p>
        <ol>
        <li>The challenge game</li>
        <li>The single step execution</li>
        </ol>
        <p>17/ The challenge game is a binary search over the execution trace of the &quot;fault
        proof program&quot;.</p>
        <p>In our case that program is one that, in first approximation, takes the L2 chain
        state and some transactions as inputs and emits an L2 block hash.</p>
        <p>18/ George called this program &quot;minigeth&quot;.</p>
        <p>In reality its input is a set of L1 blockhashes, and the input will be a set of
        L2 blockhashes. I&#39;ll skip the details here as they get into the weeds of
        Optimism Bedrock and not super relevant.</p>
        <p>19/ The important thing is that the input L1 blockhashes are a <em>commitment</em> to
        all the inputs we actually care about: the L2 state and the transactions. We can
        prove these things against the blockhash. For instance, we can prove that a
        batch was posted to one of these L1 blocks.</p>
        <p>20/ To retrieve the transactions &amp; L2 state, minigeth uses a component called
        &quot;the preimage oracle&quot;.</p>
        <p>This is a generic component that lets you go from a hash to a preimage. This is normally
        <a href="https://en.wikipedia.org/wiki/Preimage_attack">impossible</a> to compute for cryptographic hashes.</p>
        <p>21/ So the trick will be to get these [hash ‚Üí preimage] mappings from somewhere.
        I&#39;ll explain later how the preimage oracle is implemented on &amp; off-chain. But
        take it for granted for now.</p>
        <p>22/ So we have minigeth with our preimage oracle (which btw entirely replaces
        geth&#39;s usual database).</p>
        <p>We compile this to some instruction set, and execute it for our L1 blocks. This
        yields an execution trace, which is the list of every instruction executed
        during the execution.</p>
        <p>23/ During the challenge game, both the challenger and the sequencer do this,
        and then perform a binary search to find the first instruction whose result they
        disagree on.</p>
        <p>24/ It&#39;s a binary search because they start by looking a the result of the
        instruction 1/2 of the way through. If they disagree, they&#39;ll look at the
        instruction 1/4 of the way through, otherwise the instruction 3/4 of the way
        through, etc...</p>
        <p>25/ They&#39;ll keep narrowing the range until they zero in on a single instruction
        they disagree on.</p>
        <p>(Note that the challenger and the sequencer don&#39;t actually need to agree on the
        size of the execution trace.)</p>
        <p>26/ What&#39;s the &quot;result of an instruction&quot;? What do they agree/disagree on? It&#39;s
        simply a <a href="https://en.wikipedia.org/wiki/Merkle_tree">Merkle root</a> of a snapshot of the minigeth&#39;s memory!</p>
        <p>27/ George decided to compile minigeth to <a href="https://en.wikipedia.org/wiki/MIPS_architecture">MIPS</a>. So every step in the
        execution trace is a MIPS instruction.</p>
        <p>Why MIPS? It was one of the simplest instruction for which to implement an
        interpreter on-chain, and Go can natively compile to MIPS!</p>
        <p>28/ To do all of the above, we need to be able to run minigeth off-chain, to (1)
        get the execution trace and (2) generate MIPS memory snapshots.</p>
        <p>This is done by running the MIPS minigeth binary on the QEMU CPU emulator, and
        hooking into the emulator.</p>
        <p>29/ Off-chain (in MIPS-on-QEMU), the preimage oracle is implemented via calls to
        a JSON-RPC endpoint (i.e. querying an Ethereum node). In minigeth, each oracle
        use is tagged with its type, so we know which JSON-RPC call to emit.</p>
        <p>30/ (The most common JSON-RPC call is &quot;eth_getProof&quot;, used very creatively to
        retrieve storage slots and trie nodes.)</p>
        <p>31/ Alright, so the challenger and sequencer have agreed to disagree on a single
        instruction.</p>
        <p>Next comes the single step execution.</p>
        <p>The goal is to execute that single instruction, on the L1 chain.</p>
        <p>32/ For this, we need:</p>
        <ol>
        <li>An on-chain MIPS interpreter to interpret any instruction</li>
        <li>Any location in MIPS memory that the instruction might read</li>
        <li>Any preimage that the instruction might request</li>
        </ol>
        <p>33/ (1) was simply written by George.</p>
        <p>For (2), we already have a Merkle root of a memory snapshot taken right before
        the instruction (from the challenge game). We can use it to prove any memory
        location we might need to supply.</p>
        <p>34/ For (3), we simply presupply the [hash ‚Üí preimage] mapping by supplying
        the preimage, and then the hash is derived on-chain.</p>
        <p>Note that minigeth off-chain is also instructed to save all the [hash ‚Üí
        preimage] mappings it uses, so we have those handy.</p>
        <p>35/ Obviously, &quot;preimage requests&quot; are not a native MIPS instruction. Instead,
        it&#39;s encoded as a read to a pre-defined memory location, which &quot;magically&quot; has
        the preimage of the hash that was previously written at another pre-defined
        memory location.</p>
        <p>36/ This behaviour is implemented in the MIPS interpreter on-chain, and in the
        QEMU hooks off-chain.</p>
        <p>37/ Alright, so finally we can use our pre-supplied memory and preimages to run
        the single MIPS instruction on the on-chain MIPS interpreter. This yields a new
        memory snapshot Merkle root, which can be compared to the root asserted by the
        challenger.</p>
        <p>38/ If its Merkle root is the same, the challenge is valid, and the challenger
        wins.</p>
        <p>We haven&#39;t talked about this here, but in this case the challenger would receive
        the sequencer&#39;s &quot;bond&quot; as a reward.</p>
        <p>39/ And that&#39;s most of what there is to it!</p>
        <p>‚ÄºÔ∏è A very important note before I give you some further reading.</p>
        <p>The current implementation of Cannon DOES NOT allow you to challenge L2 blocks.
        Instead, it&#39;s a proof-of-concept that allows you to challenge L1 blocks.</p>
        <p>40/ So minigeth is currently a program that takes a blockhash as input and
        verifies the validity of that block by re-executing it on top of the previous
        state.</p>
        <p>Obviously, no L1 block should ever be invalid, meaning no challenge should ever
        succeed.</p>
        <p>41/ At least that&#39;s the theory we&#39;re putting on the line in our <a href="https://immunefi.com/bounty/optimismcannon/">bug bounty
        program</a>. Break this assumption and make 50k$ !</p>
        <p>42/ That was a looong thead, but I still had to simplify quite a bit and ommit
        some details.</p>
        <p>So, were can you learn more about Cannon? I&#39;m glad you ask!</p>
        <p>43/</p>
        <ul>
        <li>There&#39;s the <a href="https://github.com/ethereum-optimism/cannon">github repository</a></li>
        <li><a href="https://github.com/ethereum-optimism/optimistic-specs/wiki/Cannon-High-Level-Overview">A high-level overview</a></li>
        <li>A more detailed overview]<a href="https://github.com/ethereum-optimism/optimistic-specs/wiki/Cannon-Overview">detailed</a></li>
        </ul>
        <p>44/ Now, go forth and spread the chant</p>
        <p>cannon cannon cannon</p>
        <p>Cannon! Cannon! Cannon!</p>
        <p>CANNON CANNON CANNON</p>
      ]]>
      </description>
      <pubDate>2022-03-10T16:00:00.000Z</pubDate>
      <link>https://norswap.com/cannon-intro</link>
      <guid isPermaLink="true">https://norswap.com/cannon-intro</guid>
    </item>
    <item>
      <title>Olympus DAO: An Economic Analysis</title>
      <description>
      <![CDATA[
        <p>In my previous post ‚Äî <a href="/olympus">Olympus DAO from Primary Sources</a> ‚Äî we looked at
        exactly how <a href="https://www.olympusdao.finance/">OlympusDAO</a> worked by digging into the smart contracts implementing
        it.</p>
        <p>If you&#39;re jumping aboard this wagon, OlympusDAO is a decentralized app that
        turned quite a few heads due to the high promised APY, sharp price increase, and
        even sharper market cap increase.</p>
        <p>Last time we looked at what the protocol did mechanistically (the findings will
        be recapped shortly). This time, we&#39;re looking at the consequence of the
        mechanisms for price, market cap, valuation, etc.</p>
        <p>(It goes without saying that all of this is a fun educational analysis, and none
        of it is financial advice.)</p>
        <h2 id="the-bottom-line">The Bottom Line</h2>
        <p>I won&#39;t tease you further, here are the basic conclusions (presented
        out-of-order compared to the main text):</p>
        <ol>
        <li><p>OHM (Olympus&#39; token) has extremely high programmed inflation, but the staking
        product protects stakers against dilution.</p>
        </li>
        <li><p>At first look, it looks like staking also increases ownership over the total
        OHM supply when less than 100% of the supply is staked. In practice, it seems
        likely that most of the unstaked supply is made out of liquidity pool
        reserves owned by the protocol, meaning any increase in ownership is
        compensated by a dilution of the treasury (which underpins the value of
        owning the protocol!).</p>
        </li>
        <li><p>As a result staking is very much useless (economically neutral) as a
        mechanic, besides as a way to drive narrative and hype (high APYs!!).</p>
        </li>
        <li><p>As a first approximation, the treasury value offers a floor price on OHM&#39;s
        market cap ‚Äî however this notion is thwarted by the fact that the OHM
        treasury contain OHM tokens (in the liquidity pools underlying the LP
        tokens). So when the price of OHM goes down, so the does the market value of
        the treasury.</p>
        </li>
        <li><p>In reality, there exists a price <code>&gt; 1$</code> such that the OHM market cap is equal
        to the market value of the treasury. Let&#39;s call the treasury value at that
        price the <em>sustainable value</em>.</p>
        </li>
        <li><p>The sustainable treasury value must exist becau</p>
        <ul>
        <li><p>The treasury value decreases slower than the market cap (notably because
        it contains stablecoins), so if the price keeps dipping, at some point the
        market cap &quot;catches up&quot; with the treasury value.</p>
        </li>
        <li><p>Part of the treasury is denominated in stablecoins, and these were
        collected when the OHM price was much higher than 1$. Meaning the
        equilibrium (sustainable) price is <code>&gt; 1$</code>.</p>
        </li>
        </ul>
        </li>
        <li><p>In any case, the &quot;backing per OHM&quot; advertised by Olympus and the &quot;treasury
        value&quot; advertised by Wonderland are misleading since these value go down when
        the price goes down.</p>
        </li>
        <li><p>If the high inflation (rebase) rate persists, OHM will eventually go down to
        1$, at which point a backstop in the inflation logic prevents further
        inflation until the price increases again.</p>
        </li>
        <li><p>Bond sales are the real interesting mechanism. They are a programmed way to
        raise funds for the treasury via further inflation. Wether this is inflation
        is dilutive to OHM stakers depends on whether the bond sales discount is
        lower or higher than the current price premium (see below).</p>
        </li>
        <li><p>When discussing Olympus valuation, it will be much more useful to use gOHM
        (indexed OHM ‚Äî i.e. wrapped staked OHMs that do not dilute due to rebases)
        as a reference.</p>
        </li>
        <li><p>A useful model to value Olympus&#39; market cap is to assume it should trade at
        a premium to the sustainable treasury value. This premium is justified by
        the fact that gOHM is essentially (a) a voucher for ownership of part of the
        treasury + (b) a call option on the gOHM price. The call option part is the
        premium.</p>
        </li>
        <li><p>The premium essentially depends on the <em>sustainable</em> backing per gOHM + the
        expected future premium.</p>
        </li>
        <li><p>The backing could increase for multiple reasons: yield farming with the
        treasury, VC-like investments with the treasury, or new products that
        increase the treasury, like Olympus Pro.</p>
        </li>
        <li><p>The backing also naturally increases through bond sales, as long as the bond
        sales discount is lower than the current premium.</p>
        </li>
        <li><p>Because the current premium depends on the expected future premium, the
        process is reflexive (it&#39;s a &quot;Keynesian beauty context&quot; or &quot;a fixed-point
        calculation&quot;). Each participant must try to guess how every other
        participant will value OHM.</p>
        </li>
        <li><p>Ignoring this issue for now, what price should you be willing to purchase
        OHM at. i.e. what premium are you willing to accept?</p>
        </li>
        <li><p>I propose the formula: <code>maximum_purchase_price = expected_sustainable_treasury_backing * (1 + expected_premium) - current_price * (risk_free_rate + risk_premium)</code> (We already discussed all
        terms except the risk-free rate and the risk premium.)</p>
        </li>
        <li><p>The risk-free rate is the return rate you could get without taking risk. No
        such thing as &quot;risk-free&quot; in crypto, but you could set that to the lending
        rate on Aave or Compound for instance. (Or just use the US bonds rate!)</p>
        </li>
        <li><p>The risk premium is the return rate you demand to be compensated for the
        risk that you are taking.</p>
        </li>
        <li><p>See the article for an example of thow this computation can be borne out in
        practice.</p>
        </li>
        <li><p>I also briefly discuss the relationship between the premium and the treasury
        size. Mostly, as the treasury grows, it&#39;s natural to expect that the premium
        should decrease: the team doesn&#39;t scale linearly with capital, and
        investment opportunities become scarcer.</p>
        </li>
        <li><p>It&#39;s important to note that the Olympus team is aware of some of these
        issues. See this <a href="https://hackmd.io/@HMyg0dxkQ96YOMpI30o8PA/mbga">whitepaper</a> by Zeus and Indigo, which proposes
        &quot;an evolution from the existing staking-centric model in favor of a
        bond-centric model&quot;. The goal are to truly lock away part of the supply
        (which staking doesn&#39;t do) and enable selling &quot;internal&quot; OHM-OHM bonds (just
        like US treasury bonds but with OHM instead of USD) at high volume without
        adversely affecting the OHM price.</p>
        </li>
        <li><p>The team also came up with <a href="https://olympusdao.medium.com/olympus12-building-a-strong-ecosystem-around-a-web3-native-reserve-currency-416f58175e74">the Olympus12 roadmap</a>, which
        outlines a strong (imho) and extremely interesting action plan for
        bolstering the economics of OlympusDAO going forward. I do think the success
        of the plan hinges on whether they will manage to convince projects and
        people to effectively treat OHM (more like gOHM) as a token to put on the
        balance sheet / in their long-term portfolio, and not just speculation &amp;
        arbitrage. With the right mix of incentives and interesting use cases, they
        might be able to.</p>
        </li>
        </ol>
        <h2 id="table-of-contents">Table of Contents</h2>
        <ul>
        <li><a href="#the-bottom-line">The Bottom Line</a></li>
        <li><a href="#how-olympus-works-recap">How Olympus Works: Recap</a></li>
        <li><a href="#example">Example</a></li>
        <li><a href="#olympusdao-valuation">OlympusDAO Valuation</a><ul>
        <li><a href="#olympus-assets">Olympus&#39; Assets</a></li>
        <li><a href="#treasury-as-market-cap-floor">Treasury as Market Cap Floor</a></li>
        <li><a href="#sustainable-value">Sustainable Value</a></li>
        <li><a href="#the-floor-in-practice">The Floor in Practice</a></li>
        <li><a href="#the-premium-risk-free-rate-and-riks-premium">The Premium, Risk-Free Rate and Risk Premium</a></li>
        <li><a href="#pricing-gohm">Pricing gOHM</a></li>
        <li><a href="#evolution-of-the-backing-per-gohm">Evolution of the backing per gOHM</a></li>
        <li><a href="#modelling-the-premium">Modelling the Premium</a></li>
        </ul>
        </li>
        <li><a href="#olympus-in-the-long-run">Olympus in the Long Run</a></li>
        <li><a href="#on-the-uselessness-of-staking">On the Uselessness of Staking</a></li>
        <li><a href="#on-the-usefulness-of-bonding">On the Usefulness of Bonding</a></li>
        <li><a href="#coda">Coda</a></li>
        </ul>
        <h2 id="how-olympus-works-recap">How Olympus Works: Recap</h2>
        <p>If you missed <a href="/olympus">the previous article</a>, here is a copy of my (fairly
        detailed) summary of OHM&#39;s mechanisms. This should be all you need to follow
        along!</p>
        <ol>
        <li><p>The total supply of $OHM inflates at the <em>staking reward rate</em> every ~8
        hours. This inflation is redistributed among stakers. The inflation
        distribution event that happens every 8 hours is called <em>a rebase</em>.</p>
        </li>
        <li><p>The staking reward rate is set by the OlympusDAO policy team. For the longest
        time, this reward rate was 0.35%. It is currently 0.2%, on its way down to a
        target of 0.16%. At 0.35%, this implies an inflation of 4487%. This is also
        the minimum staking APY in OHM (if 100% of the OHM is staked, otherwise it
        will be higher). At 0.16%, this implies a 475% inflation (yup ‚Äî exponentials
        are weird).</p>
        </li>
        <li><p>OlympusDAO has a treasury composed of stablecoins and OHM-stablecoin
        [liquidity pool (LP) tokens][lp-tokens]. The treasury is constituted by
        selling bonds (see below).</p>
        </li>
        <li><p>A central concept is the &quot;risk-free value&quot; (RFV) of the treasury. This is simply
        1$ for stablecoin. For LP tokens, it is the price the token would take if the
        OHM price fell to 1$. Controversially, this means that part of the RFV of the
        treasury is made of OHM tokens (in the liquidity pools).</p>
        </li>
        <li><p>Rebases can only go through if there is 1$ of risk-free value in the treasury
        for each OHM in existence including the newly-minted ones. This sets a
        soft-floor if 1$ on the OHM price, assuming that the OHM market cap should
        always be at least as large as the risk-free value of the OHM treasury.</p>
        </li>
        <li><p>The protocol maintains a metric called &quot;the index&quot; which is how much OHM you
        would own if you staked a single OHM on the day the protocol launched
        (currenty 74). Recently, Olympus launched the gOHM (&quot;governance OHM&quot;) which
        &quot;wraps&quot; the indexed amount of staked OHM. The main avowed purpose was to
        enable the trading of staked OHM on other chains.</p>
        </li>
        <li><p>Staking comes with an optional warm-up period (currently disabled) which
        forces people to wait a configurable amount of time before their OHM tokens
        are staked.</p>
        </li>
        <li><p>At any time, people can purchase OHM bonds using various stablecoins and
        OHM-stablecoin <a href="https://www.google.com/search?hl=en&q=lp%20tokens">LP tokens</a>. The policy team can add, remove or tweak these
        bond markets. The bonds are usually sold as a small discount to
        the OHM market price. The bonds grant newly minted OHM tokens to the buyer.
        These tokens vest over a configurable period, which has always been 5 days.</p>
        </li>
        <li><p>The DAO takes a (configurable) fee over every bond sale, although this is
        currently set to 0, and it&#39;s rather hard to search historical state to see if
        it was ever set differently.</p>
        </li>
        <li><p>Bond pricing uses a notion of risk-free value (RFV). The risk-free value of
        stablecoins is equivalent to their market value. For LP tokens however,
        Olympus assumes a worst-case scenario where OHM is worth 1$, and prices the
        LP tokens accordingly.</p>
        </li>
        <li><p>Bonds are priced differently depending on the token used to purchase the
        bonds. The bond price is determined by the formula <code>bondPrice = min(BCV * debtRatio + 1, minimumPrice)</code>, where:</p>
        <ul>
        <li><p>One bond grants one OHM after the vesting period.</p>
        </li>
        <li><p>For simplicity, I ignore the decimals on <code>minimumPrice</code> and <code>bondPrice</code>
        (assume those are infinite precision numbers), and assume that <code>debtRatio</code>
        is a value between 0 and 1.</p>
        </li>
        <li><p><code>BCV</code> is the bond control variable, set by the policy team for each token</p>
        </li>
        <li><p><code>debtRatio</code> is a ratio between (a) the risk-free value of all tokens used for
        bond purchases (tallied at the moment of purchase) scaled by the remaining
        vesting time; and (b) the total OHM supply.</p>
        <p>Note that the numerator and the denominator have different units (risk-free
        USD and OHM), and consequently, the debt ratio rises faster when the OHM
        price is high.</p>
        </li>
        <li><p><code>minimumPrice</code> ‚Äî as the name indicates. However, once a bond purchases occurs
        above the minimum price, it is then set to 0, allowing subsequent purchases
        to occur below the bond price.</p>
        </li>
        </ul>
        <p> There is maximum amount of debt (denominated in risk-free value) allowed
         per token, preventing the emission of too many bonds, and offering some
         protection against attacks (e.g. if a stablecoin was to lose his peg).</p>
        <p> Because the formula is not based on the market price of OHM, the bond price
         can occasionally exceed the market price!</p>
        </li>
        </ol>
        <h2 id="example">Example</h2>
        <p>To make things more concrete, I&#39;m also copying verbatim the example from last
        time in this section. This will help you have a better sense of the mechanisms
        that we are discussing.</p>
        <p>Let&#39;s assume that</p>
        <ul>
        <li>OHM is worth 70$ (as it was when I wrote this example)</li>
        <li>the OHM-DAI liquidity pool contains 100 OHM (and therefore
        7000 DAI, which we&#39;ll write 7000$ for convenience)</li>
        <li>the ownership of the pool is split accross 100 LP tokens, each of which is
        worth <code>0.01 * 2 * 7000 = 140</code> $</li>
        <li>the current debt ratio for the OHM-DAI bond depository contract is 5%</li>
        <li>the bond control variable (BCV) for the OHM-DAI contract is 207 (as it is at
        the time for writing)</li>
        <li>the (thrice-daily) rebase rate is 0.24% (as it was when I wrote this)</li>
        <li>the DAO fee is 1%. This is currently 0% in both v1 and v2 bonds, and it&#39;s
        particularly difficult to find historical values (you&#39;d have to run your own
        node and re-execute transactions, since value changes are not even logged).</li>
        <li>the RFV backing per OHM is about 26$ (as it was ...)</li>
        <li>the market-rate backing per OHM is about 60$ (as it was ...)</li>
        </ul>
        <p>Under these condtions, the risk-free value (RFV) of such a DAI-OHM LP token is
        <code>0.01 * 2 * sqrt(100 * 7000) ~= 16.73</code> $.</p>
        <p>If a user uses a single LP token to purchase bonds, he would get back bonds that
        would grant <code>(16.73 * 100) / (100 + 5 * 207) == 2.32</code> OHM. This represents a
        &quot;premium&quot; of 0.73 OHM compared to the market price, which is equivalent of an
        effective OHM price of <code>140 / 2.32 = 60.34</code> $, or an effective discount rate of
        14% compared to the market price.</p>
        <p>A more realistic discount assessment would also consider that during the vesting
        period of 5 days, the OHM supply will inflate by around 3.7% (<code>1.0024^(3*5) ~= 1.037</code>), so the effective discount is closer to 10%, assuming the buyer redeems
        at the end of the vesting period (of course, Ethereum transaction prices makes
        the amounts we&#39;re discussing completely unreleastic, but whatever).</p>
        <p>We&#39;ll note that <a href="https://olympusdao.medium.com/introducing-olympus-v2-c4ade14e9fe">v2 bonds</a> solve this issue by staking the granted amount
        immediately, and so there is no loss due to inflation.</p>
        <p>So in this example, 2.343 OHM are emitted (<code>1.01 * 2.32</code> to account for the DAO
        fee), backed by 140$ of market value and 16.73$ of risk-free value (7.14$ per
        OHM).</p>
        <p>In this case, the RFV backing per minted OHM (7.14$) is significantly less than
        the current RFV backing per OHM (which is 26$). This means that each OHM emitted
        in bonding decreases the backing per OHM.</p>
        <p>This is an inherent property of LP bond sales. Stablecoin bond sales, on the
        other hand, tend to increase the RFV backing per OHM.</p>
        <h2 id="olympusdao-valuation">OlympusDAO Valuation</h2>
        <p>The central question in our analysis is going to be &quot;how should OlympusDAO be
        valued?&quot;. Meaning: what should the market cap on the OHM supply be?</p>
        <p>As we shall see, this is not an easy question, given that on one hand the
        treasury value is in flux, and the highly dilutive nature of the token on the
        other hand.</p>
        <p>There is of course no definitive answer to that question, but we can give many
        clues as to what an answer can look like.</p>
        <p>A lot of the data I&#39;m going to use in this analysis, come from the excelent
        <a href="https://dune.xyz/shadow">Dune dashboards</a> by <a href="https://twitter.com/sh4dowlegend">shadow</a> (Olympus&#39; policy lead), in particular the
        <a href="https://dune.xyz/shadow/Olympus-(OHM)">Olympus dashboard</a> and the Olympus Policy dashboard.</p>
        <h3 id="olympus-assets">Olympus&#39; Assets</h3>
        <p>OlympusDAO has three &quot;assets&quot;:</p>
        <ul>
        <li>the treasury</li>
        <li>the DAO funds</li>
        <li>its &quot;team members&quot; (i.e. the people paid by the DAO to develop OlympusDAO, either by
        means of code, marketing, business development, ...)</li>
        </ul>
        <p>First, let&#39;s precise the difference between the treasury and the DAO funds.</p>
        <p>The treasury is by design a reserve that backs the value of OHM. There is no
        peg, and so this reserve is allowed to be less than the market cap of OHM (as it
        has been for most of its history), or even greater (though this should only be a
        temporary aberration, as we&#39;ll argue shortly).</p>
        <p>The DAO funds are accrued via the DAO fee perceived during a bond sale. They are
        managed by the DAO&#39;s <a href="https://docs.olympusdao.finance/main/contracts/dao">multisig signatories</a>, which used to be the de facto leaders
        of the project. With the introduction of the gOHM token, token governance now
        has a purview on how the DAO spends those funds.</p>
        <p>Although I haven&#39;t looked into it, DAO funds are traditionally used to pay the
        team and perform other interventions (e.g. usage incentives, strategic token
        acquisition, such as CRV or TOKE, etc...).</p>
        <p>However, if the DAO pulls in enough fees to properly fund development, it is
        perfectly possible that it could redistribute part of the fee cashflows to users
        in various ways (dividends, token buybacks, or a combination of both *).</p>
        <p>*) In Olympus&#39; case, there is an extremely elegant way to do this: use DAO
        funds to purchase bonds, then deposit the received OHM in the staking contract
        where it will automatically be distributed amongst all stakers (cf. <a href="/olympus">previous
        article</a> to see how this distribution works on a nuts-and-bolt level).</p>
        <p>The team members should only be considered an asset insofar that users are
        confident that they are working to accrue value to token holder, whether by
        growing the treasury, accruing DAO fees to be redistributed, or other mechanisms
        like airdrops.</p>
        <h3 id="treasury-as-market-cap-floor">Treasury as Market Cap Floor</h3>
        <p>So, how do we value this?</p>
        <p>Well, Olympus must at least be worth as much as the treasury + the portion of
        DAO funds that hasn&#39;t been yet earmarked for a specific use. The DAO fee percent
        is currently 0, and though I don&#39;t have the data, I don&#39;t believe it was ever
        very high. We&#39;ll thus make the simplifying assumption that its value is
        negligible compared to the treasury.</p>
        <p>The project must be worth at least as much as the treasury because, in the worst
        case, token holders can vote to dissolve the treasury and compensate OHM and
        sOHM holders in proportion of their holdings.</p>
        <p>However, things are not <em>entirely</em> as simple as this, because the treasury does
        contain OHM tokens (underlying half the value of the LP token). <strong>So when the
        price of OHM goes down, so the does the market value of the treasury.</strong></p>
        <p>The market value doesn&#39;t work as a price floor, but neither does the risk-free
        value (RFV, the value when OHM is priced at 1$). That price is actually too
        pessimistic.</p>
        <p><strong>In reality, there exists a price &gt; 1$ such that the OHM market cap is equal to
        the market value of the treasury.</strong> Let&#39;s call the treasury value at that price
        the <em>sustainable value</em>.</p>
        <h3 id="sustainable-value">Sustainable Value</h3>
        <p>In this section, I will show why the sustainable value exists. We&#39;ll illustrate
        how a decreasing OHM price decreases the market value of the treasury, then show
        that this decrease is less than the price decrease, meaning that at some point,
        the market cap falls below the market value of the treasury. The market value of
        the treasury at this point is what we call the sustainable value.</p>
        <p>(If you accept this premise and are not interested in getting more supporting
        intuition as to why it is true, feel free to skip this section.)</p>
        <p>The Olympus treasury comprises a lot of LP tokens. The market value of those is
        made by half by OHM tokens. This means that as the OHM price drops, so does the
        market treasury value.</p>
        <p>Even simple <code>x*y=k</code> AMMs are not intuitive, so I&#39;ll avoid off on giving a full
        exposition. However, to give some intutition, as the price falls and people sell
        OHM into the liquidity pool, these three things happen:</p>
        <ul>
        <li>The market value of the OHM reserve of the liquidity pool drops.</li>
        <li>The OHM reserves of the pool increase.</li>
        <li>The stablecoin reserves of the pool decrease, by the amount of OHM sold to the
        pool at some &quot;average&quot; price between the old OHM price and the new OHM price.</li>
        </ul>
        <p>So that&#39;s not great: not only does the value of the whole OHM part decrease, but
        the stable reserves also decreases, and decreases more than compensated by the
        increase in OHM reserves valued at the new market price.</p>
        <p>Let&#39;s do a simple example for illustration&#39;s sake.</p>
        <ul>
        <li>Assume a liquidity pool with 100 OHM valued at $69 each.</li>
        <li>The pool is thus worth (<code>2*100*69 == 13,800$</code>).</li>
        <li>Using the <code>x*y = k</code> AMM formula, we get <code>k == 690,000</code>.</li>
        </ul>
        <p>Now assume someone sells 10 OHM into the pool.</p>
        <ul>
        <li>We have 110 OHM, so to preserve the value of <code>k</code>, the new amount of
        stablecoin becomes <code>690,000 / 110 == 6,272,72</code>.</li>
        <li>The new value of the pool is the double of this, i.e 12,544.44.</li>
        <li>The new token price is <code>6,272,72 / 110 == 57.022</code>.</li>
        </ul>
        <p>Consequently:</p>
        <ul>
        <li>The token price dropped 17.36%</li>
        <li>The pool&#39;s total value dropped by 9%.</li>
        </ul>
        <p>Note that the relationship between those things is not linear and depends on the
        parameters (e.g. the impact of a 10 OHM sale would have been smaller on a bigger
        pool, although the impact of a sale 10% the size of the pool would have been the
        same).</p>
        <p>Using the <a href="https://dune.xyz/shadow/Olympus-(OHM)">Olympus Dune dashboard</a>, we can see that (at the time
        of writing) the treasury market value is $484,110,067, while the risk-free
        market value is $237,941,247.</p>
        <p>The dashboard does warn that the values might not be accurate because of
        the v2 migration. There is some discrepancy from the Olympus app. For
        instance, the market cap on dashboard is $710M while it is $680M on the app. The
        app seems to put the market value of the treasury (as determined form the
        backing per OHM seems a few 10s of % higher).</p>
        <p>So let&#39;s be conservative and say that the RFV of the treasury is 2-4x lower than
        its market value.</p>
        <p>So as the OHM price decreases so does the market value of the treasury, albeit
        potentially slower than the price.</p>
        <p>Also, the treasury also contains stablecoins in addition to LP tokens, which
        means it will fall even slower percentage-wise than the OHM price.</p>
        <p>Because this market value of the treasury decreases slower than the price, it
        means there must necessarily exist a price (the <em>sustainable price</em>) such that
        the OHM market cap is equal to the market value of the treasury.</p>
        <p>Because part of the treasury is denominated in stablecoins, and these were
        collected the OHM price was much higher than 1$, it does mean that the
        sustainable price is higher than 1$, and hence the sustainable value is higher
        than the RFV.</p>
        <p>As simple way to see that is that this is like solving the equation <code>100 + 10x = 100x</code> (e.g. imagine the treasury holds 100$ and 10 OHM and the market cap is 100
        OHM, and <code>x</code> is the OHM price). In this case <code>x = 100 / 90 &gt; 1</code>.</p>
        <p>What this analysis shows is that the &quot;backing per OHM&quot; advertised by Olympus (as
        well as the &quot;treasury value&quot; advertised by Wonderland) are misleading since
        these value go down when the price goes down. However, the RFV value of the
        treasury is too pessimistic as a floor price, since there exist an intermediate
        &quot;floor price&quot; where the market cap is equal to the market value of the treasury.</p>
        <h3 id="the-floor-in-practice">The Floor in Practice</h3>
        <p>Interestingly, the theory that the market cap should never dip below the market
        price (the point at which it dips below being the sustainable price) has been
        put to the test recently, as OlympusDAO and its forks experience an accelerating
        crash over the past few weeks.</p>
        <p>OlympusDAO is currently hovering at 25% over the market value of the treasury.
        <a href="https://www.wonderland.money/">Wonderland</a>, Olympus&#39; biggest and most famous fork, actually <a href="https://www.coindesk.com/markets/2022/01/18/defis-wonderland-is-buying-time/">dipped under the
        market value of its treasury</a> and <a href="https://archive.is/1Av9l">a vote was held to dissolve the
        treasury</a>, which failed narrowly, but with a majority of holders
        against dissolution.</p>
        <p>For context, in addition to the price crash, Wonderland was shaken by the
        revelation that &quot;Sifu&quot; ‚Äî its treasury manager ‚Äî was a former convicted scammer.</p>
        <p>(As an aside, I consider this vote rational and see it as mostly a vote of
        confidence. Since Sifu was removed, as long as you trust the rest of the team
        with the treasury, there is no reason to not wait to recapture a premium over
        the treasury value. Such rebounds are common in crypto if the project does not
        immediately implode. If things don&#39;t improve, the treasury can still be unwound
        later ‚Äî there is a no-cost upside in waiting a little bit.)</p>
        <h3 id="the-premium-risk-free-rate-and-risk-premium">The Premium, Risk-Free Rate and Risk Premium</h3>
        <p>If the <em>sustainable value</em> of the treasury represents a floor for the market
        cap, what causes it to rise above that level? This is what we&#39;ll call <em>the
        premium</em>.</p>
        <p>Basically, in the case of OlympusDAO, a big part of the premium comes from the
        team and the possibility of future earnings. If team members roll out new
        features or new products that will accrue value to token holders, this
        possibility should be captured in the token price.</p>
        <p>The easiest way to think about the premium is that when you buy the token, you
        really buy two things: (a) a voucher for a slice of the treasury at its
        <strong>current</strong> (not sustainable) value; and (b) a call option representing the
        potential for the sustainable value of the treasury to increase. This call
        option part is the premium.</p>
        <p>In particular, the call option part represent the expectation that the treasury
        backing per inflation-indexed token (gOHM) will increase. It&#39;s important to only
        consider gOHM, not OHM, because there is no expected backing increase per OHM ‚Äî
        since it inflates so much due to the rebases.</p>
        <p>There are a few ways the backing per gOHM could increase:</p>
        <ol>
        <li>new initiatives increase the value of the treasury without dilution</li>
        <li>yield farming with the treasury</li>
        <li>venture capital investments with the treasury</li>
        <li>bond sales, as long as the current premium is higher than the bond discount</li>
        </ol>
        <p>Olympus actually rolled out an initiative that increased the treasury value at
        no cost or dilution to token holders, in the form of <a href="https://www.olympusdao.finance/pro">OlympusPro</a>, a side
        product that allowed other protocols to conduct their own bond sales based on
        the Olympus model. The Olympus treasury captures a 3.3% fees on every bond sale
        conducted on Olympus Pro.</p>
        <p>Another potential source of premium is the utilization of treasury funds to
        generate yield.</p>
        <p>Here we need to be careful, because it wouldn&#39;t make sense to say that the
        treasury funds can be used for yield farming (e.g. lending on Aave for a 5% APY)
        and thus the premium should increase accordingly.</p>
        <p>The idea here is that the yield farming opportunity is also open to you. Say you
        have stablecoins sitting around, instead of buying gOHM (or equivalently, buying
        and staking OHM), you could yield farm yourself. <strong>The premium should only
        capture returns in excess of that yield.</strong></p>
        <p>In traditional finance, this notion is known as the &quot;risk-free rate&quot; and is
        typically given by the yield on AAA-rated treasury bonds, in particular the US
        treasury bonds.</p>
        <p>(If you&#39;re interested in treasury bonds and how they behave, see my previous
        article on the topic: <a href="https://norswap.com/bonds/">one</a>, <a href="https://norswap.com/bonds-2/">two</a>.)</p>
        <p>This is not to say Olympus shouldn&#39;t yield farm. Quite the opposite: it&#39;s much
        easier to produce excess return on the risk-free rate if you just happen to have
        funds that you can yield farm with to produce this rate in the first place.</p>
        <p>In fact, <a href="https://twitter.com/quasicypher1/status/1486737670088896517">Olympus <em>is</em> yield farming</a> (see also <a href="https://twitter.com/ohmzeus/status/1486744382825017349">this
        remark</a>).</p>
        <p>Now, there is nothing such as a <em>risk-free</em> return in crypto. You&#39;re always at
        least taking smart contract risk (bugs, hacks).</p>
        <p>However it&#39;s fair to consider that buying OHM high abvoe the sustainable rate is
        riskier than yield farming on Aave. If we consider that both projects have been
        extremely well audited, then OHM additionally exposes you to price (premium!)
        volatility. You need to be compensate for that risk, and that is the <em>risk
        premium</em> (not the same thing as the OHM price premium over the sustainable
        price!).</p>
        <p>Finally, another source of premium would be to conduct venture capital (VC)
        investments using the treasury. Here the premium stems from a few factor:</p>
        <ul>
        <li>The treasury is large, which makes OlympusDAO a privileged partner compared to
        poorer individual investors.</li>
        <li>The treasury is also large enough that it can diversify by betting on numerous
        projects, which is central to the sustainability of the venture capital model
        (where you only have a few winners that make up for all your losers).</li>
        <li>The OlympusDAO team is talented and probably better able to determine a
        project&#39;s odds of success than the average OHM holder.</li>
        </ul>
        <p>Though it has been discussed online, there is no indication at the moment that
        the Olympus team intends to engage in venture capital investments.</p>
        <p>Last, but not least, the sustainable backing per OHM increases naturally via
        bond sales, as long as the discount price is lower then the current premium,
        i.e. as long a bonds are sold for more than the sustainable backing per OHM.</p>
        <p>This mechanism is the main driver of treasury growth, and we will revisit it
        <a href="#evolution-of-the-backing-per-gohm">below</a>. Unlike the previous mechanisms, it
        is &quot;dilutive&quot; in the sense that it mints new tokens ‚Äî although if the backing
        per gOHM increases, this is not really a problem.</p>
        <h3 id="pricing-gohm">Pricing gOHM</h3>
        <p>Let&#39;s put all the pieces from the last section (premium, risk-free rate and risk
        premium) together and attempt to see if we can come with a &quot;fair&quot; price for
        gOHM, given our assumptions as investors.</p>
        <p>Let&#39;s assume, for simplicity sake, that the sustainable price of gOHM is 100$ at
        present, and you expect the sustainable price to increase by 50$ over your
        investment horizon (say one year). How much should be willing to buy gOHM for?</p>
        <p>A naive (and wrong) answer to this would be to say that any price under 150$ is
        fine, as it will net you a you profit. This is wrong for a two reasons:</p>
        <ul>
        <li>At your point of reference in the future, gOHM should still trade at a
        premium, so if the sustainable value is 150$, the price of gOHM will be higher
        than that.</li>
        <li>If on the other hand, if we assume that the premium will be 0, it&#39;s still
        wrong to purchase at say 149$, because you&#39;re only making a <code>1/149 = 0.6%</code>
        return. This is much less than the risk-free rate (e.g. 5%).</li>
        <li>But buying so that you make exactly the risk-free rate is also wrong. You&#39;re
        taking significantly more risk by buying OHM, therefore you should expect
        higher returns to compensate you for that risk (the <em>risk premium</em>).</li>
        </ul>
        <p>Therefore your buy price should be any price under:</p>
        <p><code>expected_sustainable_treasury_backing * (1 + expected_premium) - current_price * (risk_free_rate + risk_premium)</code></p>
        <p>Where <code>expected_premium</code>, <code>risk_free_rate</code> and
        <code>risk_premium</code> are percentages (quantities between 0 and 1).</p>
        <p>Therefore, to value gOHM, you need to make the following predictions/decisions:</p>
        <ul>
        <li>How much will the (sustainable) treasury backing per gOHM increase?</li>
        <li>How will the premium change?</li>
        <li>What are my &quot;risk-free&quot; alternatives? i.e., what do I use as risk-free rate?</li>
        <li>How risky is the investment? i.e., what risk premium do I demand in order to
        feel like the potential upside is worth the risk?</li>
        </ul>
        <p>Let&#39;s plug in some numbers. Say the current premium is 25% (so the price is
        125$) and I expect this to remain stable. Say I consider 5% to be my risk-free
        rate, and I&#39;d like to be compensated at 10% for the risk I&#39;m taking. Then you
        get:</p>
        <p><code>150 * (1 + 0.25) - 125 * (0.05 + 0.1) = 168.75</code></p>
        <p>Since the current price (125$) is less than 168.75$, you should buy gOHM, and if
        all your predictions are uncannily accurate, the token will be worth <code>150 * 1.25 = 187.5$</code> in a year. You will sell for a 62.5$ profit, which is a 50% return
        rate ‚Äî as expected since the backing increased 50% and the premium didn&#39;t
        change. This is higher than your desired 15% return rate (5% risk-free rate +
        10% risk premium).</p>
        <h3 id="evolution-of-the-backing-per-gohm">Evolution of the Backing per gOHM</h3>
        <p>The formula above asks you to predict the future sustainable backing per gOHM.
        Let&#39;s now look at how you could do that. The value actually depends on a couple
        of factors:</p>
        <ol>
        <li>The percentage of the OHM supply staked (this has been fairly stable at <a href="https://dune.xyz/shadow/Olympus-(OHM)">90%
        for most of of Olympus&#39; history</a>, though it has dipped to
        the low 80s over the last month. The lower the percentage of the supply
        staked, the faster stakers (hence gOHM holder) accrue ownership over the
        total supply at the expense of non-stakers. At 90%, the return rate is 6.6%.</li>
        <li>The dilution incurred by LP bond sales.</li>
        <li>The amount of bond token sales, and their discount rate.</li>
        </ol>
        <p>One big question to solve here is &quot;who are the non-stakers?&quot;. I actually expect
        that a significant part of the non-staked supply is made of the OHM token
        backing the LP tokens owned by the treasury!</p>
        <p>This explanation fits perfectly the fact that the staking percentage decreased
        over the last month: as OHM price decreased, the amount of OHM underlying the LP
        token naturally increased (as OHM was traded in in exchange for stablecoins)!</p>
        <p>This means that even the increased ownership for stakers comes at the expense of
        the treasury (whose OHM tokens keep diluting). I think it&#39;s fair to model the
        return on staking as essentially nil, but preventing rebase-induced dilution.</p>
        <p>So we&#39;re left with bonding.</p>
        <p>The sustainable backing by gOHM can either increase or decrease from bond sales,
        depending on whether the increase in the sustainable treasury value compensates
        the dilution incurred by the bond sale.</p>
        <p>It depends on the current premium and the bond discount: if the discount is
        smaller than the premium, then the backing per newly minted OHM is higher than
        the current sustainable backing per OHM (therefore very slightly increasing to
        total backing per OHM). If on the other hand the discount is higher than the
        discount, then the backing per OHM decreases.</p>
        <h3 id="modelling-the-premium">Modelling the Premium</h3>
        <p>There is one question that all of the above doesn&#39;t really answer directly ‚Äî how
        large should the premium be?</p>
        <p>Well, imagine all investors run the above calculation. Each of them will come up
        with their own &quot;acceptable&quot; premium. In our example that would have been 68.5%
        (<code>(168.5 - 100) / 100</code>). The actual premium will be the premium such that no one
        will sell any investor OHM with a premium lower than their premium of choice.</p>
        <p>In (the messy and complex) reality, investors will need to try to anticipate
        what this premium will be in order to price their own premium of choice. This
        makes the whole market pricing affair a reflective process known as a <a href="https://en.wikipedia.org/wiki/Keynesian_beauty_contest">Keynesian
        beauty contest</a>. If you&#39;re more mathematically inclined, you could also
        say the market price is the result of a <a href="https://en.wikipedia.org/wiki/Fixed_point_(mathematics)">fixed-pointed computation</a>.</p>
        <hr>
        <p>Now, we could also look at the premium from another angle. And that is: how is
        the premium expected to change as the treasury increases or decreases?</p>
        <p>The key question is whether the premium should be flat (since the team&#39;s ability
        to deliver new successful projects is only very weakly correlated with the size
        of the treasury), or proportional to the treasury size (in the case of venture
        capital investments).</p>
        <p>Since both of these make sense, a simple model of the premium would be one where
        the premium decreases as the treasury grow. In this model, the excess value
        incurred by the premium (i.e. <code>premium * sustainable_treasury</code>) grows along with
        the treasury, but at a decreasing rate. Think of square-root like functions.</p>
        <p><img src="square_root.svg" alt="square root function"></p>
        <p>This decrease in growth represents the fact that the team&#39;s potential does not
        increase linearly with the treasury (you could hire more people, but it&#39;s well
        established that company productivity does not scale linearly with the number of
        hires). It also represents the fact that there are diminishing returns when you
        sling around a large amount of capital: the yield farming returns tend to be
        lower, which decreases your edge on the &quot;risk-free&quot; rate. Similarly, quality
        venture capital opportunities might dry up.</p>
        <p>A more complete model should probably take into account that if the treasury
        value is low, then the premium should grow faster than the treasury (as it
        enables new essential hires, new venture capital opportunities, etc). However,
        Olympus&#39; treasury is already large ($484M), so we&#39;ll eschew this part of the
        model.</p>
        <hr>
        <p>Ok. All good and fair, but concretely, what would a good premium be for Olympus
        today?</p>
        <p>One answer to that is that you just run the price calculation from above. But to
        do that, you need to estimate what the premium will be!</p>
        <p>Well, I&#39;m a bit of a loss here.</p>
        <p>First of all, investors are not rational, and I feel fairly confident to say
        many (most?) of them never really did understood how Olympus worked. The price
        is still a reflective process of investor&#39;s willingness to pay, but without
        common knowledge (such as this blogpost! though at this point I have to wonder
        how many investors will read this novel I have written), it&#39;s hard to know what
        investors will think ‚Äî more likely their willingness to pay will be ruled by
        momentum, hype, FOMO and FUD.</p>
        <p>The current premium of 25% over the market rate doesn&#39;t feel particularly
        extreme to me, neither does it feel particularly low. Note that this is a
        premium over the <em>market value</em>, not the <em>sustainable value</em> (which I haven&#39;t
        computed ‚Äî reach out if you feel like doing that!).</p>
        <p>Looking at Olympus Pro, it has so far yield about $2M in fees, or about 0.5% of
        the treasury size. Since it was introduced 4 months ago, we can extrapolate that
        it will yield about 1.5% of the treasury value over a year. If the Olympus team
        introduces some new products, these returns could start adding up.</p>
        <p>Additionally, one should look at the returns that OlympusDAO is getting on its
        <a href="https://twitter.com/quasicypher1/status/1486737670088896517">yield farming activities</a>.</p>
        <p>If you have opinions on this (backed with data) ‚Äî I&#39;d be interested to talk to
        you!</p>
        <h2 id="olympus-in-the-long-run">Olympus in the Long Run</h2>
        <p>How can we expect Olympus to behave in the long run?</p>
        <p>Well, the fact of the matter is that OHM is designed to inflate until its price
        drops to 1$. This path could however be stretched indifinitely if the team
        decides to drastically lower the rebase rate. If they lower this rate enough,
        then the earnings from fees on bond sales (both from Olympus and Olympus Pro),
        the treasury value could increase faster than OHM dilutes.</p>
        <p>In the case where the rebase rate stays high, then OHM will decrease in price
        until it reaches 1$. This is not super relevant: as I&#39;ve argued before, it&#39;s the
        price of gOHM (indexed, inflation-protected OHM) that is relevant!</p>
        <p>When the price of OHM reaches 1$, a backstop prevents any further inflation,
        whether via discounted bounding or via rebasing. This would be rather crippling
        for the protocol so I would expect the team to take some measures before that
        happens (whether that&#39;s curbing the rebase rate, or something else).</p>
        <p>Other than that... it could continue chugging along and raising money via bond
        sales. At the end of the day, gOHM is a voucher to a portion of the underlying
        treasury and a call option to speculate on the fluctuation of the premium.</p>
        <p>The real question for Olympus and OHM holders is what the team is going to come
        out with next! The team has plans, see the <a href="#further-reading">Further Reading</a>
        section!</p>
        <p>As for questions of price, there are two questions of interest:</p>
        <ol>
        <li>How fast can the sustainable treasury value increase?</li>
        <li>How will the premium evolve?</li>
        </ol>
        <p>At present, the answer to (2) is purely a question of market psychology, meaning
        keeping a finger on the pulse of the hype. Crypto markets are not super mature
        yet, and Olympus is still relatively niche amongst crypto markets.</p>
        <p>More surprisingly, (1) similarly depends and on the premium, and thus on hype.
        When the premium is high, the sustainable treasury value increases rapidly.
        Similarly, I would expect more bonds to be sold when the hype is high and the
        price is on the uptrend.</p>
        <h2 id="on-the-uselessness-of-rebases">On the Uselessness of Rebases</h2>
        <p>At this point, I want to emphasize something that has been implied, but hasn&#39;t
        been made crystal clear at this point: staking and rebases are absolutely
        useless in Olympus, and serve no purpose besides creating hype and a narrative
        based on widespread misunderstanding of Olympus&#39; mechanics.</p>
        <p>As an Olympus dev <a href="https://twitter.com/_nd_go/status/1488060799096696833">says</a>: &quot;I think one of the biggest mistakes the
        DAO made was allowing the APY become the focus of anything.&quot;</p>
        <p>Basically, staking protects the inflation created by rebases. It&#39;s both the
        poison and the cure.</p>
        <p>Since not 100% of the supply is staked, staking does entail a transfer of
        ownership from non-stakers to stakers. But as mentionned before, it&#39;s likely
        that most of the unstaked supply lives in LP pools whose tokens are owned by the
        Olypus treasury. Which means the small ownership increase gets cancelled by a
        loss of value of the treasury.</p>
        <p>One thing this achieves, however is to disincentivize anyone but Olympus to
        provide liquidity. I&#39;m not sure how good or bad that is... On the one hand,
        Olympus can monopolize the transfer fees, on the other hand, that&#39;s just less
        liquidity period.</p>
        <p>This last point is also moot with the introduction of gOHM since you can now
        provide liquidity for gOHM which wraps staked OHM.</p>
        <p>In general, the whole existance of gOHM calls the usefulness of rebases into
        question, since it abstracts away the whole rebase/staking mechanic.</p>
        <p>I think rebases (inherited from <a href="https://www.ampleforth.org/">Ampleforth</a>) were included because OHM was
        envisioned as some kind of stablecoin. But at present, Olympus doesn&#39;t perform
        rebases that lower user balances (which would be necessary to let the price dip
        below 1$ and bring it back to that level).</p>
        <h2 id="on-the-usefulness-of-bonding">On The Usefulness of Bonding</h2>
        <p>We haven&#39;t talked about this much, but one of Olympus&#39; big idea was &quot;buy
        liquidity, don&#39;t rent it&quot;.</p>
        <p>This is based on the observation that liquidity providers can be quite
        mercenary, and will move their liquidity elsewhere once incentivization stops.
        Hence you&#39;re only ever &quot;renting liquidity&quot;. And as we all know, in the long
        term, renting is more expensive than buying outright.</p>
        <p>The idea makes a lot of sense, and for projects where you can expect a high
        enough premium, bonding can make a lot of sense.</p>
        <p>It solves two fundamental problems:</p>
        <ul>
        <li>Raising all the capital upfront means good project get a bad deal. Since your
        project is completely unproven, it will necessarily be valued with a lot of
        circonspection. (Although sometimes, the opposite is true, where project is
        overvalued on the basis of hype...) Raising money as you go with bonds, in a
        way that is not (or not very) dilutive to token holders can make a lot of
        sense for growth-oriented projects.</li>
        <li>It removes the problem of deciding when, how, how much, and from who to raise.
        (Olympus&#39; founder Zeus made <a href="https://twitter.com/ohmzeus/status/1479888653304303617">this very same point</a>). Instead, the
        decision is made by a pre-determined algorithm. An hybrid mode is possible,
        where a project decides on a number of bonds to be sold, and lets the
        algorithm figure out the execution.</li>
        </ul>
        <p>Now, some caveats.</p>
        <p>First of all, not every project is shaped as Olympus, i.e. as a big pot of
        money. Many project pass their revenues directly to the users, and only keep a
        small amount in the treasury (which are equivalent to the Olympus&#39;s DAO funds).
        The model can still work for these project, but the premium has to be modelled
        on the basis of return on capital instead.</p>
        <p>Second, it&#39;s not quite clear that the way Olympus does bond sales (on the basis
        of the bond control value and the debt ratio) is necessarily the best way. I can
        imagine much simpler mechanisms to achieve the same goals (e.g. a <a href="https://en.wikipedia.org/wiki/Dutch_auction">Dutch
        auction</a> where each successful purchase bumps the price back up). The model is
        not obviously wrong either, it&#39;s just not obvious (to me) that it is the best.</p>
        <p>I do expect that Olympus Pro offers more flexibility on this matter, but I
        haven&#39;t reviewed that codebase.</p>
        <h2 id="further-reading">Further Reading</h2>
        <ul>
        <li><p><a href="https://fbifemboy.substack.com/p/a-correct-model-of-olympus-dao">A correct model of OlympusDAO</a>: A harsher (but oh so much
        terser) criticism of OlympusDAO than I make, to which I nevertheless subscribe
        excepted for valuation purposes. The memes criticized here are not dead
        though, as evidenced by <a href="https://twitter.com/ishaheen10/status/1495286382964576256">this presentation</a> of OHM (which isn&#39;t bad,
        but parrots the kool-aid a bit too much).</p>
        </li>
        <li><p><a href="https://twitter.com/ohmzeus/status/1486886116598890498">Zeus on Healthy Debt</a>: the cascading liquidations of loans
        secured against an OHM collateral was a big driver in the OHM price crash.</p>
        </li>
        <li><p><a href="https://hackmd.io/@HMyg0dxkQ96YOMpI30o8PA/mbga">Liquid Interest Rate Markets through Olympus Bonds</a> (+ <a href="https://forum.olympusdao.finance/d/1061-exploring-a-bond-centric-future">governance
        discussion</a>): A whitepaper by Zeus and Indigo from the Olympus team.
        It proposes &quot;an evolution from the existing staking-centric model in favor of
        a bond-centric model&quot;, showing that the OlympusDAO leadership is aware of the
        issues raised in this piece. I&#39;m under the impression they willingly downplay
        (or maybe are still deluded about) the uselessness of staking while at the
        same time phasing it out in favour of &quot;internal OHM bonds&quot; which are
        fixed-term bonds purchased in OHM that give a return in OHM (just like US
        treasury bonds, but using OHM instead of USD). The big advantage there is
        locking away the part of the supply used to purchase bonds (whereas staking if
        fully liquid ‚Äî users can stake and unstake instantly). Another one is that you
        can emit many more bonds (and thus grow the treasury faster), because it turns
        out most bond purchasers unstake &amp; sell OHM to buy bonds (I had no idea!),
        essentially arbitraging bonding against staking. This whitepaper covers much
        more and honestly deserves its own article!</p>
        </li>
        <li><p><a href="https://olympusdao.medium.com/olympus12-building-a-strong-ecosystem-around-a-web3-native-reserve-currency-416f58175e74">Olympus12: Building a Strong Ecosystem Around a Web3-Native Reserve
        Currency</a>: outlines a strong (imho) and extremely interesting
        action plan for bolstering the economics of OlympusDAO going forward. I do
        think the success of the plan hinges on whether they will manage to convince
        projects and people to effectively treat OHM (more like gOHM) as a token to
        put on the balance sheet / in their long-term portfolio, and not just
        speculation &amp; arbitrage. With the right mix of incentives and interesting use
        cases, they might be able to.</p>
        </li>
        </ul>
        <h2 id="coda">Coda</h2>
        <p>And that&#39;s a wrap! Thanks for following this far! If you&#39;ve liked this, you
        might like some of my other <a href="/finance">finance writings</a>. If you want to keep up with my
        new stuff, subscribe to the RSS feed or <a href="https://twitter.com/norswap">follow me on Twitter</a>.</p>
        <p>I hope that after reading this, you&#39;ll understand a bit better how Olympus
        behaves economically and how it can be valued.</p>
        <p>To conclude with some more personal opinions, I think OlympusDAO was a project
        whose theory was pretty ill-conceived. You can tell by the confused discourse
        around it (including the official discourse), and the uselessness of staking as
        a mechanic. Ironically, this confusion and the high APY hype allowed it to be
        successful.</p>
        <p>Nevertheless, the bonding mechanism is pretty solid and interesting. And am I
        impressed by the humility of the team and the plan they are making to further
        improve the project. I would be surprised is this is the last we heard of
        OlympusDAO.</p>
      ]]>
      </description>
      <pubDate>2022-02-27T16:00:00.000Z</pubDate>
      <link>https://norswap.com/olympus-econ</link>
      <guid isPermaLink="true">https://norswap.com/olympus-econ</guid>
    </item>
    <item>
      <title>ZK Rollups vs Optimistic Rollups</title>
      <description>
      <![CDATA[
        <p>This was originally a <a href="https://twitter.com/norswap/status/1494763568843132931">tweet thread</a> that I have reproduced here for
        discoverability and archive purposes (the copy was done on 23 October 2022).</p>
        <p>I&#39;ve only slightly reformatted the text (mostly links) and updated the line of
        code statistics.</p>
        <hr>
        <p>1/ At EthDenver, people keep asking me on my perspective on optimistic rollups
        vs zkRollups. Unfortunately, zkRollups have managed to occupy the whole
        narrative space, so here&#39;s a take that is a bit more nuanced!</p>
        <p>2/ The first advantages of zkRollups is a lower L1 calldata part of the fee.
        There a two important caveats:</p>
        <ul>
        <li>The advantage is probably less than you think, see <a href="https://twitter.com/norswap/status/1494456477246844928">this thread to understand why</a>.</li>
        <li>Optimistic rollups have an advantage in non-calldata L1 cost, and in L2 cost.</li>
        </ul>
        <p>3/ A zkRollup needs to run the prover for every transaction, which has massive
        overheads (~ 10000x). On the other hand, <a href="https://github.com/ethereum-optimism/cannon/">Cannon</a>&#39;s MIPS-compiled validator has
        10x overhead, and this would disappear if we ran it on MIPS hardware.</p>
        <p>4/ zkRollups also need to verify the zk proof on chain, which entails L1 gas
        costs on top of the calldata. The next version of Optimism (Bedrock) is going to
        be almost 100% calldata cost.</p>
        <p>5/ We&#39;re working hard to lower L1 calldata costs for all rollups. We want to
        help bring &quot;blob-carrying transactions&quot; to Ethereum in the Shangai hardfork.</p>
        <p>See Vitalik Buterin&#39;s <a href="https://notes.ethereum.org/@vbuterin/blob_transactions">explanation of blobs</a> for more details.</p>
        <p>6/ With blobs, calldata costs would likely lower 1Norswap üè¥‚Äç‚ò†Ô∏èüî¥‚ú®
        @norswap
        ¬∑
        Feb 1800x (since rollups would be
        the only ones seriously competing for this calldata space).</p>
        <p>Suddenly, non-calldata costs would become dominant, and opRollups would have the
        upper hand!</p>
        <p>7/ To be fair, this would likely revert in the long term as rollups become the dominant way to transact.</p>
        <p>But it&#39;s still not clear to me that zkRollups will necessarily be cheaper, and
        it&#39;s downright doubtful they will be significantly cheaper.</p>
        <p>8/ As an aside, blobs are like a primitive version of &quot;danksharding&quot; (named after the wonderful @dankrad
        ), which is itself an easier version of full sharding. Find all about this
        <a href="https://notes.ethereum.org/@hww/workshop_feb_2022">here</a>.</p>
        <p>9/ The second advantage of zkRollups is the absence of a withdrawal period.</p>
        <p>This advantage is also a curse. You might know that Optimism recently paid the
        <a href="https://twitter.com/optimismFND/status/1491821983796895747">largest bug bounty</a> in history (2M$) for an infinite money bug.</p>
        <p>10/ But if the bug had been exploited, the withdrawal period would have allowed
        us to rollback the chain to mitigate the damage.</p>
        <p>11/ At the moment this is possible because the system is permissioned (as are
        all rollups), but in the future, some form of governance could easily take this
        decision within 7 days.</p>
        <p>12/ Economic bridges provide enough liquidity for most uses, and would be rekt
        in case of such a hack, but they do not have enough liquidity for an attacker to
        drain the chain.</p>
        <p>13/ If this happened on a zkRollup instead, the exploiter could just immediately
        drain the whole rollup.</p>
        <p>The zkProof wouldn&#39;t save you: it&#39;s happy to prove a buggy program/contract ran correctly.</p>
        <p>14/ What about some advantages of opRollups?</p>
        <p>For one, they&#39;re much simpler to understand and audit.</p>
        <p>They are only a handful of people in the world capable of auditing the zk prover and verifier logic.</p>
        <p>15/ Not only that, but optimistic designs can be incredibly tiny and elegant.</p>
        <p>In Bedrock, we&#39;re on track to implement the system with <a href="https://github.com/ethereum-optimism/op-geth">less than one thousand
        lines of code on top of Geth</a>.</p>
        <p>16/ The node itself (the part responsible for deriving the L2 chain from L1) is
        less than 20k lines of code.</p>
        <p>We could probably cut that a lot if we weren&#39;t using Go and its notoriously
        verbose error-checking üòÅ</p>
        <p>17/ To be clear, I like zero knowledge proofs. We&#39;re not shy about using them,
        if and when it makes sense.</p>
        <p>e.g. I&#39;m thinking about using a zkProof to aggregate ECDSA signatures &amp; reduce
        our calldata size. (Hit me up if you know how!)</p>
        <p>18/ I wish a lot of success to our zk competitors. The improvement they make to
        the technology is a net positive for all of us.</p>
        <p>But to claim that ZK is the only way in the future (and even moreso, the only
        way now) is intellectually dishonest. The truth is much more nuanced.</p>
        <p>19/ tl;dr</p>
        <ul>
        <li>opRollups are cheaper on non-calldata cost</li>
        <li>opRollups will be cheaper with blobs transactions</li>
        <li>long-terms fees are less clear, but there shouldn&#39;t be a huge difference</li>
        <li>the withdrawal period is a protection against attacks</li>
        <li>opRollups MUCH easier to audit</li>
        </ul>
      ]]>
      </description>
      <pubDate>2022-02-17T16:00:00.000Z</pubDate>
      <link>https://norswap.com/zk-vs-optimistic</link>
      <guid isPermaLink="true">https://norswap.com/zk-vs-optimistic</guid>
    </item>
    <item>
      <title>Olympus DAO from Primary Sources</title>
      <description>
      <![CDATA[
        <p>If you&#39;re following <a href="https://ethereum.org/en/defi/">decentralized finance (aka DeFi)</a>, you&#39;ve probably heard
        about <a href="https://www.olympusdao.finance/">OlympusDAO</a>.</p>
        <p>OlympusDAO describes itself as a &quot;decentralized reserve currency&quot;. In the
        non-crypto worlds, a <a href="https://en.wikipedia.org/wiki/Reserve_currency">reserve currency</a> is a foreign currency held by other
        governments to back and stabilized their own currency. Interestingly, OHM is
        itself a currency backed by a reserve (&quot;the treasury&quot;) of other assets (mostly
        stablecoin and OHM-stable <a href="https://www.google.com/search?hl=en&q=lp%20tokens">LP tokens</a>, but also some ETH). I don&#39;t think Olympus
        works as a reserve currency at all, but I will defer this discussion to another
        article.</p>
        <p><strong>In this article, I want to look at what Olympus actually does, and I want to
        do so by digging straight into the code.</strong></p>
        <p>I&#39;m doing this because OlympusDAO has been the subject of a lot of talk over its
        short history, but I never really manage to understand how it works. There is a
        lot of narrative to be found, but very little mechanistic explanations ‚Äî at
        least not enough to answer most of my question. What I read about it also didn&#39;t
        seem to make sense from an economic standpoint, but this was impossible to
        determine without establish ground truth on OlympusDAO&#39;s inner workings.</p>
        <p>So why were people talking about Olympus you ask? First, look at this chart:</p>
        <p><img src="ohm-price.png" alt="OHM price chart"></p>
        <p>Quite volatile (up 4x, down 6x, up 6x, down 12x), but nothing extraordinary for
        crypto. No, what is incredible is that this is while OlympusDAO was offering
        <a href="https://hackernoon.com/earning-passive-income-with-defi-staking-an-overview-4a1y3720">stakers</a> interest rates (aka <a href="https://www.investopedia.com/terms/a/apy.asp">APY</a>) of thousands of percents (&gt; 1700% as we
        speak). These interest rates are, importantly, denominated in OHM. Who wouldn&#39;t
        be enticed?</p>
        <p>However, all of this comes with a caveat, in a word: inflation.</p>
        <p>Over the last week, OlympusDAO (and its forks, most notably <a href="https://www.wonderland.money/">Wonderland</a>) have
        come under fire for the massive drop in prices they have experienced, putting
        the market cap of OHM very close to the value of its treasury (which logically
        is the smallest possible price, just how a company should at least be worth at
        least at much as its assets minus its debts). Wonderland even periodically
        dipped under its treasury value.</p>
        <p>The market capitalization chart (which is in many ways much more relevant than
        the price charts, because of inflation) for OHM tells of its meteoric rise, and
        recent fall:</p>
        <p><img src="ohm-market-cap.png" alt="OHM market capitalization chart"></p>
        <p><strong>In a subsequent article, I will dive deep into the economics of OlympusDAO and
        how the current situation is not all that surprising.</strong> I will say right now
        that I do not think Olympus is a scam or a ponzi scheme (which many people
        accuse it of being). I do think the communication about the project has been
        somewhat deceitful. At the very least, impressive elements ‚Äî like the
        OHM-denominated APY ‚Äî have been emphasized, while immense caveats have been
        ommitted from the discourse.</p>
        <h2 id="summary-of-findings">Summary of Findings</h2>
        <p>This is going to be a long and technical article. For those that are just
        interested in the take aways, here they are:</p>
        <ol>
        <li>The total supply of $OHM inflates at the <em>staking reward rate</em> every ~8
        hours. This inflation is redistributed among stakers. The inflation
        distribution event that happens every 8 hours is called <em>a rebase</em>.</li>
        <li>The staking reward rate is set by the OlympusDAO policy team. For the longest
        time, this reward rate was 0.35%. It is currently 0.2%, on its way down to a
        target of 0.16%. At 0.35%, this implies an inflation of 4487%. This is also
        the minimum staking APY in OHM (if 100% of the OHM is staked, otherwise it
        will be higher). At 0.16%, this implies a 475% inflation (yup ‚Äî exponentials
        are weird).</li>
        <li>OlympusDAO has a treasury composed of stablecoins and OHM-stablecoin
        <a href="https://www.gemini.com/cryptopedia/what-is-a-liquidity-pool-crypto-market-liquidity">liquidity pool (LP) tokens</a>. The treasury is constituted by
        selling bonds (see below).</li>
        <li>A central concept is the &quot;risk-free value&quot; (RFV) of the treasury. This is simply
        1$ for stablecoin. For LP tokens, it is the price the token would take if the
        OHM price fell to 1$. Controversially, this means that part of the RFV of the
        treasury is made of OHM tokens (in the liquidity pools).</li>
        <li>Rebases can only go through if there is 1$ of risk-free value in the treasury
        for each OHM in existence including the newly-minted ones. This sets a
        soft-floor if 1$ on the OHM price, assuming that the OHM market cap should
        always be at least as large as the risk-free value of the OHM treasury.</li>
        <li>The protocol maintains a metric called &quot;the index&quot; which is how much OHM you
        would own if you staked a single OHM on the day the protocol launched
        (currenty 74). Recently, Olympus launched the gOHM (&quot;governance OHM&quot;) which
        &quot;wraps&quot; the indexed amount of staked OHM. The main avowed purpose was to
        enable the trading of staked OHM on other chains.</li>
        <li>Staking comes with an optional warm-up period (currently disabled) which
        forces people to wait a configurable amount of time before their OHM tokens
        are staked.</li>
        <li>At any time, people can purchase OHM bonds using various stablecoins and
        OHM-stablecoin <a href="https://www.google.com/search?hl=en&q=lp%20tokens">LP tokens</a>. The policy team can add, remove or tweak these
        bond markets. The bonds are usually sold as a small discount to
        the OHM market price. The bonds grant newly minted OHM tokens to the buyer.
        These tokens vest over a configurable period, which has always been 5 days.</li>
        <li>The DAO takes a (configurable) fee over every bond sale, although this is
        currently set to 0, and it&#39;s rather hard to search historical state to see if
        it was ever set differently.</li>
        <li>Bond pricing uses a notion of risk-free value (RFV). The risk-free value of
        stablecoins is equivalent to their market value. For LP tokens however,
        Olympus assumes a worst-case scenario where OHM is worth 1$, and prices the
        LP tokens accordingly.</li>
        <li>Bonds are priced differently depending on the token used to purchase the
           bonds. The bond price is determined by the formula <code>bondPrice = min(BCV *    debtRatio + 1, minimumPrice)</code>, where:</li>
        </ol>
        <ul>
        <li><p>One bond grants one OHM after the vesting period.</p>
        </li>
        <li><p>For simplicity, I ignore the decimals on <code>minimumPrice</code> and <code>bondPrice</code>
        (assume those are infinite precision numbers), and assume that <code>debtRatio</code>
        is a value between 0 and 1.</p>
        </li>
        <li><p><code>BCV</code> is the bond control variable, set by the policy team for each token</p>
        </li>
        <li><p><code>debtRatio</code> is a ratio between (a) the risk-free value of all tokens used for
        bond purchases (tallied at the moment of purchase) scaled by the remaining
        vesting time; and (b) the total OHM supply.</p>
        <p>Note that the numerator and the denominator have different units (risk-free
        USD and OHM), and consequently, the debt ratio rises faster when the OHM
        price is high.</p>
        </li>
        <li><p><code>minimumPrice</code> ‚Äî as the name indicates. However, once a bond purchases occurs
        above the minimum price, it is then set to 0, allowing subsequent purchases
        to occur below the bond price.</p>
        </li>
        </ul>
        <p>   There is maximum amount of debt (denominated in risk-free value) allowed per
           token, preventing the emission of too many bonds, and offering some
           protection against attacks (e.g. if a stablecoin was to lose his peg).</p>
        <p>   Because the formula is not based on the market price of OHM, the bond price
           can occasionally exceed the market price!</p>
        <p>I tried to explicitly stay away from the economical implications. As said
        before, these will be the subject of a subsequent article!</p>
        <p>In what follows, I will dive into the contracts themselves. Together, we&#39;ll
        learn where all of the above functionality is implemented, and how.</p>
        <h2 id="table-of-contents">Table of Contents</h2>
        <ul>
        <li><a href="#">Top</a></li>
        <li><a href="#summary-of-findings">Summary of Findings</a></li>
        <li><a href="#olympus-v11-vs-olympus-v2">Olympus v1.1 vs Olympus v2</a></li>
        <li><a href="#contracts">Contracts</a><ul>
        <li><a href="#v11-contracts">v1.1 Contracts</a></li>
        <li><a href="#v2-contracts">v2 Contracts</a></li>
        <li><a href="#upgrade-paths">Upgrade Paths</a></li>
        </ul>
        </li>
        <li><a href="#basics--staking">Basics &amp; Staking</a><ul>
        <li><a href="#intro-to-rebases--sohm-balances">Intro to Rebases &amp; sOHM Balances</a></li>
        <li><a href="#staking--unstaking">Staking &amp; Unstaking</a></li>
        <li><a href="#rebases-in-depth">Rebases in Depth</a></li>
        <li><a href="#locker">Locker</a></li>
        <li><a href="#sohm-index">sOHM Index</a></li>
        </ul>
        </li>
        <li><a href="#bonding">Bonding</a><ul>
        <li><a href="#stablecoin-bond-pricing">Stablecoin Bond Pricing</a></li>
        <li><a href="#liquidity-token-bond-pricing">Liquidity Token Bond Pricing</a>
        (This section explains the Risk-Free Value computation for bonds.)</li>
        <li><a href="#bonding-in-depth">Bonding in Depth</a><ol>
        <li><a href="#1-checking-against-the-maximum-debt">Checking against the maximum debt</a></li>
        <li><a href="#2-calculate-the-bond-price">Calculate the bond price</a></li>
        <li><a href="#3-calculate-the-market-value-USD-bond-price">Calculate the market-value USD bond price</a></li>
        <li><a href="#4-calculate-the-payout-and-dao-fee">Calculate the payout and DAO fee</a></li>
        <li><a href="#5-mint-ohm-for-payout-and-dao-fee">Mint OHM for payout and DAO fee</a></li>
        <li><a href="#6-pay-the-dao-and-perform-book-keeping">Pay the DAO and perform book-keeping</a></li>
        </ol>
        </li>
        <li><a href="#example">Example</a></li>
        </ul>
        </li>
        </ul>
        <h2 id="olympus-v11-vs-olympus-v2">Olympus v1.1 vs Olympus v2</h2>
        <p>The present investigation was on conducted on the 1.1 version of the protocol.
        This is because I started this a long time ago in mid-December, and didn&#39;t
        realize that the <a href="https://olympusdao.medium.com/introducing-olympus-v2-c4ade14e9fe">v2 of the protocol</a> was already launched, <em>excepted</em> the v2
        bonds (which are now live too).</p>
        <p>Olympus v1.1 was apparently intended as an intermediary milestone to facilitate
        the deployment of v2.</p>
        <p>The particular code I investigated is <a href="https://github.com/OlympusDAO/olympus-contracts/tree/Version-1.1/">the 1.1 codebase</a> as can be
        found in the <code>Version-1.1</code> branch on Github.</p>
        <p>Annoyingly, it looks like not all the code of that repository was deployed as
        such. For instance, the OHM contract is not identical to <a href="https://etherscan.io/address/0x383518188c0c6d7730d91b2c03a03c837814a899#code">its first
        deployment</a> (verified in March 2021) nor to <a href="https://etherscan.io/address/0x64aa3364F17a4D01c6f1751Fd97C2BD3D7e7f1D5#code">its second
        deployment</a> (verified in December 2021 and matching the v2
        code).</p>
        <p>If you want to investigate the latest deployed v2 codebase, check out <a href="https://github.com/OlympusDAO/olympus-contracts/tree/542c215c57e213ed82a98ffc052ebaa9ee4f1ce9">the tree
        at this commit</a>, which merges in the v2 bonds.</p>
        <p>That being said, as far as I was able to determine, <strong>the protocol did not change
        significantly between v1.1 and v2</strong>. The major change seems to be that bonds no
        longer vest linearly but immediately stake OHM which can be redeemed at expiry
        (this will be repeated below, in the appropriate context).</p>
        <p>The other change is the start of on-chain governance via the gOHM token
        (representing an indexed amount of sOHN, as mentionned in the take-aways). This
        doesn&#39;t affect the behaviour of contracts, however.</p>
        <p>If you follow throught this article, you&#39;ll have a thorough enough understanding
        that understanding the v2 contracts should be a breeze.</p>
        <p>The v2 codebase seems vastly improved, and most likely assuages some of the
        complaints I make below!</p>
        <p>You might also want to read <a href="https://blog.oighty.com/olympus-v2-bonds">this deep dive on Olympus v2 bonds</a>
        for an alternative analysis, focused on v2.</p>
        <h2 id="contracts">Contracts</h2>
        <p>Before we dig into the protocol&#39;s internals, let&#39;s inventorize the contracts,
        both for v1.1 and v2 deployments. In particular, <a href="https://docs.olympusdao.finance">the OlympusDAO
        documentation</a> is not yet updated to list the addresses of the v2
        contracts.</p>
        <p>If you consult the doc, you&#39;ll note that some contracts have many versions which
        are dubbed v1, v2, v3, v4, ... It goes without saying that these version bear no
        relationship to the protocol versions (v1.1, v2, ...).</p>
        <p>As said earlier, the v1.1 source does not always match the deployment (some
        contracts were tweaked that were not deployed), so it may happen that the source
        file I link does not match the deployed contract. You can check this by
        comparing the verified source code in the contract/code tab agains the GitHub
        source.</p>
        <h3 id="v11-contracts">v1.1 Contracts</h3>
        <ul>
        <li><a href="https://etherscan.io/address/0x383518188c0c6d7730d91b2c03a03c837814a899#code">OlympusERC20.sol</a> (<a href="https://github.com/OlympusDAO/olympus-contracts/blob/Version-1.1/contracts/OlympusERC20.sol">source</a>)<ul>
        <li>Owned by <a href="https://etherscan.io/address/0x763a641383007870ae96067818f1649e5586f6de">this EOA address</a></li>
        </ul>
        </li>
        <li><a href="https://etherscan.io/address/0x04f2694c8fcee23e8fd0dfea1d4f5bb8c352111f#code">sOlympusERC20.sol</a> (<a href="https://github.com/OlympusDAO/olympus-contracts/blob/Version-1.1/contracts/sOlympusERC20.sol">source</a>)</li>
        <li><a href="https://etherscan.io/address/0xFd31c7d00Ca47653c6Ce64Af53c1571f9C36566a#code">Staking.sol</a> (<a href="https://github.com/OlympusDAO/olympus-contracts/blob/Version-1.1/contracts/Staking.sol">source</a>)</li>
        <li><a href="https://etherscan.io/address/0xC8C436271f9A6F10a5B80c8b8eD7D0E8f37a612d#code">StakingHelper.sol</a> (<a href="https://github.com/OlympusDAO/olympus-contracts/blob/Version-1.1/contracts/StakingHelper.sol">source</a>)</li>
        <li><a href="https://etherscan.io/address/0x2882a5cd82ac49e06620382660f5ed932607c5f1#code">StakingWarmup.sol</a> (<a href="https://github.com/OlympusDAO/olympus-contracts/blob/Version-1.1/contracts/StakingWarmup.sol">source</a>)</li>
        <li><a href="https://etherscan.io/address/0xC58E923bf8A00E4361FE3f4275226a543D7D3ce6#code">StakingDistributor.sol</a> (<a href="https://github.com/OlympusDAO/olympus-contracts/blob/Version-1.1/contracts/StakingDistributor.sol">source</a>)</li>
        <li><a href="https://etherscan.io/address/0x31F8Cc382c9898b273eff4e0b7626a6987C846E8#code">Treasury.sol</a></li>
        </ul>
        <p>In v1.1, there is one bonding contract per token that can be used to purchase
        bonds. I will only list the DAI and OHM-DAI contracts, to serve as examples:</p>
        <ul>
        <li><a href="https://archive.fo/KkeeN">List of Bond Contracts</a><ul>
        <li>e.g. <a href="https://etherscan.io/address/0x575409F8d77c12B05feD8B455815f0e54797381c#code">DAI Bond</a></li>
        <li>e.g. <a href="https://etherscan.io/address/0x956c43998316b6a2F21f89a1539f73fB5B78c151#code">OHM/DAI LP Bond</a></li>
        </ul>
        </li>
        <li>Bond Calculator Contract<ul>
        <li><a href="https://etherscan.io/address/0xcaaa6a2d4b26067a391e7b7d65c16bb2d5fa571a#code">older deployment used by the newest OHM/DAI LP bond</a></li>
        <li><a href="https://etherscan.io/address/0x7b1a5649145143f4fad8504712ca9c614c3da2ae#code">newer deployment used by the newest OHM/FRAX LP bond</a></li>
        <li>the code in those two are exactly identical!</li>
        </ul>
        </li>
        </ul>
        <p>There are also some contracts related to governance and operations:</p>
        <ul>
        <li><a href="https://etherscan.io/address/0x245cc372c84b3645bf0ffe6538620b04a217988b#code">DAO</a><ul>
        <li>Proxied to <a href="https://etherscan.io/address/0x34cfac646f301356faa8b21e94227e3583fe3f5f#code">Gnosis Safe</a> (<a href="https://github.com/gnosis/safe-contracts/blob/v1.1.1/contracts/GnosisSafe.sol">github source</a>)</li>
        <li><a href="https://docs.olympusdao.finance/main/contracts/dao">List of signers</a> (4 of 7)</li>
        </ul>
        </li>
        <li><a href="https://etherscan.io/address/0x0cf30dc0d48604a301df8010cdc028c055336b2e#code">Policy</a><ul>
        <li>Also proxied to <a href="https://etherscan.io/address/0x34cfac646f301356faa8b21e94227e3583fe3f5f#code">Gnosis Safe</a></li>
        <li><a href="https://docs.olympusdao.finance/main/contracts/policy">List of signers</a> (3 of 5)</li>
        </ul>
        </li>
        </ul>
        <h3 id="v2-contracts">v2 Contracts</h3>
        <ul>
        <li><a href="https://etherscan.io/address/0x1c21f8ea7e39e2ba00bc12d2968d63f4acb38b7a#code">OlympusAuthority.sol</a> (<a href="https://github.com/OlympusDAO/olympus-contracts/blob/542c215c57e213ed82a98ffc052ebaa9ee4f1ce9/contracts/OlympusAuthority.sol">source</a>)<ul>
        <li>This replaces the &quot;Policy&quot; from v1.1 and also owns the ERC-20 contract.</li>
        </ul>
        </li>
        <li><a href="https://etherscan.io/address/0x64aa3364f17a4d01c6f1751fd97c2bd3d7e7f1d5#code">OlympusERC20.sol</a> (<a href="https://github.com/OlympusDAO/olympus-contracts/blob/542c215c57e213ed82a98ffc052ebaa9ee4f1ce9/contracts/OlympusERC20.sol">source</a>)</li>
        <li><a href="https://etherscan.io/address/0x04906695D6D12CF5459975d7C3C03356E4Ccd460#code">sOlympusERC20.sol</a> (<a href="https://github.com/OlympusDAO/olympus-contracts/blob/542c215c57e213ed82a98ffc052ebaa9ee4f1ce9/contracts/sOlympusERC20.sol">source</a>)</li>
        <li><a href="https://etherscan.io/address/0xb63cac384247597756545b500253ff8e607a8020#code">Staking.sol</a> (<a href="https://github.com/OlympusDAO/olympus-contracts/blob/542c215c57e213ed82a98ffc052ebaa9ee4f1ce9/contracts/Staking.sol">source</a>)<ul>
        <li>v2 does not have separate warmup &amp; helper contracts ‚Äî instead the
        functionality is merged in <code>Staking.sol</code></li>
        </ul>
        </li>
        <li><a href="https://etherscan.io/address/0xeeeb97a127a342656191e0313df33d58d06b2e05#code">StakingDistributor.sol</a> (<a href="https://github.com/OlympusDAO/olympus-contracts/blob/542c215c57e213ed82a98ffc052ebaa9ee4f1ce9/contracts/StakingDistributor.sol">source</a>)</li>
        <li><a href="https://etherscan.io/address/0x9a315bdf513367c0377fb36545857d12e85813ef#code">Treasury.sol</a> (<a href="https://github.com/OlympusDAO/olympus-contracts/blob/542c215c57e213ed82a98ffc052ebaa9ee4f1ce9/contracts/Treasury.sol">source</a>)</li>
        <li><a href="https://etherscan.io/address/0x9025046c6fb25fb39e720d97a8fd881ed69a1ef6#code">BondingDepository.sol</a></li>
        <li><a href="https://etherscan.io/address/0x0ab87046fbb341d058f17cbc4c1133f25a20a52f#code">gOHM</a> (<a href="https://github.com/OlympusDAO/olympus-contracts/blob/542c215c57e213ed82a98ffc052ebaa9ee4f1ce9/contracts/governance/gOHM.sol">source</a>)</li>
        <li>The DAO contract is the same as before.</li>
        </ul>
        <p>A big difference in v2 is that there is a single deployed bonding contract,
        which handles all tokens (unlike v1.1, which has one deployed contract per
        token).</p>
        <p>v2 has also other contracts, but I haven&#39;t reviewed those, so I&#39;ll limit myself
        to establish this mapping will the old contracts. Also note that the <a href="https://github.com/OlympusDAO/olympus-contracts/tree/542c215c57e213ed82a98ffc052ebaa9ee4f1ce9">v2
        codebase</a> splits interface and imports away from the main contract
        to be deployed, unlike 1.1.</p>
        <h3 id="upgrade-paths">Upgrade Paths</h3>
        <p>Olympus uses very few proxy (only for the DAO and the v1.1 policy contract). Yet
        they were able to deploy many new versions of contracts.</p>
        <p>These upgrade paths are not explicit in the code (which is a shame), but I do
        believe some thoughts went into them.</p>
        <p>Often, upgrades entails co-existence. For instance, the v1.1 staking contract
        still &quot;works&quot; if you staked your OHM in it and haven&#39;t migrated to v2. However,
        the old contract does not accept new stakers anymore (this can be achieved by
        setting some configurable values (e.g. addresses) so that new attempts to stake
        on the old contract revert).</p>
        <p>In the future, it&#39;s possible that Olympus might be able to &quot;disable&quot; some old
        contracts. For instance, it could suspend rebases in the old staking contract
        (by modifying the address of the distributor), forcing people to migrate if they
        want to keep earning yield.</p>
        <p>That being said, the lack of proxys does not mean that the protocol is
        &quot;decentralized&quot;. In fact, the policy/authority multisig has the ability to
        change a lot of variables, including contract addresses!</p>
        <h2 id="basics--staking">Basics &amp; Staking</h2>
        <p>Let&#39;s begin our dive into the contracts! First, let&#39;s get the easy stuff out of
        the way:</p>
        <ul>
        <li><p>The <a href="https://etherscan.io/address/0x383518188c0c6d7730d91b2c03a03c837814a899#code">OlympusERC20.sol</a> contract is a straightforward <a href="https://eips.ethereum.org/EIPS/eip-20">ERC-20</a> token
        contract implementation. It is owned by an <a href="https://etherscan.io/address/0x763a641383007870ae96067818f1649e5586f6de">EOA</a> (Externally Owned
        Account). This is not very secure, but is fixed in Olympus v2, where the owner
        is remplaced by the Olympus authority contract, which is in turn controlled by
        a <a href="https://help.gnosis-safe.io/en/articles/3876456-what-is-gnosis-safe">multisig Gnosis safe</a>.</p>
        <p>Minting privileges are given to the &quot;vault&quot; which is the
        <a href="https://etherscan.io/address/0x31F8Cc382c9898b273eff4e0b7626a6987C846E8#code">Treasury.sol</a> contract.</p>
        </li>
        <li><p>The <a href="https://etherscan.io/address/0x245cc372c84b3645bf0ffe6538620b04a217988b#code">DAO</a> contract is simply a <a href="https://help.gnosis-safe.io/en/articles/3876456-what-is-gnosis-safe">Gnosis safe</a>, which lets a majority of
        <a href="https://docs.olympusdao.finance/main/contracts/dao">signers</a> do whatever with the funds held by the DAO contract.</p>
        </li>
        </ul>
        <h3 id="intro-to-rebases--sohm-balances">Intro to Rebases &amp; sOHM Balances</h3>
        <p>The <a href="https://etherscan.io/address/0x04f2694c8fcee23e8fd0dfea1d4f5bb8c352111f#code">sOlympusERC20.sol</a> contract is also an <a href="https://eips.ethereum.org/EIPS/eip-20">ERC-20</a> implementation, this
        time for the staked OHM token (<em>sOHM</em>, which you receive in exchange for your
        OHMs after you stake). However, the contract also implements part of the
        &quot;rebase&quot; logic.</p>
        <p>In Olympus parlance, a <em>rebase</em> is the thrice-daily inflation event. It used to
        be set at 0.35% for a long time, but is now <a href="https://dune.xyz/shadow/Olympus-Policy">sitting at 0.2%</a>,
        subject to changes by the Olympus policy team. During each rebase, the newly
        minted tokens are auto-staked and distributed to the stakers proportionally to
        their existing stake.</p>
        <p>Because of the frequent rebases, sOHM balances are constantly in flux. They
        change automatically, without users needed to submit transactions to claim.</p>
        <p>The way this is implemented is rather ingenious. The contract does not maintain
        sOHM balances: this would be too expensive, as every rebase would need to touch
        every single balance. Instead it maintains a balance of &quot;gons&quot; (I don&#39;t know
        where the term comes from). Whenever a rebase occur, the gon balance does not
        change ‚Äî only the total pot of OHM owned by the <a href="https://etherscan.io/address/0xFd31c7d00Ca47653c6Ce64Af53c1571f9C36566a#code">staking contract</a> is
        increased. A user&#39;s sOHM balance is the fraction of the OHM pot equal to its gon
        balance divided by the total gon supply. This is also the amount of OHM the user
        would receive if unstaking his whole sOHM balance (one sOHM always corresponds
        1-1 to one OHM in the staking contract).</p>
        <p>The sOHM contract itself defines only part of that logic. It has a
        <code>rebase(uint256 profit_, uint epoch_)</code> function, callable only by the staking
        contract. The <code>profit_</code> here is the amount of sOHM that is to be distributed in
        the rebase. The logic in that function ensures that the sum of the balances of
        all stakers is increased by this amount.</p>
        <p>Now we must tackle a peculiarity in the contract code I cannot quite explain.
        Instead of letting the staking contract mint the sOHM whenever it receives OHM,
        the sOHM contract allocates <code>5*10^15</code> (or 5 million billion) sOHM to the staking
        contract. Whenever the staking contract receives OHM, it sends a corresponding
        amount of sOHM from his own balance to the staker. I assume there must be a
        reason for this, but it is not obvious. The contract also calls sOHM
        &quot;fragments&quot;, though I&#39;m not quite sure why. (It could be to better differentiate
        them from gons, and avoid using ambiguous terms like <em>amount</em>, but the contract
        does that sometimes anyway.)</p>
        <p>EDIT: <a href="https://twitter.com/_nd_go">iND1G0</a> points out the terminology is
        inherited from <a href="https://www.ampleforth.org/">Ampleforth</a>, an algorithm
        stablecoin. This explanation from the home page is pretty eloquent:</p>
        <blockquote>
        <p>When Price &gt; $1, wallet balances Increase proportionally
        When Price &lt; $1, wallet balances Decrease proportionally</p>
        </blockquote>
        <p>This sOHM allocation to the staking contract also means that the sOHM contract
        must distinguish between the total supply and the <em>circulating supply</em> (which
        excludes the staking contract&#39;s balance), and that the <code>rebase</code> function must
        inflate the total supply by more than the <code>profit_</code> parameter, in order for the
        circulating supply to be inflated by <code>profit_</code> and be effectively accrued to the
        stakers. The staking contract balance inflation is irrelevant (since it&#39;s only
        ever exchange for OHM that was staked, or to reward lockers ‚Äî see later).</p>
        <p>An interesting thing to note is that the staking contract&#39;s sOHM balance is not
        backed by underlying OHM. This is fine because (a) when staking, users exchange
        OHM for sOHM 1-1 with the staking contract and (b) when rebasing, the
        <a href="https://etherscan.io/address/0xC58E923bf8A00E4361FE3f4275226a543D7D3ce6#code">distributor contract</a> mints OHM for the staking contract 1-1 with
        the reward (see later).</p>
        <h3 id="staking--unstaking">Staking &amp; Unstaking</h3>
        <p>The abstract idea of staking is pretty easy: you send X OHM to the <a href="https://etherscan.io/address/0xFd31c7d00Ca47653c6Ce64Af53c1571f9C36566a#code">staking
        contract</a>, and the staking contract sends you X sOHM in return.
        Unstaking is the same, but in reverse.</p>
        <p>In pratice, it&#39;s a bit more involved because the contracts introduce a notion of
        <em>warmup</em>, which is not currently used.</p>
        <p>To stake, you call the <code>stake(uint _amount, address _recipient)</code> function, which
        receives your OHM, and sends sOHM to the <a href="https://etherscan.io/address/0x2882a5cd82ac49e06620382660f5ed932607c5f1#code">StakingWarmup.sol</a> contract on
        your behalf. Then, after the warmup period (<code>warmupPeriod</code>, currently 0), you
        can call <code>claim (address _recipient)</code> to transfer the sOHM locked in the warmup
        contract to your own balance.</p>
        <p>Because the warmup period is currently 0, you could do both calls in a single
        transaction. For this purpose, Olympus has deployed the
        <a href="https://etherscan.io/address/0xC8C436271f9A6F10a5B80c8b8eD7D0E8f37a612d#code">StakingHelper.sol</a> contract whose <code>stake(uint _amount)</code> function
        does exactly this. Additionally, the recipient is implicitly the sender.</p>
        <p>You can cancel the warmup period and reclaim your OHM with the <code>forfeit()</code>
        function, and you can prevent other people from staking OHM for you using
        <code>toggleDepositLock()</code> (my best guess is that this is just for extra protection,
        so that a contract that you&#39;ve authorized to handle your OHM can&#39;t unstake your
        sOHM).</p>
        <h2 id="rebases-in-depth">Rebases in Depth</h2>
        <p>Rebases are initiated by calling the <code>rebase()</code> function of the <a href="https://etherscan.io/address/0xFd31c7d00Ca47653c6Ce64Af53c1571f9C36566a#code">staking
        contract</a>. Anybody can call the function, as long as a rebase is due.
        The function is also automatically called when someone stakes some OHM!</p>
        <p><code>rebase()</code> does four things:</p>
        <ol>
        <li>Check if a rebase is due via the <em>current epoch</em> (see below), otherwise
        return.</li>
        <li>Call <code>sOHM.rebase(uint256 profit_, uint epoch_)</code></li>
        <li>Call <code>distributor.distribute()</code> (if <code>distributor</code> != 0)</li>
        <li>Update the current epoch.</li>
        </ol>
        <p>The <em>current epoch</em>, held in the <code>epoch</code> variable tracks the length of the
        epoch, its number, its deadline <code>endBlock</code> (indicating when <code>rebase()</code> can be
        called), and <code>distribute</code> (the amount of sOHM to be distributed during the
        rebase).</p>
        <p>In the first step, we simply check <code>epoch.endBlock &lt;= block.number</code>. If that&#39;s
        alright, we call <code>sOHM.rebase(epoch.distribute, epoch.number)</code>, which works as
        described above.</p>
        <p>Then we (possibly) call <code>distribute()</code> on the <a href="https://etherscan.io/address/0xC58E923bf8A00E4361FE3f4275226a543D7D3ce6#code">distributor
        contract</a>. Here is how the documentation misleadingly describes it:</p>
        <blockquote>
        <p>The distributor contract receives minted OHM from the treasury in order to
        drip-feed rewards to stakers. The reward rate target as of time of writing is
        set to 3500, which translates to 0.35% of total supply, since the reward rate
        is defined in tens of thousands. Note that the reward rate determines the
        rebase rate and that the rebase rate determines the APY. Below are listed
        distributor contracts by version, where the latest version represents the
        currently active contract.</p>
        </blockquote>
        <p>This makes it sound like the distributor is the one that gives out rebasing
        reward. As we&#39;ve seen before, this would be too expensive, and it&#39;s actually
        done by the sOHM contract.</p>
        <p>In reality, the role of the distributor is to send OHM to the staking contract
        in a way that is commensurate with the rebase amount (<code>profit_</code> from above).
        However this mechanism is fully generic and does not encode a direct dependency
        on the staking contract. Let&#39;s see how it works briefly.</p>
        <p>Skipping over the fine details, what <code>distribute()</code> does is distribute OHM
        rewards (minted from the <a href="https://etherscan.io/address/0x31F8Cc382c9898b273eff4e0b7626a6987C846E8#code">Treasury contract</a> via its
        <code>mintRewards(address _recipient, uint _amount)</code> function) to &quot;recipients&quot; which
        are added/removed through the <code>addRecipient</code> and <code>removeRecipient</code> functions.
        These functions are only callable by the <a href="https://etherscan.io/address/0x0cf30dc0d48604a301df8010cdc028c055336b2e#code">policy</a> multisig (which is the current
        value of <code>_policy</code> in the distributor contract). <code>addRecipient</code> also takes an
        individualized reward rate for every recipient.</p>
        <p>If you query the <a href="https://etherscan.io/address/0xeeeb97a127a342656191e0313df33d58d06b2e05/advanced#readContract">latest version of the distributor contract on
        Etherscan</a>, you&#39;ll see that the (latest version of the) staking
        contract is currently the only recipient.</p>
        <p>An important detail about <code>mintRewards</code> is that it will refuse to mint OHM if
        the risk-free USD value of the reserves is inferior to the OHM supply
        (denominated in OHM), effectively setting a lower bound price of 1$ on OHM,
        fully backed by the treasury. Fun fact: <code>mintRewards</code> reverts in that case,
        which means any attempt to trigger further rebases or to stake more OHM will
        revert too. (This could be sidestepped by removing the staking contract as
        distribution recipient, but it would be useless to stake in the absence of
        rebases anyhow.)</p>
        <p>Is the staking <code>profit_</code> connected in any way with the treasury&#39;s reward?
        Actually yes. This is done during step 4 of the rebse, when updating the current
        epoch.</p>
        <p>The <code>distribute</code> field of the epoch is set to the OHM balance of the staking
        contract minus the circulating supply of sOHM (remember the circulating excludes
        the staking contract&#39;s own sOHM balance). This ensures that we can only
        distribute staking rewards if there is more OHM in the staking contract than
        owned by users, guaranteeing that every sOHM can be redeemed for an OHM.</p>
        <p>As a consequence of calling <code>distribute()</code> earlier, this OHM balance of the
        staking contract increased, <code>distribute</code> will be set to the the OHM reward from
        the distributor, and will be distributed as sOHM during the next epoch.</p>
        <p>The distributor contract also has logic handling what it calls &quot;adjustments&quot;
        which are a way to smooth a reward rate transition from the current rate to a
        target rate, with the reward rate being updated incrementally during each epoch
        (when <code>distribute()</code> is called) until the target rate is reached.</p>
        <h3 id="locker">Locker</h3>
        <p>A little mystery lives in the v2 staking contract (the one from Olympus v1.1
        that we are considering here): the notion of &quot;locker&quot;.</p>
        <p>The contract has a function <code>giveLockBonus(uint _amount)</code> which transfers a sOHM
        &quot;bonus&quot; to a &quot;locked staking contract&quot; (the <code>locker</code> contract variable). This
        function is only callable by the locker, which can also ostensibly return the
        bonus via <code>returnLockBonus(uint _amount)</code>.</p>
        <p>The locker does not appear in either the v1 or v3 contract, and is now set to
        the zero address in the v2 contract. My best guess is that it is a crutch used
        to upgrade the Olympus deployment, though I&#39;m not sure how and why.</p>
        <h3 id="sohm-index">sOHM Index</h3>
        <p>If you go to the <a href="https://app.olympusdao.finance">Olympus DAO App</a>, you can see it features the &quot;current
        index&quot; (74 at the time of writing), with the description:</p>
        <blockquote>
        <p>The current index tracks the amount of sOHM accumulated since the beginning of
        staking. Basically, how much sOHM one would have if they staked and held a
        single OHM from day 1.</p>
        </blockquote>
        <p>This notion also appears in the sOHM contract. The index is set once (via
        <code>setIndex(uint _INDEX)</code>), to an initial sOHM amount, which is converted to a gon
        balance and stored internaly as <code>INDEX</code>. (Remember, gon balances do not change
        when rebasing and are used to track fractional ownership of all the sOHM.)</p>
        <p>Calling <code>index()</code> returns the amount of sOHM now controlled by this initial sOHM
        amount, if it was staked at contract inception.</p>
        <p>During the first sOHM contract deployment, the initial <code>INDEX</code> was the gon value
        for 1 sOHM. Each time the sOHM contract is upgraded, the value returned by
        <code>index()</code> needs to carried over as the new <code>INDEX</code> value in the new contract.</p>
        <h2 id="bonding">Bonding</h2>
        <p>The goal of bonding is to sell OHM at a small discount (at least, usually) in
        the form of bonds that vests linearly over a small period of time (currently 5
        days).</p>
        <p>&quot;Linear vesting&quot; means that after one day you can already withdraw 1/5 of the
        OHM, etc (at the time resolution of blocks ~= 13s).</p>
        <p>The bond purchaser makes a small profit, but takes on price risk. More on the
        purpose of bonding in the economic analysis part.</p>
        <p>In &quot;bonds v2&quot;, there is no longer linear vesting. Instead the purchased OHM is
        staked and can be claimed at the end of the period. This increases risk for bond
        holder who can&#39;t dump at least part of their OHM before expiry, but solves the
        problem that the discount rate is actually misleading because the OHM supply
        inflates during the vesting period (by about 3% at the current rebase reward
        rate).</p>
        <p>Bonds are sold for various assets (called <code>principle</code> or sometimes <code>reserve</code> in
        the contracts), which are either stablecoin or OHM-stablecoin LP tokens. There
        is one contract for each asset, instantiated from the <code>BondDepository.sol</code> file.
        For instance:</p>
        <ul>
        <li><a href="https://etherscan.io/address/0x575409F8d77c12B05feD8B455815f0e54797381c#code">DAI Bond Contract</a></li>
        <li><a href="https://etherscan.io/address/0x956c43998316b6a2F21f89a1539f73fB5B78c151#code">OHM/DAI LP Bond Contract</a></li>
        </ul>
        <p>v2 only has a single contract to handle all bonds.</p>
        <p>We&#39;ll look at how bond prices are determined, starting with stablecoins, then
        moving on the more complex pricing of LP tokens, then looking at what the
        bonding process actually does (hint: more inflation!).</p>
        <p>For a given bonding contract, the bond price is computed by the view
        <code>bondPrice()</code> method. There is also the <code>_bondPrice()</code> method, which is the one
        actually called during bond purchases. The difference is that the <code>_bondPrice()</code>
        can modify the minimum bond price, as we&#39;ll see.</p>
        <h3 id="stablecoin-bond-pricing">Stablecoin Bond Pricing</h3>
        <p>First of all, bonds are fractional, i.e. you get a claim on OHM proportional to
        the value of the tokens you use to purchase bonds, without unit limitation.</p>
        <p>This means that &quot;one bond&quot; maps to 1 OHM. However, it can also appear that &quot;one
        bond&quot; maps to 100 OHM because bonds are represented with 2 extra digits of
        precision: the <code>payoutFor(uint _value)</code> function of the depository contract
        divides the value by the bond price, obtaining a number with 36 digits of
        precision, but dividing only by 10^16, hence 100 times more than the expected 18
        digits precision. The reason for the extra precision is that the bond price is
        expressed in risk-free USD with 2 digits precision (though it&#39;s not clear why
        that particular choice was made).</p>
        <p>I must say that dealing with significant digits was by FAR the most tricky and
        painful part of reading the contracts. It almost completly threw me for a loop
        multiple times, and the devs did an horrendous job at documenting the
        assumptions. In fact, I even found what I must assume is a mistake in one of the
        comments.</p>
        <p>The formula to determine the bond price (with two digits precision, so the
        obtained number will be 100x the price) is <code>bondPrice = min(BCV * debtRatio + 100, terms.minimumPrice)</code>, where:</p>
        <ul>
        <li><p><code>BCV</code> is the &quot;bond control variable&quot; (<code>terms.controlVariable</code> in the code).
        This value is tweaked for every principle by the Olympus DAO policy team, and
        can change over time.</p>
        </li>
        <li><p><code>debtRatio</code> is the ratio (in percent) of the total bond debt (the OHM to be
        paid out for bonds still have to vest) over the total OHM supply. It&#39;s a bit
        weird however, because it&#39;s actually a ratio between the &quot;risk-free&quot; value of
        the debt in USD (we&#39;ll explain this in the next section) and the supply in
        OHM! A consequence of this is that the debt ratio increases faster when the
        OHM price is high.</p>
        <p>The debt ratio can be obtained by calling <code>debtRatio()</code> which returns the
        ratio with 9 significant digits of precision (so 1B = 100%). This debt ratio
        is different for each bond contract (i.e. for each token).</p>
        </li>
        <li><p><code>terms.minimumPrice</code> is a minimum price for the bonds. This is useful as
        otherwise the first bond sales would be done at a very steep discount, as
        <code>debtRatio</code> is effectively 0. The minimum price is <strong>only</strong> intended for this
        ramp-up: the first time the price exceeds the minimum price in <code>_bondPrice</code>,
        <code>terms.minimumPrice</code> is set to 0.</p>
        </li>
        </ul>
        <p>As the debt ratio increases, so does the bond price, and vice-versa. This
        automatically throttles the rate of bond emission, and incentivizes bond
        purchase when few bonds are being sold.</p>
        <p>As a side-note, the Olympus DAO glossary defines BCV as follows:</p>
        <blockquote>
        <p>Bond Control Variable, is the scaling factor at which bond prices change. A
        higher BCV means a lower discount for bonders and higher inflation by the
        protocol. A lower BCV means a higher discount for bonders and lower inflation
        by the protocol.</p>
        </blockquote>
        <p>I find this statement frankly puzzling, since you would expect that when the
        discount is higher, more bonds are sold, and so inflation is higher. I think the
        explanation here is that &quot;inflation&quot; doesn&#39;t refer to the increase in supply,
        but to the loss of value: when more bonds are sold, each bond sale tends to
        increase the backing per OHM, which means that OHM will decrease in value more
        slowly. More on this in the economic analysis part.</p>
        <h3 id="liquidity-token-bond-pricing">Liquidity Token Bond Pricing</h3>
        <p>The formula for determining the bond price when purchasing using liquidity
        tokens (with two significant digits) is the same as before: <code>bondPrice = min(BCV * debtRatio + 100, terms.minimumPrice)</code> (see previous sections for
        important details). <strong>This expresses an amount of USD, not an amount of
        liquidity tokens.</strong></p>
        <p>But not so fast! When purchasing bonds using LP tokens, Olympus first converts
        bonds to their risk-free value (RFV) and then only uses this RFV to determine
        the number of bonds purchased.</p>
        <p>The RFV assumes a &quot;worst-case scenario&quot; where 1 OHM is worth 1$. This is a
        worst-case scenario because the <code>mintRewards</code> function of the <a href="https://etherscan.io/address/0x31F8Cc382c9898b273eff4e0b7626a6987C846E8#code">treasury
        contract</a> ensures a minimum backing per OHM of 1$.</p>
        <p>(This computation is slightly sketchy because at 1$ it means OHM is partly
        backed LP tokens whose value is made up in half of OHM valued at 1$. Close
        enough.)</p>
        <p>The RFV is computed by the <code>valueOf(address _token, uint _amount )</code> method of
        the <a href="https://etherscan.io/address/0x31F8Cc382c9898b273eff4e0b7626a6987C846E8#code">treasury contract</a>, both for stablecoins and LP token. For
        stablecoins the RFV value is trivially computed as the amount of stables. For LP
        tokens, the function defers the computation to the <code>valuation(address _pair, uint amount_)</code> function of an instance of the <code>StandardBondingCalculator.sol</code>
        contract (e.g. <a href="https://etherscan.io/address/0xcaaa6a2d4b26067a391e7b7d65c16bb2d5fa571a#code">the instance used by the OHM-DAI contract</a>).</p>
        <p>The formula to compute the RFV of the whole liquidity pool is <code>2 * sqrt(k)</code>,
        where <code>k = ohmInPool * stableInPool</code> (this is the classical <code>x * y = k</code>
        <a href="https://docs.uniswap.org/protocol/V2/concepts/protocol-overview/how-uniswap-works">equation of Uniswap v2 pools</a>).</p>
        <p>This makes sense: at 1$ = 1 OHM, <code>ohmInPool == stableInPool == sqrt(k)</code>, hence
        <code>ohmInPool + stableInPool == 2 * sqrt(k)</code>.</p>
        <p>To compute the RFV of any amount of LP tokens, you simply multiply the liquidity
        pool RFV by the fraction of the pool controlled by the tokens.</p>
        <p>The bonding calculator also has a <code>markdown</code> function which indicates how
        discounted the RFV is compared to the actual price. The actual price for the
        whole pool is the amounts of stable times 2 (since by definition the values of
        one side of the pool equals the value of the other side). Then to get the
        markdown, you divide this by the RFV value of the whole pool.</p>
        <h3 id="bonding-in-depth">Bonding in Depth</h3>
        <p>To purchase a bond, you call the <code>deposit(uint _amount, uint _maxPrice, address _depositor)</code> method of the <code>BondDepository.sol</code> instance of your choice (e.g.
        [the DAI bond contract][dai-bound]).</p>
        <ul>
        <li><code>_amount</code> is the amount of tokens (stable or LP) you&#39;re sending for your
        purchase</li>
        <li><code>maxPrice</code> is the maximum <strong>USD</strong> price (using the decimal precision of your
        stablecoin (*), usually 18) you&#39;re willing to pay per bond. This is intended to
        protect against <a href="https://www.investopedia.com/terms/s/slippage.asp">slippage</a>.</li>
        <li><code>_depositor</code> is the address of the depositor (this is useful in case a
        contract is calling this method on your behalf).</li>
        </ul>
        <p>(*) If purchasing a bond with LP tokens, this will be the precision of
        stablecoin in the pair.</p>
        <p>Here are the various steps taken by the function:</p>
        <ol>
        <li>Verify that the max &quot;debt&quot; is not exceeded, as set by <code>terms.maxDebt</code>.</li>
        <li>Calculate <code>nativePrice</code> ‚Äî the bond price in &quot;risk-free USD&quot;, with two digits
        of precision.</li>
        <li>Calculate <code>priceInUSD</code> ‚Äî the bond price in &quot;market-price USD&quot;, using the
        stablecoin&#39;s decimals.</li>
        <li>Calculate the payout (amount of OHM the bonds can be redeemed for) and the
        DAO fee.</li>
        <li>Call the <code>deposit(uint _amount, address _token, uint _profit)</code> function of
        the <a href="https://etherscan.io/address/0x31F8Cc382c9898b273eff4e0b7626a6987C846E8#code">treasury contract</a> to mint the OHM for the payout and for the
        DAO fee.</li>
        <li>Pay the DAO fee, and perform book-keeping: update bond info, total debt and
        perform adjustments.</li>
        </ol>
        <p>Let&#39;s go over some  these things in more details.</p>
        <h4 id="1-checking-against-the-maximum-debt">1. Checking against the maximum debt</h4>
        <p>The variable <code>terms.maxDebt</code> indicates the maximum allowable debt for the
        contract. Intuitively, the debt is the amount of granted OHM yet to be vested.
        However, <code>terms.maxDebt</code> is denominated in risk-free USD (&quot;RFV USD&quot;) instead.</p>
        <p>First the total debt held in the variable <code>totalDebt</code> is decayed by calling
        <code>debtDecay()</code> removing the value of the tokens that have vested since the last
        time the debt was decayed.</p>
        <p>Decaying it is done on a proportional basis: for instance if 50% of the vesting
        period (so 2.5 days) have passed since the last decay, the <code>totalDebt</code> is split
        in half.</p>
        <p><code>totalDebt</code> is also denominated in RFV USD. As we&#39;ve already mentionned, this
        makes the <code>debtRatio</code> a ratio between a value in RFV USD and OHM, which is
        peculiar, but has the effect of increasing the debt ratio (and hence the bond
        price) faster when the OHM price is high.</p>
        <h4 id="2-calculate-the-bond-price">2. Calculate the bond price</h4>
        <p>As explained earlier, the bond price is computed by using the formula
        <code>rfvBondPrice = BCV * debtRatio + 100</code>, where <code>debtRatio</code> is a whole integer
        representing a percentage (so for 5%, we&#39;d multiply BCV by 5).</p>
        <p>The bond price, held in the variable <code>nativePrice</code> inside the function, is
        denominated in USD, but the RFV of the tokens will be used to &quot;pay&quot; for this
        price. Hence I will say it is denominated in &quot;risk-free USD&quot; or &quot;RFV USD&quot;.</p>
        <p>I will refer to this value as <code>rfvBondPrice</code> to be clearer.</p>
        <p>As we have said earlier, <code>rfvBondPrice</code> is a value with two significant digit
        (instead of the usual 18).</p>
        <h4 id="3-calculate-the-market-value-usd-bond-price">3. Calculate the market-value USD bond price</h4>
        <p>Since <code>rfvBondPrice</code> is a risk-free amount, the function also computes the
        market price of a bond. This will later (see section on boo-keeping) be recorded
        in the bond information.</p>
        <p>Since bond sales affect bond prices, this value ‚Äî as well as the RFV bond price
        ‚Äî will be recomputed later and included in an event called <code>BondPriceChanged</code>.</p>
        <p>For LP bonds, the value is computed as <code>rfvBondPrice * markdown / 100</code> (cf.
        section on LP token pricing for info on the markdown). Here, unlike in many
        other places, I&#39;ve included the <code>/ 100</code> which adjusts the digits. If you&#39;re
        thinking of amounts as real numbers, feel free to ignore it.</p>
        <h4 id="4-calculate-the-payout-and-dao-fee">4. Calculate the payout and DAO fee</h4>
        <p>First, the <code>deposit</code> function (of the bonding depository contract) computes the
        payout, the amount of OHM to grant. This is obtained by computing the RFV value
        of the amount deposited (using the <code>valueOf</code> of the <a href="https://etherscan.io/address/0x31F8Cc382c9898b273eff4e0b7626a6987C846E8#code">treasury
        contract</a>) and dividing this by the bond price.</p>
        <p>The DAO receives an OHM-denominated payout equal to a percentage of the payout,
        set by <code>terms.fee</code>.</p>
        <h4 id="5-mint-ohm-for-payout-and-dao-fee">5. Mint OHM for payout and DAO fee</h4>
        <p>Next, the the <code>deposit(uint _amount, address _token, uint _profit)</code> function of
        the <a href="https://etherscan.io/address/0x31F8Cc382c9898b273eff4e0b7626a6987C846E8#code">treasury contract</a> is called. This function&#39;s purpose is to mint
        OHM for the payout and for the DAO fee.</p>
        <p>The function takes a <code>_profit</code> parameter, which is completely different from the
        rebase &quot;profit&quot; that we talked about before. In this case, the profit is
        computed as <code>profit = rfvValue - payout - fee</code>. The only purpose of this
        <code>_profit</code> is that the treasury <code>deposit</code> function will subtract it from the RFV
        values of the tokens to obtain a <code>_send</code> value: <code>_send = rfValue - profit = payout + fee</code>. This determines the amount of OHM minted to the bond depository
        contract, to be paid to the DAO and to be granted by the emitted bonds. If you
        think it would have been immensely simpler to sent something like <code>_mint = payout + fee</code>... you would be right. It makes very little sense, given for
        instance that <code>rfvValue</code> is denominated in USD while the payout and the fee are
        denominated in OHM.</p>
        <h4 id="6-pay-the-dao-and-perform-book-keeping">6. Pay the DAO and perform book-keeping</h4>
        <p>The book-keeping part is important: this is where we actually record that the
        user is entitled to redeem the payout!</p>
        <p>We also increase the total debt by the RFV value of the tokens supplied. This is
        necessary to check the maximum debt and compute the debt ratio.</p>
        <p>Finally, just like the distributor contract, bond depository contracts have some
        &quot;adjustment&quot; logic, used to smooth a transition in the value of the BCV. Unlike
        the distributor, which adjusts during each rebase epoch, a depository contract
        adjusts during every bond sale, which means changes can be relatively fast if
        many bond sales occur in rapid succession.</p>
        <h3 id="example">Example</h3>
        <p>To make things hopefully a little bit clearer, let&#39;s work through a bonding
        example.</p>
        <p>Let&#39;s assume that</p>
        <ul>
        <li>OHM is worth 70$ (as it was when I wrote this example)</li>
        <li>the OHM-DAI liquidity pool contains 100 OHM (and therefore
        7000 DAI, which we&#39;ll write 7000$ for convenience)</li>
        <li>the ownership of the pool is split accross 100 LP tokens, each of which is
        worth <code>0.01 * 2 * 7000 = 140</code> $</li>
        <li>the current debt ratio for the OHM-DAI bond depository contract is 5%</li>
        <li>the bond control variable (BCV) for the OHM-DAI contract is 207 (as it is at
        the time for writing)</li>
        <li>the (thrice-daily) rebase rate is 0.24% (as it was when I wrote this)</li>
        <li>the DAO fee is 1%. This is currently 0% in both v1 and v2 bonds, and it&#39;s
        particularly difficult to find historical values (you&#39;d have to run your own
        node and re-execute transactions, since value changes are not even logged).</li>
        <li>the RFV backing per OHM is about 26$ (as it was ...)</li>
        <li>the market-value backing per OHM is about 60$ (as it was ...)</li>
        </ul>
        <p>Under these condtions, the risk-free value (RFV) of such a DAI-OHM LP token is
        <code>0.01 * 2 * sqrt(100 * 7000) ~= 16.73</code> $.</p>
        <p>If a user uses a single LP token to purchase bonds, he would get back bonds that
        would grant <code>(16.73 * 100) / (100 + 5 * 207) == 2.32</code> OHM. This represents a
        &quot;premium&quot; of 0.73 OHM compared to the market price, which is equivalent of an
        effective OHM price of <code>140 / 2.32 = 60.34</code> $, or an effective discount rate of
        14% compared to the market price.</p>
        <p>A more realistic discount assessment would also consider that during the vesting
        period of 5 days, the OHM supply will inflate by around 3.7% (<code>1.0024^(3*5) ~= 1.037</code>), so the effective discount is closer to 10%, assuming the buyer redeems
        at the end of the vesting period (of course, Ethereum transaction prices makes
        the amounts we&#39;re discussing completely unreleastic, but whatever).</p>
        <p>We&#39;ll note that v2 bonds solve this issue by staking the granted amount
        immediately, and so there is no loss due to inflation.</p>
        <p>So in this example, 2.343 OHM are emitted (<code>1.01 * 2.32</code> to account for the DAO
        fee), backed by 140$ of market value and 16.73$ of risk-free value (7.14$ per
        OHM).</p>
        <p>In this case, the RFV backing per minted OHM (7.14$) is significantly less than
        the current RFV backing per OHM (which is 26$). This means that each OHM emitted
        in bonding decreases the backing per OHM.</p>
        <p>I&#39;ll discuss this more in the economic analysis part, but this is an inherent
        property of LP bond sales. Stablecoin bond sales, on the other hand, tend to
        increase the RFV backing per OHM.</p>
        <h2 id="coda">Coda</h2>
        <p>That&#39;s it! This ended up much longer than I expected, and also took longer to
        write, but I learned a lot doing the research. I hope you enjoyed the deep dive,
        and learned something!</p>
      ]]>
      </description>
      <pubDate>2022-02-14T16:00:00.000Z</pubDate>
      <link>https://norswap.com/olympus</link>
      <guid isPermaLink="true">https://norswap.com/olympus</guid>
    </item>
    <item>
      <title>The Essence of Blockchains</title>
      <description>
      <![CDATA[
        <p>What are blockchains for? Why are they useful?</p>
        <p><strong>I contend that the essence of blockchain is that they are decentralized trust
        engines.</strong></p>
        <p>Decentralized trust has a lot of benefits, but the one I&#39;m personally excited
        about is that it enables <strong>permissionless innovation</strong>.</p>
        <p>Below I explain what the hell I mean by <em>decentralized trust</em> and
        <em>permissionless innovation</em>.</p>
        <h2 id="who-do-you-trust">Who do you trust?</h2>
        <p>Whenever you perform some action online, you&#39;re always implicitly trusting some
        entity.</p>
        <p>For instance, if you run a computation on Amazon Web Service (AWS), or even in
        Google Sheets, you trust Amazon and Google not to alter the result of the
        computation.</p>
        <p>If you host files on Dropbox, you trust Dropbox not to alter their content, and
        to not arbitrarily destroy your backup.</p>
        <p>You trust that Google won&#39;t return you completely fabricated search result to
        get you to take some specific decision (e.g. a purchase) that is in their
        interest. (They certainly influence search results, but they don&#39;t (yet?)
        fabricate them.)</p>
        <p>You trust that your bank won&#39;t take your money. You trust that your insurer will
        actually compensate you in case of accident.</p>
        <p>You might also trust all of these companies with the privacy of your data.</p>
        <p>Etc, etc...</p>
        <p>You might object that these companies won&#39;t do these shady things. They stand to
        lose a lot, including reputation, customers, future revenues, etc! As for banks
        and insurances, they are heavily regulated.</p>
        <p>That&#39;s true ‚Äî although I will say these companies have gotten away with a
        surprising number of things. But more importantly it means you can only deal
        with entities that either (a) have something to lose or (b) comply with draconic
        and time-consuming regulations ‚Äî and mostly that means big entrenched companies.
        We&#39;ll explore this when we talk about <em>permissionless innovation</em>.</p>
        <p>Also consider that companies might be <em>forced</em> to do something, probably by some
        government.</p>
        <h2 id="decentralized-trust">&quot;Decentralized&quot; trust?</h2>
        <p>The fundamental proposition of blockchains is the following: <strong>What if you did
        not have to trust a single entity, a single company?</strong></p>
        <p>In blockchains, there is a network of <em>nodes</em> (aka <em>verifiers</em>, <em>validators</em>,
        <em>stakers</em>, <em>miners</em>, ...) that verify the operations of the blockchains. As long
        as a majority of these nodes are honest (e.g. 50% of them, this changes between
        blockchains), you can trust that anything that happens on the blockchain follows
        the rules of the blockchain. And dishonesty has dire consequences for validators
        ‚Äî because of sunk costs, or because of explicit penalties.</p>
        <p>This changes your trust assumption from trusting a single entity to trusting
        that a majority of validators are honest.</p>
        <p>The more validators there are, the less collusion is likely. Said otherwise, the
        more decentralized the system is, the less trust you need to put in the system.</p>
        <p>It is also of paramount importance that anyone be able to become a validator of
        the network. Otherwise, the network is really controlled by the gatekeeper of
        the validation rights. This is less easy than it sounds ‚Äî you have to make
        validation costly enough, otherwise an attacker could just spin a huge number of
        nodes and take over the network ‚Äî a <a href="https://en.wikipedia.org/wiki/Sybil_attack">sybil attack</a>. Preventing sybil attacks is
        the main technical breakthrough of blockchain technology. I explain the
        solutions (proof-of-work and proof-of-stake) in my article: <a href="/blockchain-how"><strong>Freaking
        blockchains: How do they work?</strong></a></p>
        <h2 id="applications--trade-offs">Applications &amp; Trade-Offs</h2>
        <p>Let&#39;s go back to our examples. Am I saying that blockchains will supersede AWS,
        Google Sheet, Google Search, Dropbox, banks and insurances?</p>
        <p>Not necessarily.</p>
        <p>In reality, there is a trade-off. Nothing is truly trustless or riskless.
        Running most web apps on AWS is really fine, because the risk that Amazon is
        going to manipulate your results is close to zero, and the downside if they do
        is very low. Even if you&#39;re running with a brand-new competitor, you&#39;re not
        risking all that much.</p>
        <p>But for some applications, trust and security are a really big deal. In
        particular, where money is concerned. It&#39;s not by accident that finance is
        stringently regulated. And similarly, it&#39;s not an accident that most popular
        applications of blockchains right now deal with money. It&#39;s doubly important
        when you&#39;re dealing with anonymous blockchain developers with no pre-existing
        reputation (more on this in the section on permissionless innovation).</p>
        <!--
        
        Since we mentionned Dropbox, I will mention there are a few blockchains
        specialized in storage, like [Arweave] and [Filecoin]. These are very useful if
        censorship is a concern ([example][hong-kong]).
        
        Privacy-wise, blockchains are not there yet, at least for computation. In most
        blockchain, transactions are public! It's already possible the hide the
        transactions using [zero-knowledge proofs][zkp], however the resulting
        blockchain state modification is public. you are only "protected" by the
        pseudonimity of your blockchain address, but that is a weak kind of protection.
        This is a topic of ongoing research.
        
        [Arweave]: https://www.arweave.org/
        [Filecoin]: https://filecoin.io/
        [hong-kong]: https://www.reuters.com/article/us-hongkong-security-apple-daily-blockch-idCAKCN2E00JP
        [zkp]: https://en.wikipedia.org/wiki/Zero-knowledge_proof
        
        -->
        
        <h2 id="permissionless-innovation">Permissionless Innovation</h2>
        <p>Finally, we come to what is to me the most exciting consequence of decentralized
        trust: <em>permissionless innovation</em>.</p>
        <p>On computation-centric blockchains, like <a href="https://ethereum.org/en/">Ethereum</a>,
        the network certifies computation, and the code of the computation is a public
        smart contract stored on the blockchain, you can trust the contract to do what
        its code says, nothing more and nothing less.</p>
        <p>This means that <em>anybody</em> can deploy a new smart contract, and other people can
        use it as long as they trust the code. The contract author does not need to have
        resources, a reputation or even to comply with regulations (1) to deploy his
        contract, or for you to trust that the contract will be executed faithfully.</p>
        <p>(1) He <em>has to</em>, legally speaking, but blockchains being novel, it&#39;s unclear
        which rules apply in the first place. Such <a href="https://en.wikipedia.org/wiki/Fear,_uncertainty,_and_doubt">FUD</a> would normally stifle
        innovation ‚Äî but not on the blockchain where the barrier to entry is low, and
        many developers are anonymous.</p>
        <p>This is super exciting! It has already led to numerous innovations in the
        financial realm, such as <a href="https://www.paradigm.xyz/2021/04/understanding-automated-market-makers-part-1-price-impact/">automated market makers</a> (AMM), as well as many
        new forms of clever incentivization mechanisms such as <a href="https://academy.shrimpy.io/post/what-is-liquidity-mining">liquidity mining</a>,
        <a href="https://www.okex.com/academy/en/olympusdao-protocol-owned-liquidity-defi-reserve-currency-ohm">liquidity purchases via bonding</a>, and more.</p>
        <p>Besides brand new constructions, it also makes opportunities available to
        everyone that were previously available only to a few. Option protocols such as
        <a href="https://docs.lyra.finance/">Lyra</a> make it possible for everyone to profit from market-making the option
        market: a process where the <em>market maker</em> sells an option, which is hedged by
        the underlying, in order to pocket the option premium. (If this is Chinese to
        you, see my articles on <a href="/options/">options</a> and on <a href="/gamestop/">gamma squeezes</a>.) Previously, this
        lucrative and relatively safe opportunity reserved to big investment banks.
        On-chain, everyone can add their money to a pool and participate!</p>
        <p>And this is just an example amongst many. Another one would be <a href="https://medium.com/coinmonks/what-is-liquidation-in-defi-lending-and-borrowing-platforms-3326e0ba8d0">lending to
        overcollateralized borrowers</a>.</p>
        <p>Hopefully, more areas can benefit from this innovative drive besides finance.
        One area that looks promising at the moment is gaming. Increasingly, game
        development is financed by the sales of in-game assets (skins, character
        customizations, convenience features, ...). One could be hesitant to buy into a
        relatively unknown game. Using the blockchain to encode these assets incurs many
        benefits: it can be made certain that they won&#39;t disappear at the whim of the
        developer, that they are tradeable without the developer investing any resources
        to make them so. Even better, another developer could decide to reuse the
        assets, and give them a function within his own game.</p>
        <blockquote>
        <p>I think the use of blockchain in gaming is at the same stage where
        <a href="https://en.wikipedia.org/wiki/Peer-to-peer">peer-to-peer</a> (P2P) technology used to be some 20 years back. P2P had a
        terrible reputation as a thing used only to download copyrighted material. Yet
        only a few years later it became a common way to distribute big games and their
        updates, proving invaluable at handling the load on release day.</p>
        </blockquote>
        <p>Or maybe crypto gaming doesn&#39;t work out. Who knows? There are <strong>many</strong> other
        areas in which people are building on the blockchain at the moment. Most
        projects will fail, but those who succeed might create immense value (I&#39;m
        talking about usefulness, not money), and these wouldn&#39;t have gotten built
        without the blockchain.</p>
        <h2 id="conclusion">Conclusion</h2>
        <p>I&#39;ll simply recap the thesis: blockchain are decentralized trust engines.
        Instead of trusting a single service provider, you trust a majority of the
        validators to be honest ‚Äî and they are incentivized to be.</p>
        <p>On decentralized computation blockchains like Ethereum, this enable anybody to
        deploy a smart contract, and anybody else to trust that the code will be
        executed faithfully (it still requires reading and understanding the code!).</p>
        <p>This enables permissionless innovation: anybody can innovate, not only big
        companies with a reputation, or with government sign-off ‚Äî even when money is
        involved.</p>
        <p>It also enables anybody to port existing constructions to the blockchain, for
        all to take advantage of (e.g. option market-making).</p>
        <p>Hopefully, these innovations will spread outside finance in the future.</p>
        <h2 id="ps">PS</h2>
        <p>The subject seems to be momentous, and here are two excellent recent pieces that
        harp on the value of decentralization:</p>
        <ul>
        <li><a href="https://mnot.github.io/avoiding-internet-centralization/draft-nottingham-avoiding-internet-centralization.html">Avoiding Internet Centralization</a> talks about the importance of
        decentralizing the internet&#39;s infrastructure, but many of its arguments are
        valid arguments against centralization in general. (It also makes clear that
        blockchains aren&#39;t really the solution for low-level internet infrastructure.)</li>
        <li><a href="https://www.chris-granger.com/2021/12/09/is-web3-anything/">Is Web3... anything?</a> is similar to this post and explains
        blockchains as &quot;a protocol/architecture for near-trustless commitments&quot;.</li>
        </ul>
      ]]>
      </description>
      <pubDate>2021-12-10T16:00:00.000Z</pubDate>
      <link>https://norswap.com/essence-blockchains</link>
      <guid isPermaLink="true">https://norswap.com/essence-blockchains</guid>
    </item>
    <item>
      <title>How rollups scale Ethereum</title>
      <description>
      <![CDATA[
        <p>From the <a href="https://hackmd.io/ZJR05zr-SP-tm1D9aqKJaA">overview</a>:</p>
        <blockquote>
        <p>Ethereum&#39;s limited resources, specifically bandwidth, computation, and
        storage, constrain the number of transactions which can be processed on the
        network, leading to extremely high fees. Scaling Ethereum means increasing the
        number of useful transactions the Ethereum network can process, by increasing
        the supply of these limited resources.</p>
        </blockquote>
        <p>But how do rollups increase these resources? To understand this, we first need
        to give some details about layer-1 (L1) Ethereum.</p>
        <h2 id="state-in-l1-ethereum">State in L1 Ethereum</h2>
        <p>The size of the L1 state <a href="https://youtu.be/LjGPCX2V1qk?t=267">as per summer 2021</a> was around 35GB.
        However, during execution, the state needs to be stored in a <a href="https://github.com/norswap/nanoeth/tree/master/src/com/norswap/nanoeth/trees/patricia#readme">Merkle Patricia
        Tree</a> (MPT), which takes the effective stored size to 100GB. This size is
        expected to grow by 50GB per year, assuming the Ethereum <a href="https://ethereum.org/en/developers/docs/gas/#what-is-gas-limit">gas limit</a> stays
        constant. These amounts does not even include historical state, some of which
        <strong>must</strong> be kept to be able to process <a href="https://www.paradigm.xyz/2021/07/ethereum-reorgs-after-the-merge/">chain reorganizations</a>. A node
        must also keep at least some recent block header data.</p>
        <p>Currently, core developers are not increasing the gas limit because we expect
        higher throughput to cause faster state growth.</p>
        <p>Still these numbers are manageable. 4TB SSD drives can be purchased for 400$ or
        less. So why don&#39;t we just increase the gas limit?</p>
        <h2 id="why-not-increase-the-gas-limit">Why not increase the gas limit?</h2>
        <p>There are two reasons. The first is a commitment to keep Ethereum as
        decentralized as possible, which includes making it possible for as many people
        as possible to validate the network. We could increase the gas limit and require
        every validator to spend a few thousand dollars to participate and this wouldn&#39;t
        really decrease the security of the network. However, the same kind of reasoning
        could be repeatedly applied to take us to a situation where you&#39;d need to rent
        in a data center to validate the network. This is extremely undesirable, because
        it would let a small number of majority actors (e.g. staking pools) collude with
        very few people noticing.</p>
        <p>Let me give just one possible scenario. A majority cabal of staking pools could
        claim to run a jointly-developed custom client, which so happened to have a
        &quot;subtle bug&quot; that associates of the pools are able to exploit for profit. The
        few remaining honest actors need to detect and then identify the problem ‚Äî are
        the pools or the other validators correct? The pools could make this
        investigation difficult, and by the time the &quot;bug&quot; surfaces, the chain has moved
        on so far that a fork becomes unthinkable. The pools can maintain plausible
        deniability by claiming this was an innocent bug.</p>
        <p>Like a lot of things in the blockchain space, this is a social problem as much
        as a technical one. One reason more eyes on the chain is better is because it
        can cause more outcry in case of fraud, and give legitimacy to the correct fork.</p>
        <p>The second reason we don&#39;t want to increase the gas limit is <a href="https://www.parity.io/blog/what-is-a-light-client/">light clients</a>.
        Light clients are clients that can validate the network but are not required to
        store the state. Instead they can request the state from the network and
        validate it against state roots stored in recent block headers. Light clients
        allow reducing the reliance on centralized state providers like Infura.</p>
        <blockquote>
        <p><strong>Aside: how light clients work</strong></p>
        <p>A light client needs to start with a trusted block header (either coming from
        an initial sync or trusted source). Let&#39;s assume that this hash is a
        semi-recent block hash, updated each time you use your light-client-enabled
        wallet. Then, the next time you use your wallet, you need to get all the block
        headers between that trusted header and the current head of the chain. There
        are solutions to validate these headers in both proof-of-work and
        proof-of-stake, but let&#39;s focus on the latter, as it is Ethereum&#39;s future.</p>
        <p>To verify a block header, you&#39;ll need to determine that the block was indeed
        signed by known Ethereum validators (stakers). The validator data is small
        enough that it could be kept locally, or you can request it from the network
        and validate it against the trusted block header.</p>
        <p>Once you&#39;re caught up with the chain (which should be fast unless you haven&#39;t
        opened your wallet in months/years), you can speculatively execute
        transactions locally, or even execute whole new blocks yourself. During these
        executions, you&#39;ll need to request the state from the network, which you can
        again validate against the state Merkle root in the most recent block header.</p>
        <p>This state can even be obtained from a centralized provider. The difference is
        that you do not need to trust him anymore: now you can verify the state
        against block headers, and you run the computations yourself.</p>
        </blockquote>
        <p>Light clients are expected to run on user&#39;s machines (laptops, cell phones) and
        only sporadically (e.g. when using a wallet). Clearly this puts a limit on
        storage, computation and bandwidth. The storage is solved by getting the state
        from the network, but this further constrains bandwidth.</p>
        <p>Increasing the gas limit too much would overwhelm light-client&#39;s ability to
        catch up and keep up with the chain, in terms of bandwidth and computation.</p>
        <p>Finally, light clients help keep Ethereum decentralized by creating more
        validators. Light clients associated with wallets are a formidable deterrent
        because it means these wallets won&#39;t transact on fraudulent chains, even if they
        are supported by a majority of miners/stakers. Vitalik Buterin makes this point
        <a href="https://vitalik.ca/general/2021/05/23/scaling.html#its-crucial-for-blockchain-decentralization-for-regular-users-to-be-able-to-run-a-node">here</a>.</p>
        <h2 id="enter-rollups">Enter Rollups</h2>
        <p>I first want to acknowledge the fact that how rollups scale Ethereum ‚Äî while
        preserving its security guarantees ‚Äî is not as straightforward as it is often
        made out to be.</p>
        <p>The scaling property of rollups falls out from two facts:</p>
        <ol>
        <li>A rollup needs orders of magnitude less validators than L1 to maintain its
        security. As long as a single honest validator does its job, the network will
        remain secure.</li>
        <li>State growth can be spread between multiple independent rollups.</li>
        </ol>
        <p>Let&#39;s look at (1) first. In an <a href="https://vitalik.ca/general/2021/01/05/rollup.html">optimistic rollup</a>, the rollup will be secure if
        there is always a validator that can submit a fraud proof for every detected
        sequencer fraud. Therefore, it is okay to increase the requirements needed to
        run these validators, as long as motivated entities and individuals are able to
        run them. Note also that many entities have a vested interest in running these
        validators, because they derive value from the rollup: data and insight
        providers like Infura, The Graph, Dune Analytics; as well as projects building
        on top of the rollup. Unlike in my &quot;evil staking pools&quot; scenario, a majority of
        bad actors is no longer able to get away with fraud!</p>
        <p>In a <a href="https://vitalik.ca/general/2021/01/05/rollup.html">zk rollup</a>, you do not need validators at all for security (you might need
        them for data availability however, depending on the architecture of the
        rollup), but you need to trust the code of the zk verifier smart contract. While
        no external validators are needed, the requirements on the prover (the zk
        pendant of the sequencer) are extreme, as building the zk proofs is very costly.</p>
        <p>Regarding (2), this lets different validators verify different parts of the
        state, hence not imposing the burden of the extra state of every rollup on every
        validator. Because of (1), we know that it&#39;s okay for each rollup to have many
        less validators than L1. This is also the insight behind <a href="https://ethereum.org/en/eth2/shard-chains/">sharding</a> ‚Äî though in
        this case the reduced validator requirement does not apply and is solved with
        <a href="https://vitalik.ca/general/2021/04/07/sharding.html">random committee selection</a> instead.</p>
        <h2 id="in-summary">In Summary</h2>
        <p>We can&#39;t just raise the gas limit to scale Ethereum, because that would raise
        hardware requirements for validators, and the chain needs to be validated as
        broadly as possible to avoid a collusion of majority actors. It would also
        preclude the introduction of light clients to break our reliance on centralized
        data providers.</p>
        <p>Rollups help scale Ethereum because they require order of magnitude less
        validators than L1 to stay secure (via the use of fraud proofs or zero-knowledge
        proofs), hence the requirements for validators can be increased. Additionally,
        the state growth between multiple rollups that can be validated separately.</p>
      ]]>
      </description>
      <pubDate>2021-12-03T16:00:00.000Z</pubDate>
      <link>https://norswap.com/rollups-scale</link>
      <guid isPermaLink="true">https://norswap.com/rollups-scale</guid>
    </item>
    <item>
      <title>Life Updates</title>
      <description>
      <![CDATA[
        <p>It&#39;s been a crazy year. It was already crazy <a href="/ragged">back in March</a>, but
        against my better judgement, I (thankfully!) doubled down.</p>
        <p>In June, I took a leave from my Job at Oracle to take part in the <a href="https://blog.ethereum.org/2021/05/13/core-dev-apprenticeship/">Ethereum Core
        Developer Apprenticeship</a> for four months. I learned a ton ‚Äî here&#39;s <a href="https://github.com/ethereum-cdap/cohort-zero/blob/main/showcase/norswap.md">a
        recap</a> of what I did there.</p>
        <p>By the end of the program, I was sold, and I joined <a href="https://www.optimism.io/">Optimism</a> to work on
        scaling the Ethereum blockchain. My first task there will be to help <a href="https://github.com/ethereum-optimism/optimistic-specs">specify
        and prototype</a> the new version of the Optimistic Ethereum rollup. It&#39;s
        been a blast so far!</p>
        <p>Expect more content soon, especially blockchain-related. If you hate blockchains
        ‚Äî I&#39;m so sorry.</p>
      ]]>
      </description>
      <pubDate>2021-12-03T16:00:00.000Z</pubDate>
      <link>https://norswap.com/life-updates</link>
      <guid isPermaLink="true">https://norswap.com/life-updates</guid>
    </item>
    <item>
      <title>Reviews 11</title>
      <description>
      <![CDATA[
        <p>Part of the <a href="/reviews">Reviews Series</a>.</p>
        <hr>
        <h2 id="cobra-kai">Cobra Kai</h2>
        <ul>
        <li>TV</li>
        <li>Season 3</li>
        <li>previously: <a href="/reviews-10#cobra-kai">Season 1 &amp; 2</a></li>
        </ul>
        <p>In my review of the first season, I said the show was constantly toeing the line
        of overuse on its narrative ropes. I really enjoyed the third season too, but
        it&#39;s clearly the season where the line gets crossed.</p>
        <p>Rest of the review behind the spoiler tag!</p>
        <details><summary>Click for spoilerful review.</summary>
        
        <p>There&#39;s good and there&#39;s bad in the storylines and character development arcs.</p>
        <p>Last time, I said I would be interested in how they handled Tory and Kreese.
        Tory is very much in the background. Her difficult background is briefly
        glimpsed, but mostly that doesn&#39;t make her more relatable. Instead of being a
        crazy bitch, she&#39;s now a crazy bitch in a difficult situation ‚Äî but that
        happens, and it&#39;s not necessarily bad.</p>
        <p>Kreese gets a lot of attention, in particular through the flashback fleshing his
        background. The issue is it doesn&#39;t work one bit. I reckon the goal of the
        flashback is to explain how Kreese got the way he was. But it doesn&#39;t really.
        Past Kreese is mostly sympathetic and good-hearted. What he goes through doesn&#39;t
        even explain why someone would become angry, bitter, violent, cynical, and
        jaded. They could have pulled that off, but they didn&#39;t. But what they really
        needed to pull off is to explain how he became a sociopath. Of course, people
        don&#39;t really suddenly become sociopaths (barring extremely extravagant plot
        events and/or brain damage), so they would have had a hard time pulliing that
        one off. The result is that the flashbacks have almost zero tie-in to the rest
        of the story (except explaining the origin of the term &quot;Cobra Kai&quot;), which is
        weird. Maybe they&#39;ll continue in the next season, but I&#39;m not confident in their
        ability to salvage the plot line.</p>
        <p>The biggest missed opportunity of the season lies in a character whose storyline
        gets really butchered: Hawk. Since the first season, it&#39;s obvious they are
        setting up a redemption/reconciliation arc between Hawk and Demetri. Compared to
        the other storylines, this one already felt sluggish. But mostly, things move
        along, coming to a head when Hawk breaks Demetri&#39;s arm. This should be the
        breaking point (pun intended) for Hawk. Afterwards, it&#39;s just awkward. I get
        they wanted him to flip in the final battle, but the timing just makes this
        awkward. Triple akward in fact as Demetri immediately welcomes him back (&quot;don&#39;t
        worry for my arm bro!&quot;), robbing the whole thing of its emotional payload. They
        also just push things way too far with Cobra Kai being assholes I think,
        removing a lot of the nuance that made the show great. There&#39;s being an asshole
        and then there&#39;s being a caricature of caricature of an asshole.</p>
        <p>Daniel&#39;s Japanese adventure is meh, and feels like a huge wink. The
        &quot;Daniel-san!!&quot; cliffhanger is so cringe.</p>
        <p>Aisha went MIA, probably for actor&#39;s reasons.</p>
        <p>Robby&#39;s storyline is retarded, plain and simple. His action don&#39;t really add up,
        especially the ending point of &quot;Kreese is cool, he told me to fight ‚Äî never mind
        he just tried to stab you&quot;.</p>
        <p>Okay, so I&#39;m very negative and a bit disappointed ‚Äî but I actually mostly
        enjoyed the thing. I probably couldn&#39;t bring myself to write such a long review
        for a thing I didn&#39;t care about anyway.</p>
        <p>Let&#39;s talk about some good things. Johnny and Miguel&#39;s storyline were pretty
        good. I was pleasantly surprised that the Amy plotline did not feature some
        misunderstanding between Johny &amp; Carmen. Demetri is hilarious as always and
        standing up for himself.</p>
        <p>Can season 4 pull an Attack on Titan and turn this ship around?</p>
        </details>
        
        <hr>
        <h2 id="lupin">Lupin</h2>
        <ul>
        <li>TV show</li>
        <li>Part 1 (6 episodes)</li>
        </ul>
        <p><img src="lupin.jpg" alt=""></p>
        <p>Lupin is the first French TV show I&#39;ve watched in forever. And, oh shock, it&#39;s
        actually pretty good.</p>
        <p>The story centers around Assane Diop (played by the excellent Omar Sy), a
        professional thief. When he was young, his father was framed for a theft he
        didn&#39;t commit ‚Äî something Assane only learns at the start of the season. We then
        follow his struggle against his mighty enemies, in order to get justice for his
        father.</p>
        <p>Assane is inspired and emulates the character of Ars√®ne Lupin ‚Äî the gentleman
        burglar. This leads to a series of clever plans, tricks and deceptions that make
        the show quite entertaining.</p>
        <p>Besides the great story, the show also benefits from the insane charisma of Omar
        Sy, who really sells the character.</p>
        <p>Truly, a pleasure to watch.</p>
        <iframe width="560" height="315" src="https://www.youtube-nocookie.com/embed/ga0iTWXCGa0" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
        
        <hr>
        <h2 id="pragmatic-capitalism">Pragmatic Capitalism</h2>
        <ul>
        <li>Book, by Cullen Roche</li>
        </ul>
        <p>This was a book I enqueued on my read list when I started to learn about
        finance. I have mixed feelings about it.</p>
        <p>The book is mostly concerned with discussing the monetary system, with some
        investment portfolio advice thrown in the middle. This is not capitalism, it&#39;s
        not finance, it&#39;s macro-economics. Fine, but what not what I expected from the
        book.</p>
        <p>The description of the monetary system itself is well-meaning, but falls short
        for me. I&#39;m not quite sure who the intended audience is. Roche keeps emphasizing
        some points ‚Äî common misconceptions that seem to be his pet peeves ‚Äî and to his
        credit that is very clear, though a little preachy. More advanced topics are
        unfortunately not that well-explained and seem to assume some familiarity with
        the system already.</p>
        <p>You can tell Roche means well, but its content would have worked better as a
        series of blog posts. It would be hard to me to recommend it to anyone. It&#39;s too
        long to be an introduction, doesn&#39;t go far enough to be textbook, and doesn&#39;t
        explain the advanced concepts well-enough anyway. The portfolio advice is also
        well-meaning but all the same, I don&#39;t particularly recommend it.</p>
        <p>It&#39;s not a bad book, but I&#39;m not sure what it&#39;s trying to achieve. Meh.</p>
        <hr>
        <h2 id="fff-class-trashhero">FFF-Class Trashhero</h2>
        <ul>
        <li>Webtoon</li>
        <li>up to chapter 86</li>
        </ul>
        <p>Another entry in the leveling genre. In this one, we join the hero (that has
        been summoned to another world to defeat the demon king, nothing unusual) after
        he defats the demon king. However, it turns out that his performance is being
        graded, and he fails, because he actually murdered his party before confronting
        the demon king. So now he has to start all over again.</p>
        <p>Why did he do such a thing? From his point of view, he was being abducted
        against his will, and the people in this fantasy land actually mistreated him
        pretty badly, beating him to toughen him up, having him run nonsensical errands,
        etc.</p>
        <p>The story is fairly comedic in nature, there&#39;s some slapstick humor
        √†-la-<a href="/every-anime/#konosuba">Konosuba!</a>, albeit much less charming. But it sits uneasy between its dark
        premise and the comedic element. The hero&#39;s character is terrible, but the story
        is earnest in telling us that he has good reasons for it ‚Äî he&#39;s not just being
        silly. At the same, the story also depends on its dumb factor. The hero starts
        being evil from the get-go in his second attempt, even as that&#39;s obviously not
        the correct way to succeed.</p>
        <p>At some point, it also veers into a weird over-the-top power trip, and I&#39;m not
        sure how the author will extirpate himself from this mess.</p>
        <p>I enjoyed this, but I would have enjoyed it much more if the comedic element was
        dropped and the premise was left to shine. What could a bitter hero have done to
        try to pass while being subjected to the rules (or break free in other ways, or
        get revenge)? And there are already plenty of elements that could have made that
        good (for instance, how good or bad is it to kill a king to avoid a war?).</p>
        <p>Still, everything before the power trip was engaging enough.</p>
        <hr>
        <h2 id="kill-the-hero">Kill The Hero</h2>
        <ul>
        <li>Webtoon</li>
        <li>up to chapter 53</li>
        </ul>
        <p>A fairly classical leveling-genre entry. The setting is very similar to <a href="/reviews-9/#solo-leveling">Solo
        Leveling</a> (modern-day South Korea, dungeons appear, some people get power, and a
        whole semi-corrupt industry of &quot;heroes&quot; springs up). The twist is that the
        protagonist is also a returnee that was betrayed in his previous life (another
        super common trop of the genre). Hence &quot;kill the hero&quot;, where the &quot;hero&quot; is
        actually this scheming villain that everybody thinks is good. I was hoping the
        title was referring to some story-telling twist or some unusual perspective, but
        not really.</p>
        <p>This one is bog-standard, but indubitably well done.</p>
        <hr>
        <h2 id="the-great-mage-returns-after-4000-years">The Great Mage Returns After 4000 Years</h2>
        <ul>
        <li>Webtoon</li>
        <li>up to chapter 82</li>
        </ul>
        <p>Another &quot;leveling&quot; story that takes some of the basic genre building blocks and
        arranges them in yet another configuration. In this one, a very powerful mage
        (just like in <a href="/reviews-10/#i-am-the-sorcerer-king">I am The Sorcerer King</a>) dies and returns in the future, this
        future is not modern-day South Korea, but instead some kind of medieval fantasy.</p>
        <p>In his previous life, the mage was defeated by a <em>demigod</em>, some kind of
        malevolent super-powerful entity. In his new life, the mage seeks to find out
        what happened to his companions and to take on the demigods.</p>
        <p>The story is a bit more earnest than average, and the tone reminded me of <a href="/reviews-9/#the-beginning-after-the-end">The
        Beginning After The End</a>, which is great since that&#39;s one of the best leveling
        webtoons out there. Recommended.</p>
        <hr>
        <h2 id="your-throne">Your Throne</h2>
        <ul>
        <li>Webtoon</li>
        <li>up to chapter 67</li>
        </ul>
        <p>Finally, a webtoon that&#39;s not about people powering up! This one follows two
        noble lady ‚Äî Medea and Psyche. The cold ruthless Medea was promised to the crown
        prince, before the engagement was broken and he chose to get engaged to the
        sweet innocent Psyche. Medea swears to have revenge and retrieve what is
        rightfully hers. And then a lot of things happen but I don&#39;t want to spoil you.</p>
        <p>This is pretty well done. One criticism I have is that it&#39;s at times a bit
        confusing. Another one is that it departs from the traditional <em>arc</em> format.
        While I applaud initiatives to be less formulaic, arcs are used because they
        work, and this works less well. What would have been arcs in other stories
        instead blend into one another. And I don&#39;t mean this in the positive, &quot;story
        expertly woven&quot; way. Instead, we&#39;re not given the time to breathe, assimilate
        what happened, participate in the protagonist&#39;s happiness, sadness, triumph or
        defeat and instead we&#39;re immediately trust into the next thing.</p>
        <p>I think saying the story doesn&#39;t breathe enough is maybe clearer. As a result,
        it becomes much more emotionally muted than it could be. Its high points don&#39;t
        take you that high, and its low points don&#39;t take you that low. Which is too
        bad, because the story has potential.</p>
        <hr>
        <h2 id="akudama-drive">Akudama Drive</h2>
        <ul>
        <li>Anime</li>
        </ul>
        <p>I watched on the recommendations of a few friends who said it was one of the
        best anime of the Fall 2020 season (this was a particularly dry season for me, I
        don&#39;t think I watched a single other anime from it, excepted giving <a href="/reviews-9/#jujutsu-kaisen">Jujutsu
        Kaisen</a> a try).</p>
        <p>I ended up nonplussed. Like, it&#39;s not bad. It&#39;s not that great either. It&#39;s
        annoying because there are a lot of great things about it. I really dig the
        aesthetic, the character design is top-notch, the animation looks very good, the
        music is quite nice. But the story never really got me invested or even
        interested. The stakes are not that much, character development is meh-meh-meh,
        the ending is unsatisfying.</p>
        <p>I think I&#39;d recommend it if you really dig the outrun/retrowave/neon sci-fi
        aesthetic or if you watch anime for the eye candy. If you&#39;re story-driven, this
        will leave you hungry.</p>
        <hr>
        <h2 id="unordinary">unOrdinary</h2>
        <ul>
        <li>Webtoon</li>
        <li>up to chapter 235</li>
        </ul>
        <p><img src="unordinary.jpg" alt=""></p>
        <p>This one looks straightforward, but I actually found it to be quite weird. In
        this world, most people get a special ability (usually fighting-related ‚Äî I
        appreciated how straightforward they all were), and the strong trample on the
        weak in a very hierarchical society.</p>
        <p>The story follows John, who doesn&#39;t have any ability, as he has a hard time at
        his high school, being unpowered as he is but still rather proud. Many twists
        ensue.</p>
        <p>So what makes this weird? Well, first, the society being depicted is despicable.
        Unrealistically, and unsustainably so, in fact. By the way, fair warning, if you
        don&#39;t want to see kids beat each other meanly and bloodily for 200 chapters, you
        probably shouldn&#39;t read this. There&#39;s bullying on every second panel.</p>
        <p>Still, surprisingly, no one ever dies ‚Äî even after someone uses their head to
        bash some concrete. Nobody ever goes for the eyes somehow. In a world so full of
        bullying, there also isn&#39;t a single mention of suicide. Honestly, the world is
        so bad that you&#39;d expect that to pop up, and also strong people to be murdered
        in their sleep.</p>
        <p>But alright, none of that happens, and to enjoy the story you really got to take
        as a premise that it is the way of that particular world to be like this.</p>
        <p>This has another awkward consequence, which is that almost everyone in the story
        is despicable. Yes, even the main character. There are maybe two main characters
        that are not loathsome, but they were strong and uncaring in a world where you
        can&#39;t walk through two hallways without finding some bullying, which uhhhm ...
        eeeeh. Some people start to improve towards the end, and to the credit of the
        writing, this is done in a subtle way.</p>
        <p>You know what else is strangely lacking in a high-school setting? Nobody seems
        to have the slightest interest in romance and/or sex.</p>
        <p>Webtoons often shy away from these themes, for what I ignorantly assume must be
        weird Korean cultural reasons? Although seeing that K-Drama is a thing, this at
        least makes no sense for romance. Often, there is some romance slapstick, like
        unreciprocated crushes, tsundere moments, and even the occasional lewd event
        where the male MC&#39;s head lands on some woman&#39;s breasts. I really don&#39;t get the
        absence of these themes, which are interesting and complex and inherently
        interesting to us humans. Someone please enlighten me.</p>
        <p>Anyway, unOrdinary doesn&#39;t even have the slapstick. Nobody expresses even a iota
        of romantic intentions or sexual tension. And that&#39;s just weird.</p>
        <p>With all that said, unOrdinary&#39;s story is quite gripping. Despite its characters
        being often (or at least initially) loathsome, it&#39;s a character-driven story and
        the characters <strong>are</strong> well-written. They have clear motivations, personalities,
        and as alluded earlier, there is real character development. The broader story
        is also solid enough that it makes you want to keep reading to know what will
        happen and how the characters will end up being implicated in it.</p>
        <p>I&#39;m conflicted about this one. On the one hand, I found it hard to put down once
        I got started, and there is objectively a lot that it does well on the
        story-telling front. Perhaps my problem with it is a lack of relatability to the
        characters, given the problems with the setting.</p>
        <hr>
        <h2 id="second-life-ranker">Second Life Ranker</h2>
        <ul>
        <li>Webtoon</li>
        <li>up to chapter 84</li>
        </ul>
        <p>Yet another formulaic leveling webtoon. A confusingly-named one at that, since
        in this one, the MC does not return from his previous life, but instead goes by
        the notes left by his deceased brother.</p>
        <p>I don&#39;t have much else to say, it&#39;s fairly classic as an entry, but quite well
        done. You&#39;ll like this if you like the other leveling webtoon, and vice-versa.</p>
        <hr>
        <h2 id="raid">Raid</h2>
        <ul>
        <li>Webtoon</li>
        <li>up to chapter 95</li>
        </ul>
        <p>Yep, another level webtoon! This one is of the Solo Leveling &quot;monster gates
        spawn all over Korea&quot; persuasion, though with less emphasis on RPG mechanics (no
        skill windows!) and less of a fantasy theme (no orcs and goblins and the rest of
        the fantastic bestiary, just plain old demons).</p>
        <p>Aaand, it&#39;s okay. Entertaining, but clearly a notch under <a href="#kill-the-hero">Kill The Hero</a> and
        <a href="#second-life-ranker">Second Life Ranker</a> as far as not-particularly-original entries go.</p>
        <hr>
        <h2 id="castlevania">Castlevania</h2>
        <ul>
        <li>Anime</li>
        <li>Season 4</li>
        <li>Previously: <a href="/reviews-6/#castlevania-all-3-seasons">Seasons 1-3</a></li>
        </ul>
        <p>In its final season, Castelevania keeps being good, but imperfect, but damn
        entertaining.</p>
        <p>Compared to the previous seasons, I feel like this one steps up the game in
        terms of animation. These last few fights are really impressive. On the other
        hand, maybe we didn&#39;t need <strong>quite</strong> that much fighting? When you get 4 fights
        back to back, it kind of undermines their weight.</p>
        <p>Story-wise (and you know I&#39;m a story guy), it&#39;s not bad ‚Äî I was engaged through
        ‚Äî but could have been better. The big conclusion didn&#39;t really feel
        woven/foreshadowed. I expected some big reveal, and I guess there was some
        reveal, but it fell flat.</p>
        <p>For the final season, I also expected some confluence of the storylines. More
        after the spoiler tag.</p>
        <details><summary>Click for spoilers.</summary>
        The Isaac storyline feels unfinished. I really thought it was going somewhere.
        Maybe the spinoff that is reportedly in the works will focus on him?
        
        <p>I also found Lenore&#39;s ending unecessarily melodramatic and unecessary. Most of
        all, it does not feel like a conclusion that the story led into.</p>
        </details>
        
        <p>I&#39;m curious to watch the spinoff.</p>
        <hr>
        <h2 id="overcoming-gravity">Overcoming Gravity</h2>
        <ul>
        <li>Book</li>
        </ul>
        <p>I picked this up as a book about bodyweight exercise. What I got is not what I
        expected.</p>
        <p>The book tells less about bodyweight training than I&#39;d hoped. Sure, there are
        instructions and cues, etc. But it&#39;s relatively terse. You can easily find more
        detailed write-ups on Google, and some good tutorials on YouTube.</p>
        <p>But, on the other hand, it&#39;s an impressive compendium of knowledge of the basic
        factors that affect strength and hypertrophy training, of how to setup a workout
        routine etc. In fact, this occupies most of the first half of the book ‚Äî you
        only get to details on specific bodyweight exercises at around page 300...</p>
        <p>Despite being well-written and interesting, I wouldn&#39;t recommend the book for
        the purpose of creating a routine either. Not unless you have a few years of
        training (and crucially, experimentation with your routines) under your belt
        and/or are coaching other athletes. It&#39;s written in a very encyclopedic style.
        I don&#39;t mean this in a bad way: it&#39;s a presentation of facts. But that means
        that the book does not read linearly. Despite the presence of &quot;stop reading,
        take action&quot; sections, the book offer little opportunity to actually start
        planning a routine until the whole has been read.</p>
        <p>So, it&#39;s not bad, but unless you&#39;re looking for a routine-building reference,
        I&#39;d try other places first.</p>
        <hr>
        <h2 id="trading-volatility">Trading Volatility</h2>
        <ul>
        <li>Book</li>
        </ul>
        <p>Trading Volatility is a book, <a href="https://www.trading-volatility.com/">available online</a> for free about trading
        in volatility-related products, in particular options.</p>
        <p>I started reading the book as parts of my efforts to learn about <a href="/finance">finance</a>. In
        the end, I decided to drop it after the first chapter, as it becomes too
        technical, and not particularly applicable to me.</p>
        <p>A lot of the strategies presented later in the book seem to require stock-based
        hedging, for which you need zero commissions and taxes on stock transactions, as
        well as some way to automate trading (i.e. a broker with an API). I don&#39;t fit
        these conditions. It also discusses instruments that are not readily available
        to the retail trader.</p>
        <p>It does look very interesting however, but I currently have much more useful
        things to learn, so I shelved it.</p>
        <hr>
        <h2 id="tales-of-demons-and-gods">Tales of Demons and Gods</h2>
        <ul>
        <li>Manga</li>
        <li>Up to chapter 348</li>
        </ul>
        <p><img src="tales.jpg" alt=""></p>
        <p>In my quest to find more webtoons in what I&#39;ve dubbed &quot;the leveling genre&quot;, I
        came across <em>Tales of Demons and Gods</em>. The particularity of this one is that
        the original is in Chinese.</p>
        <p>How much of a difference does it make? Some. Clearly the tone and the attitudes
        of the characters are different. It&#39;s still closer to Korean webtoons than to
        anything western I&#39;ve seen however. The tropes of the genre are pretty-well
        respected: in this case there is a reincarnation, growable powers, a magic
        school, world-threatening elements, ... There are few added cultural element,
        e.g. the people grow their &quot;soul power&quot; by &quot;cultivating&quot;, a term I&#39;ve seen
        popped up in other Chinese media (notably <a href="/reviews-6/#mo-dao-zu-shi">Mo Dao Zu
        Shi</a>, which I didn&#39;t enjoy so much).</p>
        <p>As far as the story goes, it&#39;s really long, and it&#39;s pretty decent. Details are
        woven throughout, so it&#39;s not just choppy arc after choppy arc, but you can
        still expect the leveling hustle to take up most of the space compared to the
        intrigue. It might be tiresome after a while ‚Äî this one is definitely not a
        literary masterpiece, but it&#39;s fun enough.</p>
        <hr>
        <h2 id="true-detective">True Detective</h2>
        <ul>
        <li>TV Show</li>
        <li>Season 1</li>
        </ul>
        <p>After hearing so much about it, we finally took the leap and watched the first
        season of true detective. There is a second season, but the characters and story
        are completely different ‚Äî it&#39;s just reusing the same principle. People say it&#39;s
        less good, but since I haven&#39;t seen it, I can&#39;t comment.</p>
        <p>The story revolves around a pair of cops, one of which is new (where have I seen
        that before?) as they investigate a murder steeped in voodoo spiritism.</p>
        <p>What really makes the show is it&#39;s grisly, bleak and oppressive atmosphere. It
        really doesn&#39;t make you want to move to Louisiana where the story takes place.
        The characters are dark and conflicted.</p>
        <p>Putting together this atmosphere in a way that&#39;s interesting and keeps you
        engaged is really the show&#39;s greatest strength. It is a somewhat unique
        experience, I must admit.</p>
        <p>As for the plot itself... it&#39;s decent, I suppose? I kept expecting more twists,
        more reveals, some acceleration of the intrigue, and in the end I was pretty let
        down. I think a great plot would have elevated this from an interesting show to
        a masterpiece.</p>
        <p>Still, as-is, it&#39;s well worth watching. If you&#39;re afraid it&#39;s not your jam, just
        watch the first episode ‚Äî if you don&#39;t like it I doubt it&#39;s worth going any
        further.</p>
        <hr>
        <h2 id="koi-to-yobu-ni-wa-kimochi-warui-kokoimo">Koi to Yobu ni wa Kimochi Warui (Kokoimo)</h2>
        <ul>
        <li>Anime</li>
        </ul>
        <p>We were looking for something more romcom-ish to watch with Sasha and landed on
        kokoimo.</p>
        <p>The dangerous-sounding plot is a young salaryman falling in love with a
        high-school girl, pursuing her as best he can.</p>
        <p>The shows ends being quite inoffensive. It&#39;s decent enough I guess, though I
        lack points of comparison in the genre (which is not my forte). Still I have
        watched it and not hated it. I also didn&#39;t think it was particularly
        interesting.</p>
        <hr>
        <h2 id="that-time-i-got-reincarnated-as-a-slime">That Time I Got Reincarnated as a Slime</h2>
        <div id=slime />
        
        <ul>
        <li>Anime</li>
        <li>Season 2</li>
        <li>Japanese Title: Tensei shitara Slime Datta Ken</li>
        <li>Previously: <a href="/even-more-anime/#that-time-i-got-reincarnated-as-a-slime">Season 1</a></li>
        </ul>
        <p>Most of what I said in my review of season 1 still holds. Slime is enjoyable,
        but never truly great.</p>
        <p>This time around it&#39;s a bit less formulaic, but it&#39;s not really better or worse,
        just different. I&#39;m sure some people will argue it&#39;s worse though, seen as
        entire episodes are dedicated to meetings. There are one or two interesting plot
        developments however.</p>
        <p>In general, if you liked the first season, keep watching.</p>
        <hr>
        <h2 id="boku-no-hero-academia">Boku no Hero Academia</h2>
        <ul>
        <li>Anime</li>
        <li>Season 5</li>
        <li>Previously: <a href="/more-anime/#my-hero-academia">Season 1 &amp; 2</a>, <a href="/even-more-anime/#my-hero-academia-season-3">Season
        3</a>, <a href="/reviews-6/#my-hero-academia-season-4">Season
        4</a></li>
        </ul>
        <p>Hero academia is still good, but it&#39;s again not the strongest season.</p>
        <p>It&#39;s divided in two arcs, the first of which is a &quot;training tournament&quot; that
        feels a little bit filler-ish. It&#39;s not too bad though, there are interesting
        fight strategies etc, but no real stakes (not even in terms of character
        development).</p>
        <p>The second one is much more interesting and revolves around the ligue of
        villains encountering challenges of their own. This could have been amazing, but
        the effect is slightly spoiled by the fact that the treatment is very formulaic.
        At some point, they go through all the key members of the league and they all
        experience some breakthrough one after the other ‚Äî this is a bit ham-fisted an
        tends to pull me out of the story.</p>
        <p>That second arc also reveals some key background elements on some characters.</p>
        <hr>
        <h2 id="to-your-eternity">To Your Eternity</h2>
        <ul>
        <li>Anime</li>
        <li>Japanese Name: Fumetsu no Anata e</li>
        </ul>
        <p>A really nice surprise, and also one that is hard to review without spoiling!</p>
        <p>I&#39;ll say two things:</p>
        <ol>
        <li><p>Watch it if you&#39;re going to watch any anime on this list, it really is good
        enough.</p>
        </li>
        <li><p>The only letdown in the anime is that some patterns repeat again and again,
        and I think it makes the anime less compelling. I was really like &quot;oh come
        on... again?&quot; at some points. This makes the story less compelling than it
        could have been if the arcs were a bit more varied / open-ended.</p>
        </li>
        </ol>
        <hr>
        <h2 id="demon-slayer-mugen-train">Demon Slayer: Mugen Train</h2>
        <ul>
        <li>Anime Movie</li>
        <li>Japanese Title: Kimetsu no Yaiba: Mugen Ressha-hen</li>
        <li>Previously: <a href="/reviews-4/#demon-slayer">Season 1</a></li>
        </ul>
        <p>Following the first season of Demon Slayer, the movie share the same visual
        strengths, and packs an emotional punch too.</p>
        <p>The movie form factor perfectly suits Demon Slayer&#39;s strength. This one is a
        must watch if you like good animation, shonen, or both.</p>
        <p>Interestingly, the showrunners have made the decision to adapt/convert the movie
        into a 7 anime episodes prelude to season 2, which have recently started airing.
        No idea how that will turn out (I won&#39;t watch it), but I expect it&#39;s worth
        seeing it as originally intended, as an unbroken movie.</p>
        <hr>
        <h2 id="james-bond-no-time-to-die">James Bond: No Time To Die</h2>
        <ul>
        <li>Movie</li>
        </ul>
        <p><img src="bond.jpg" alt=""></p>
        <p>The repeatedly-delayed movie if finally out (if you&#39;re reading from the future:
        covid), and it&#39;s pretty good!</p>
        <p>Clocking at 2 hours and 40 minutes, it&#39;s the longest James Bond to date.
        Fortunately, it&#39;s entertaining and time passes rather quickly.</p>
        <p>Daniel Craig does an amazing job as usual, the other characters are pretty good,
        and the plot is decent.</p>
        <p>It&#39;s not perfect however. While Rami Malek makes a very convincing villain, his
        motivations are very much lacking. There isn&#39;t really any rhyme or reason as to
        why he wants to destroy large part of the world. His bionic-eyed henchman
        (apparently called &quot;Primo&quot; though I don&#39;t think that&#39;s mentioned in the movie
        even once) feels like ticking a James-Bond checkbox. He&#39;s not really
        interesting, and fighting him feels like a formality to get rid of as fast as
        possible.</p>
        <p>I was left wondering why the movie was so long. I think there&#39;s simply too much
        fighting ‚Äî most of which is not very good. Bond and his associate mow down vast
        number of redshirts in a way that stretches believability (yes, even by James
        Bond standards). In some scenes, you really feel like Bond should emerge
        completely peppered with bullets, but he&#39;s invariably unscathed.</p>
        <p>The only one that can score on James Bond is Rami Malek&#39;s big villain &quot;Lyutsifer
        Safin&quot; (terrible name, but that&#39;s pretty much James Bond tradition), essentially
        by virtue of plot convenience. Just like the henchman fight, their fight is
        short and not that interesting excepted in its outcome.</p>
        <p>What I came away with was the feeling that director Fukunaga wasn&#39;t really
        skilled not really interested in directing action scenes.</p>
        <p>Interestingly, Fukunaga is the director of <a href="#true-detective-season-1">the first season of True
        Detection</a>, a show with a carefully crafted mood, but
        also not much action and not much plot intricacy. I would say that maps pretty
        well to the strength of this James Bond entry ‚Äî it&#39;s really good a showcasing
        more human and psychological elements. This is something the James Bond
        franchise is historically not so good at, but which has been a hallmark of
        Daniel Craig&#39;s &quot;new&quot; James Bond. The flip side is that the action scenes feel
        like an afterthought and the plot is lackluster.</p>
        <p>All in all, I&#39;d place this entry level with the previous Craig-era hits Casino
        Royale and Skyfall. Thinking on it, I think those actually shared the shame
        strengths and shortcomings: the villain looks the par but is not that convincing
        in his convictions and the plot could be better. Other entries probably do a bit
        better on the action though (especially the end of Skyfall, and the intro
        sequences of Quantum of Solace and Spectre do deserve a mention).</p>
        <p>I wonder if I don&#39;t like the more caricatural James Bond of the past. Mike
        Taylor (whose blog I love) <a href="https://reprog.wordpress.com/category/movies/james-bond/">reviewed the whole franchise</a> and
        <a href="https://reprog.wordpress.com/2012/11/19/james-bond-movies-part-1-sean-connery/">wrote</a> somewhere that <a href="https://en.wikipedia.org/wiki/Goldfinger_(film)">Goldfinger</a> was the prototypal James
        Bond: it has a great villain (gold magnate Auric Goldfinger), a great henchman
        (Oddjob, the steel-hat throwing Korean Oddjob), a memorable plot (irradiate the
        gold reserve at Fort Knox to make Auric&#39;s own gold value skyrocket), <a href="https://www.youtube.com/watch?v=Mx9z99YJ_7s">the best
        dialogue</a>, etc...</p>
        <p>The point being that, if your villains are not going to have interesting
        motivations, you might as well make them larger-than-life charisma machines, and
        not wounded birds with a vaguely formulated desire for revenge as in the
        Craig-era villains. Similar points can be made about other aspects of the
        franchise, but this review is long enough. I&#39;ll just mention that it&#39;s not an
        accident that my favourite Bond is Pierce Brosnan, who never loses his brushing
        even in the most intense action scenes, but offered true spectacle.</p>
        <p>I think in the end I like both types of Bond, but while Bond-as-entertainment
        has been polished to a T, Bond-the-psychological-being is not quite there yet.
        Right now it feels like a <a href="/reviews-10/#casablanca">Casablanca</a> knockoff with a lot of shooting, and I
        think they can do better.</p>
        <p>Final note: the above sounds negative, but I think the movie is pretty good, and
        worth a watch if you enjoyed any other Bond movie with Daniel Craig.</p>
        <hr>
        <h2 id="dune-2021">Dune (2021)</h2>
        <ul>
        <li>Movie</li>
        </ul>
        <p><img src="dune.jpg" alt=""></p>
        <p>I&#39;ve read the books, I&#39;ve seen the <a href="https://en.wikipedia.org/wiki/Dune_(1984_film)">1984 movie</a>, I&#39;ve seen the <a href="https://en.wikipedia.org/wiki/Frank_Herbert%27s_Dune">2000
        miniseries</a>, so I was ready for this one.</p>
        <p>But funnily enough, I didn&#39;t know before watching it that it only adapted half
        of the first book. The movie is pretty long (2h 35min) so the doubt persisted
        for a fairly long time.</p>
        <p>It&#39;s clearly the most beautiful entry to date. Villeneuve knows what he&#39;s doing.
        Dune works better in my opinion than the (equally beautiful and even longer)
        Blade Runner 2049 (which I saw but apparently forgot to review). I will chalk
        that up with the fact that Blade Runner&#39;s worst flaws where to include too much
        crud that didn&#39;t really matter to the plot in the final cut. Here Villeneuve
        works from the book (the screenplay adapts it fairly faithfully).</p>
        <p>It&#39;s a &quot;slow&quot; movie. There is action, but it&#39;s nothing to write home about ‚Äî in
        fact, it&#39;s a little bit disappointing even. Funny how I don&#39;t consider myself an
        action guy but I keep finding the action lacking in things I&#39;m reviewing in this
        entry. Fortunately, action isn&#39;t really the point of Dune as it is James Bond&#39;s.</p>
        <p>Instead, the movie really instills a mood that fits the universe. It&#39;s
        contemplative, but it works.</p>
        <p>I would have liked better to see the first and the second part in a row, since
        this first part doesn&#39;t really peek or culminate anywhere. The story is
        unfinished, and there is not much closure. Still, it was good enough that I&#39;m
        excited to see that second part.</p>
        <hr>
        <h2 id="invincible">Invincible</h2>
        <ul>
        <li>Series (Cartoon)</li>
        </ul>
        <p><img src="invincible.png" alt=""></p>
        <p>What a great surprise! I started watching the Amazon prime series on the
        strength of a raving review from I-forget-where, which was well-deserved.</p>
        <p>It adapts a <a href="https://en.wikipedia.org/wiki/Invincible_(comics)">2003 comic</a> (spoilers!), about a boy acquiring secret powers,
        something that runs in the family.</p>
        <p>The first 30/40 minutes felt like something straight out Spider-Man, it&#39;s all
        very consensual. But then, at the end of the first episode, the proverbial shit
        hits the proverbial fan.</p>
        <p>The show osciliates between the &quot;fun for the whole family&quot; and &quot;grisly murder
        scenes&quot; quite seamlessly. Surprisingly, it works!</p>
        <p>The plot is quite good, with adequate foreshadowing and clues being placed.</p>
        <p>Something I really enjoyed was that each episode encompassed a whole story arc,
        with no stupid cliffhanger at the end. That&#39;s become so rare, it felt like a
        breath of fresh air. And the show can pull it off, it&#39;s good enough you&#39;ll be
        back even without the cliffhanger.</p>
        <p>I&#39;ll be waiting for season 2.</p>
        <hr>
        <h2 id="kaamelott">Kaamelott</h2>
        <ul>
        <li>Movie (French)</li>
        </ul>
        <p>A movie sequel to the super popular French humoristic series <a href="https://en.wikipedia.org/wiki/Kaamelott">Kaamelott</a>, which
        parodies the Arthurian legend.</p>
        <p>I was never a super fan of the series, who made me smile more than it made me
        laugh.</p>
        <p>Still, the movie was greatly entertaining (though again, not something that made
        me roar with laughter the way some other movie can).</p>
        <p>I was particularly admirative of how they managed to still maintain the humor &amp;
        spirit of the series, while still creating an epic narrative with at least some
        amount of emotional weight. It&#39;s a very delicate balancing act, and they nailed
        it.</p>
        <hr>
        <h2 id="oss-117-alerte-rouge-en-afrique-noire">OSS 117: Alerte Rouge en Afrique Noire</h2>
        <ul>
        <li>Movie (French)</li>
        </ul>
        <p>The movie is the sequel to the <a href="https://en.wikipedia.org/wiki/OSS_117:_Cairo,_Nest_of_Spies">2006</a> and <a href="https://en.wikipedia.org/wiki/OSS_117:_Lost_in_Rio">2009</a> entries,
        which follows the spy OSS 117 (played by Jean Dujardin, of internal fame thanks
        to <a href="https://en.wikipedia.org/wiki/The_Artist_(film)">The Artist</a>).</p>
        <p>OSS 117 was a (serious) French James Bond knockoff, but this series uses the
        character to make a French-scented parody of the spy genre.</p>
        <p>I adore the first two movies, which have the unique flair &amp; humor of director
        Michel Hazanavicius. Notably, Hazanavicius also made <a href="https://en.wikipedia.org/wiki/La_Classe_am%C3%A9ricaine">&quot;La Classe
        Am√©ricaine&quot;</a> ‚Äî un &quot;d√©tournement&quot;, i.e. a movie made by dubbing over bits
        and pieces of other movies, which happens to be infinitely quotable. He also
        directed <a href="https://en.wikipedia.org/wiki/The_Artist_(film)">The Artist</a>.</p>
        <p>The humor of the movies is somewhat risqu√©, always at the edge ‚Äî OSS117 being
        overly nationalistic, casually racist and sexist, and generally an idiot with
        surprising talents, that somehow always comes out on top.</p>
        <p>The new entry in the franchise was not directed by Hazanavicius but by Nicolas
        Bedos. I was wary, because I do not know Bedos very well, but did not like his
        personality so much the few times I saw him on TV.</p>
        <p>Nevertheless, I thought the movie was pretty good, and very faithful in spirit
        to the previous entries.</p>
        <p>Bedos is smart enough to switch the playbook slightly however. In this
        installment, the bumbling OSS tries to appear politically correct by clumsily
        hiding his prejudices. This is not easy to make work, but I think they pulled it
        off pretty well. There are also plenty of small absurd elements (e.g. all the
        maps are bonkers) that help make the movie fun.</p>
        <p>One element I didn&#39;t like was the character of the new spy they paired up with
        OSS 117. The issue is that this character acts as a foil, pointing out loud that
        OSS 117 is stupid/prejudiced/etc and really doesn&#39;t know what he&#39;s doing. That&#39;s
        quite unnecessary, it&#39;s already obvious and some of the humor is precisely from
        characters either buying into it or subtly signaling they think he&#39;s an idiot.</p>
        <p>So anyway, a pretty good time.</p>
        <hr>
      ]]>
      </description>
      <pubDate>2021-10-14T16:00:00.000Z</pubDate>
      <link>https://norswap.com/reviews-11</link>
      <guid isPermaLink="true">https://norswap.com/reviews-11</guid>
    </item>
    <item>
      <title>Bonds Bonanza 2: Bonds Go Banana</title>
      <description>
      <![CDATA[
        <p>in <a href="/finance">Finance</a></p>
        <hr>
        <p>In the <a href="/bonds">last post</a> I explained the basics of the bonds market, the
        difference the interest rate and the yield, etc.</p>
        <p>I also mentioned that in February, yields soared from 1.13% to 1.6%, causing a
        large upset in the stock market as well. In this post, I want to look at why
        this happens, and how the effect spilled over to the stock market.</p>
        <p>Be warned that this post is a bit more about figuring things out than presenting
        orderly facts. I&#39;m far from mastering all the variables here, so take everything
        with a grain of salt.</p>
        <h2 id="the-fundamentals">The Fundamentals</h2>
        <p>The basic explanation of why the bond prices dropped precipitously and the yield
        soared is pretty simple: people expect US dollar inflation, meaning rising
        prices, hence a currency with less purchasing power. Inflation does all kinds of
        bad things to the economy (which we will examine shortly) and so the federal
        reserve tries to keep it subdued. It does this mostly by increasing the interest
        rates it pays on newly emitted bonds. This decreases bond prices and increases
        bond yield.</p>
        <p>If it&#39;s not clear to you why the federal reserve increasing the interest rate on
        bonds leads to falling bonds price and thus higher yields, see <a href="/bonds">the previous
        article</a>.</p>
        <p>Remember that government bonds are the ultimate safe investment. Raising the
        interest rate leads to a bunch of other interest rates in the economy to
        increase (for instance, on savings accounts), which promotes savings, which
        reduces the amount of money circulating in the economy. The federal reserve also
        uses the <a href="https://www.investopedia.com/terms/f/federalfundsrate.asp">federal funds rate</a> to achieve this objective. (Sorry if this is not
        very precise. I wish I had a better understanding of the mechanics here.)</p>
        <p>Reducing the amount of money circulating is important, because inflation is
        caused by a changing balance between demand and supply. When there is a lot of
        money chasing few goods, prices increase, and you have inflation. You reduce
        inflation by decreasing the amount of money in circulation, or by increasing the
        amount of good produced.</p>
        <p>People expect inflation, of course, because Joe Biden signed a stimulus bill
        where the government would spend 1.9T$ (that&#39;s trillion). For reference, the
        total market capitalization (summing the value of every share) of the S&amp;P 500 is
        about 30T$. Then there is a 2T$ infrastructure bill being debated right now, and
        there might some more down the line. When you inject so much money in the
        economy, inflation is not exactly unexpected. There is however much debate about
        how high inflation will go, and how transitory or persistent the increase will
        be. The federal reserve currently maintains that the inflation rate might rise
        over 2%, but that this should only be temporary.</p>
        <p>The only uncertainty in all of this is if, or whether <em>when</em>, the federal reserve
        would increase the interest rate in response to inflation increasing. The price
        move caused such an uproar because the federal reserved had been saying (and has
        kept saying since) that they don&#39;t expect to increase the rate anytime soon and
        that it&#39;s fine if &quot;the economy runs hot&quot; and inflation is temporarily increased.
        The bond market seemed to be saying that either the situation would be worse
        than the fed expected, forcing its hand, or that, under pressure from the
        markets, it couldn&#39;t walk the line (as seen in the <a href="https://www.investopedia.com/terms/t/taper-tantrum.asp">2013 &quot;taper
        tantrum&quot;</a>).</p>
        <p>Once the move was initiated, however, it made sense for most people to follow
        suit. Whether you&#39;re a trader or a long-term investor in long-term bonds, you
        expect the rates to increase eventually, meaning it will be profitable for you
        to sell your bonds and buy new higher-rate bonds. If the bond price starts to
        drop, you should therefore sell. In fact, the only reasons not to sell are if
        either you don&#39;t believe the rates will increase or if you&#39;re contractually
        obligated to hold bonds instead of cash.</p>
        <p>But on top of this strong fundamental reason, there were a few other catalysts
        and technical details that can help explain the sudden move.</p>
        <p>A first catalyst (<a href="https://www.bloomberg.com/news/articles/2021-02-26/chaotic-treasury-selloff-fueled-by-50-billion-position-unwind">source</a>):</p>
        <blockquote>
        <p>Back in April, the Federal Reserve tweaked its rules to exempt Treasuries from
        banks‚Äô supplementary leverage ratios ‚Äî allowing them to expand their balance
        sheets with U.S. debt. But that relief ends March 31 and what happens next is
        something of a mystery.</p>
        </blockquote>
        <p>So it was expected that by April 2021, banks would have offloaded excess bonds
        to get back in cash and satisfy the re-tightened rules.</p>
        <h2 id="bonds-butterfly">Bonds Butterfly</h2>
        <p>With all these bearish expectations towards bonds, the market just needed
        something to light the fuse. The catalyst was probably an auction of 7-year
        bonds seeing record low demand. Remember from <a href="/bonds">last time</a> that bonds are
        initially auctioned by the fed, so low demand would have caused these bonds have
        a low price and a high yield. This in turn caused the associated but more common
        5-year bonds to drop a whopping 0.75%.</p>
        <p>This made a lot of people happy, as the <a href="https://finance.zacks.com/butterfly-fixed-income-trading-strategies-10170.html">2-5-10 butterfly</a> is a popular
        trade:</p>
        <blockquote>
        <p>The butterfly strategy involves buying both long and short-term bonds while
        simultaneously selling medium-term bonds. This strategy is designed to help
        investors profit from predicted fluctuations to the yield curve.</p>
        <p>... The purchase and sales cancel each other out, making this a theoretically
        zero-cost investment. This has the impact of cancelling out any shifts in the
        overall values of the bonds unless the shifts are disproportionately weighted
        to one maturity over another. When disproportionate shifts occur, the investor
        can earn a net return. ...</p>
        <p>One common butterfly trade involves three treasury bonds. The investor sells
        five-year treasuries and buys two- and ten-year bonds with the money that he
        receives in a proportion that makes the average life of the portfolio equal to
        five years. To do this, the portfolio would be slightly more heavily weighted
        towards the two-year bond. To begin with, the idea is for the blended yield of
        the two- and ten-year bonds to be higher than the five-year bond&#39;s yield. The
        other advantage of the butterfly is that if the relationship in yields
        changes, it could increase returns.</p>
        </blockquote>
        <p>It must be noted how <a href="https://theirrelevantinvestor.com/2021/03/01/will-higher-interest-rates-kill-growth-stocks/">remarkable</a> these events are:</p>
        <blockquote>
        <p>Tracy Alloway notes that, ‚ÄúThe 2/5/10-year butterfly ‚Äî a popular trade
        involving two-, five- and 10-year U.S. bonds ‚Äî moved by an astonishing 24
        basis points (one of those events which, when measured by standard deviations,
        is only supposed to happen once in a billion years, etc.).‚Äù</p>
        </blockquote>
        <p><img src="butterfly.png" alt="picture: 2-5-10 butterfly expected returns"></p>
        <p>What I assume happened next is that traders unwound their positions to
        capitalize on this sudden dip in the 5-years price. Since they were long
        10-years bonds, that caused that price to also dip suddenly.</p>
        <p>It&#39;s hard ‚Äî if not impossible ‚Äî to tell, but this might have been the initial
        shock that set the yield surge in motion.</p>
        <h2 id="shorting">Shorting</h2>
        <p>Another straightforward force multiplier to the move was short selling. I
        talked about short selling in <a href="/gamestop">my article on Gamestop</a>, but basically
        bond short-sellers borrow bonds, sell them, wait for the price to drop to buy
        them back and return them to the original owner, pocketing the difference as
        profit.</p>
        <p>There was ample evidence of short selling in the bonds market. In particular,
        the repo market rate for the 10-years bond went to -4% at some point... The what
        now?</p>
        <p>The repo or &quot;repurchase agreement&quot; market is where one party sells a security to
        another, and agrees to repurchase it later at a higher price. Essentially, it&#39;s
        a <a href="https://en.wikipedia.org/wiki/Collateral_(finance)">collateralized loan</a>.</p>
        <p>The repo market allows financial institutions that own lots of securities (e.g.
        banks, broker-dealers, hedge funds) to borrow cheaply and allows parties with
        lots of spare cash (e.g. money market mutual funds) to earn a small return on
        that cash without much risk, because securities, often U.S. Treasury securities,
        serve as collateral.</p>
        <blockquote>
        <p>The repo market allows financial institutions that own lots of securities (e.g.
        banks, broker-dealers, hedge funds) to borrow cheaply and allows parties with
        lots of spare cash (e.g. money market mutual funds) to earn a small return on
        that cash without much risk, because securities, often U.S. Treasury securities,
        serve as collateral. (<a href="https://www.brookings.edu/blog/up-front/2020/01/28/what-is-the-repo-market-and-why-does-it-matter/">source</a>)</p>
        <p>The repo rate typically trades in line with the Federal Reserve‚Äôs benchmark
        federal funds rate at which banks lend reserves to each other overnight.</p>
        </blockquote>
        <p>The fact it went to -4% means that people were willing to pay up to 4% interest
        for the privilege to borrow 10 years bonds, with the intention to short them and
        turn a profit. In that market, 4% is a lot, meaning there was a lot of
        competitive pressure, hence a lot of short selling.</p>
        <p>But wait! That&#39;s not all. We have another villain in our story in the form of
        <em>convexity hedging</em>.</p>
        <h2 id="duration-convexity--convexity-hedging">Duration, Convexity &amp; Convexity Hedging</h2>
        <p>Some funds invest in mortgage-backed securities (MBS). Yes, those that caused
        the great financial crisis and gave us the delightful movie <a href="https://www.youtube.com/watch?v=vgqG3ITMv1Q">The Big Short</a>
        ‚Äî check <a href="https://www.youtube.com/watch?v=xbiDrzTd8fE">this excerpt</a> if you want Ryan Gosling to explain bad
        mortgage-backed securities to you. What a time to be alive.</p>
        <p>Anyway, when interest rates decrease, homeowners can refinance their mortgages
        to lock in a lower rate. This involves paying off part of the remaining loan
        immediately (hence it is called <em>prepaying</em>). This shortens the mortgages, and
        as a result the average length of mortgages in the MBS decreases. This causes
        the <em>duration</em> ‚Äî the weighted average of the times until when cash flows (loan
        repayments) are received ‚Äî to go down. The opposite is also true: when interest
        rates increase, people don&#39;t refinance, and so the average length of mortgages
        goes up.</p>
        <p>To explain how that impacts the bond market, we need to lay some groundwork.
        Bonds have a property called <em>convexity</em> ‚Äî when the interest rate decreases, the
        price increases more than proportionally, and vice-versa.</p>
        <p><img src="convexity.png" alt="picture: Illustration of convexity in bond prices"></p>
        <blockquote>
        <p><strong>Reminder:</strong> It&#39;s always been unintuitive to me that bond price should rise
        when interest fall (shouldn&#39;t it be the opposite?). So let&#39;s tackle that
        first, then we can tackle the question of proportionality.</p>
        <p>To key is that the rate increase will only affect newly emitted bonds. The
        yield must be constant across all bonds with the same maturity (otherwise
        it&#39;s an <a href="https://www.investopedia.com/terms/a/arbitrage.asp">arbitrage</a> opportunity). Adding new bonds with lower interest rates
        tends to push the yield down, hence the price of existing bonds up!</p>
        <p>It&#39;s not obvious that it would push the yield down. After all, a lackluster
        auction could bid the new bonds up just enough so that the existing yield
        doesn&#39;t move. It doesn&#39;t seem to work like that in practice, and I suspect
        it&#39;s due to the new bonds shifting the expected future yield. As older,
        higher-interest, bonds expire and newer, lower-interest, bonds are introduced,
        it does make sense to expect the average yield to go down ‚Äî at least when
        ignoring fluctuations in the bond market, and excluding the possibility of a
        sudden paradigm shift in bond valuation.</p>
        </blockquote>
        <p>So decreasing rates push bond price up. Why do they increase more than
        proportionally to the decrease in rates? In one word: compounding ‚Äî when the
        yield moves, the price move must capture not only the change in coupon payments
        but the proceeds of reinvesting these payments. For this reason, longer-term
        bonds are more convex: more interest is being paid. At this point, I&#39;m ready to
        launch in a long, fascinating (uhm) mathematical digression on yields,
        <a href="https://en.wikipedia.org/wiki/Bond_duration">duration</a>, compounding and [present value calculations], but this isn&#39;t really
        the point of this piece. Maybe another time?</p>
        <p>So bonds have <em>convexity</em>. Mortgage-backed securities, on the other hand, have
        <em>negative convexity</em> (not sure why they didn&#39;t call this &quot;concavity&quot;, but
        whatever). This means that as the interest rates fall, the price increase less
        than proportionally, or even fall!</p>
        <p>First, why would the prices go up? Same reason that the bond yields go up (see
        above). Since government bonds are the ultimate risk-free security, most other
        rates in the market depend on them, and will be higher. The difference between
        the yield for a financial product and the risk-free rate (the bond yield) is
        called <em>the risk premium</em>. So if bond yields go up, MBS yields are expected to
        follow suit (at least if we assume that the reason that the yields went up has
        no material impact on the mortgage market and the default rate).</p>
        <p>The reason MBS prices go up less than proportionally (and in any case, less than
        bond prices) is that, as we said at the start of this section, decreased rates
        increase mortgage refinancing, which decreases MBS duration ‚Äî the weighted (by
        monetary amount) average time of received cashflows (loan repayments). More
        refinancing and prepaying means less interest payments, though we will recover a
        larger part of the principal earlier. What the MBS did offer us however was a
        certain yield (based on the mortgage rate). When the duration decrease, we lose
        on that yield, and must reinvest the prepaid sums elsewhere ‚Äî right after the
        interest rates went down! This loss in compound interest is what causes MBS
        prices to rise less than expected.</p>
        <p>So, bonds have convexity, mortgage-backed securities have negative convexity.
        What is convexity hedging? It has to do with the facts that the funds that own
        these MBS include things like pension funds, which have regular cash outflows
        (e.g. to pay said pensions). This means the cashflows need to be regular. But
        MBS cashflows vary with interest rates!</p>
        <p>To take care of that unpredictability, these funds hedge for <em>duration</em>. Here&#39;s
        how they do it: When interest rates increase, MBS duration increases, and funds
        sell long-term bonds to cover liquidity needs; when rates decrease, MBS duration
        decreases, and funds reinvest prepayments into long-term bonds.</p>
        <p>Back to our initial topic, the net effect is that when interest rates increase,
        MBS duration increases, which leads to funds selling off bonds to hedge
        duration. The opposite happens when interest rates decrease. This naturally
        amplifies the movement of bonds in either direction (as the bond price is
        already on the upswing when interest rates decrease).</p>
        <p>And with that, we completed our tour of the plausible reasons for the February
        bond yield surge! Now we need to briefly examinate how this impacted the stock
        market.</p>
        <h2 id="inflation-redux">Inflation Redux</h2>
        <p>Inflation means that money loses value. With inflation, a dollar in a year is
        worth less than a dollar today. In an ideal world of <a href="https://en.wikipedia.org/wiki/Spherical_cow">spherical cows</a>, all
        prices and wages would update instantly to reflect this new value of money.</p>
        <p>If inflation worked like that, it would cause very little trouble. Sure, if
        you&#39;re holding cash, you&#39;re suddenly poorer in terms of purchasing power.
        Conversely, if you&#39;re holding debt, you&#39;re suddenly &quot;richer&quot; because your
        repayments are worth less ‚Äî and your revenues increased proportionally to
        inflation anyway.</p>
        <p>Alas, prices do not update instantly, and it&#39;s precisely this transition process
        that is painful. Inflation works in wave. The first goods whose price increase
        are those whose price is very liquid. The best example is commodities: ores,
        oil, grains, etc. In fact, the <a href="https://www.forbes.com/sites/billconerly/2021/05/22/why-lumber-and-plywood-prices-are-so-high-and-when-they-will-come-down/">flare up in lumber price</a> has been in
        the news quite a bit recently. It&#39;s probably unrelated to inflation, but it
        shows how fast these prices can move.</p>
        <p>Commodities are the very beginning of the supply chains involved in the
        production of most goods. This means that, in the presence of inflation, the
        increase in price slowly cascades through the supply chain. The increase in
        price is not reflected immediately for two big reasons: existing commitments and
        competition. If you already signed a contract to supply a good at a certain
        price, you&#39;re stuck. If you&#39;re in a very dynamic market and you can change your
        price, you might still not want to do so, because your competitors might not
        have done so yet, and you&#39;ll lose customers to them. Of course, they&#39;ll have to
        raise prices too eventually, but these effects slow down the price cascade ‚Äî
        it&#39;s a coordination problem. Where commodities are concerned, there&#39;s also
        uncertainty as though whether a price increase is just a spike (possibly fueled
        by speculation (*1)), or a more permanent shift.</p>
        <p>At the end of the supply chain lies the final customer, the individual.
        Unfortunately, wages are typically the last thing to increase in the inflation
        process. This is because the price increase takes quite some time to reach final
        consumers, and because the profits of a company must increase (after it can
        reflect inflation in the price it charges) before it starts paying employees
        more. And companies will tend to increase pay, if only to get a competitive
        advantage by poaching promising talent.</p>
        <p>(*1) This kind of speculation has, of course, unpleasant side-effects, such as
        making lumber more expensive for those that have a genuine use for it. However,
        I want to emphasize that this is the cost you pay for having an efficient
        market, and an efficient market does buy you something. In particular, it
        greatly reduces the time for inflation to cascade through the system, and hence
        the economic pain that results from it. This is what the next section is all
        about.</p>
        <h2 id="what-inflation-does-to-companies">What inflation does to companies</h2>
        <p>So inflation is a painful transition towards higher prices caused by a loss of
        value of the currency. Inflation occurs when the balance of money and goods
        shifts in the direction of there being more money and/or less goods. In the
        current situation, there is more money in circulation due to stimulus and
        massive public spending (*2), and a modest deficit for goods whose supply
        chains were shut down during the Covid pandemic.</p>
        <p>(*2) At least in the United States, though it seems likely that other parts of
        the world will suffer from, at least, a milder version of the same problem.</p>
        <p>The consequence of this on companies is that they will go through a transition
        period where their expenses will increase, but their revenues do not increase in
        kind.</p>
        <p>What, then, does inflation do to the valuation of companies? We mentioned two
        things already. First, there is an impact on the balance sheet: cash loses
        value, but so do debts. Second, there is a loss of profit due to price lag. In
        some cases, those are straightforward to compute. In some cases not so much. On
        top of this, there is the concern that this will put too much strain on the
        company&#39;s finance, which will have to borrow at unattractive rates or, in the
        worst case, be forced to liquidate.</p>
        <p>So inflation is bad for everyone; but depending on balance sheet composition,
        position within the supply chain and general financial health, it is worse for
        some companies than for other. But wait ‚Äî hasn&#39;t the S&amp;P 500 has been making
        consistent all-time highs since the events of February?!</p>
        <p>Clearly, to understand why growth stock got hammered in February, we need to
        look beyond just the fundamental prices in the growth, and into the theory of
        stock valuation.</p>
        <h2 id="equity-risk-premiums-and-hurdle-rate">Equity Risk Premiums and Hurdle Rate</h2>
        <p>Pricing the stock of a company is more art than science (otherwise they wouldn&#39;t
        constantly be swinging around even when absolutely nothing of substance
        happens). Nevertheless, many theoretical frameworks have been proposed to try to
        explain the factors that underly stock prices, and to try to estimate what a
        &quot;reasonable&quot; stock price may be.</p>
        <p>This is quite the rabbit hole, and if you&#39;re interested, the best place to start
        is Aswath Damodaran&#39;s <a href="https://www.youtube.com/playlist?list=PLUkh9m2BorqlJsEfix7R9jtSXClFZhGvC">valuation course</a>.</p>
        <p>Two concepts that are particularly useful in analyzing the price of stocks are
        the notion of <em>equity risk premium</em> and that of <em>hurdle rate</em>.</p>
        <p>The equity risk premium is the (expected or actual) return on equities in excess
        to that of the risk-free alternatives. Typically, treasury bonds are used as the
        risk-free alternatives, the 10-year rate being the most commonly used. So if
        10-year bonds have a 2% yield, and the stock market (for instance, the S&amp;P 500
        index) returned 12%, then the equity risk premium was 10%. Typically, the equity
        risk premium is calculated on historical data; there is obviously no guarantee
        going into the future.</p>
        <p>That&#39;s the <em>equity risk premium</em>, but the concept of <em>risk premium</em> generalizes
        to other financial asset and even to sub-classes of stock. Of particular
        interest to us here is the risk premium for growth stocks and the risk premium
        for value stocks.</p>
        <blockquote>
        <p>Recall that value stocks are stocks who trade in line with a valuation
        obtained through some kind of <em>fundamental analysis</em> process. The most common
        of which is to use discounted flash flows (DCF): computing the present value
        of the expected net profits of the company for some future period (typically
        10 to 20 years). This approach is of course only applicable to profitable
        companies.</p>
        <p>Growth stocks, on the other hand, are companies whose revenues are growing a
        lot (or are deemed to be poised to grow a lot), but who may not yet be
        profitable. The valuation is based on future expectations of growth ‚Äî which
        may not come to pass and can sometimes be a bit too optimistic.</p>
        </blockquote>
        <p>As the name implies, risk premiums are rewards for risk. Growth stocks are
        riskier than value stocks, and so should command a higher risk premium. But what
        is this &quot;risk&quot; we talk about? Consider that a risk premium is an average
        computed on a basket of stock (or on an index) over a certain period of time.
        Risk can be seen as the variance between the stocks in the basket, and the
        variance over time. Growth stocks, for instance, are particularly risky: most
        innovative companies end up failing, but those who survive tend to have
        extraordinary growth.</p>
        <p>The second important concept is the <em>hurdle rate</em>, which is simply the expected
        return you demand to take on some amount of risk. Everybody will have its own
        hurdle rates for different level of risks, though it tends to depend on possible
        alternative uses of capital and risk-free rates of returns. Just like the risk
        premium, the hurdle rate increases with perceived risk.</p>
        <p>Putting the two concerns together is straightforward. Given a class of assets
        (e.g. growth stocks) and their associated risks, you come up with a hurdle rate
        (the return required to convince you to invest in the asset) and a risk premium
        (the return you expect to earn on top of the risk-free rate). If the total
        expected return for the asset (risk-free rate + risk premium) is higher than the
        hurdle rate, you invest, otherwise you don&#39;t.</p>
        <p>If you want a deeper and more data-driven take on inflation and stock valuation,
        I recommend <a href="http://aswathdamodaran.blogspot.com/2021/03/rates-growth-and-value-investment.html">this article</a> by Aswath Damodaran. I don&#39;t
        pretend to understand all of it, but it makes very interesting points.</p>
        <h2 id="so-what-happened-to-growth-stocks">So what happened to growth stocks?</h2>
        <p>It would be a stretch to say that, as bond yields rose, investors recomputed
        their hurdle rate up (because the risk-free rate was up) and their expected risk
        premium down (because inflation was likely, cutting into profits).</p>
        <p>But on the other hand... Everyone knew that valuations in the growth segment
        were historically high on any metric that you cared to consider. This meant the
        category was particularly risky. Inflation comes in and maybe the risk is now
        too high given the potential rewards. Better to lock in some profit. This is
        essentially the hurdle/premium process, but perceived intuitively.</p>
        <p>At this point, we also have to mention that inflation might be particularly bad
        for the typically non-profitable growth companies, as it impedes their ability
        to raise money. Not only does inflation expectation increase the interest rate
        on debt, but it means that the money you borrow has lost value by the time you
        spend it. Inflation also negatively affects the ability to raise cash via stock
        sales: reflectively from the above, we expect inflation to negatively impact the
        stock price, which mean that less money will be generated by selling (so you
        need to sell more of it, which negatively impacts the stock price, ...).</p>
        <p>As always whenever we talk markets, we have to consider force multipliers and
        momentum. As growth stocks sold off in February, it became clear this that this
        was not a mere fluctuation but a full-blown correction. This causes stockholders
        that had not reacted to the bond market to start selling too, in reaction to the
        price movement, but for the same reasons: the upside of continuing to hold
        longer is limited compared to the immediate risk embedded in the downward trend.</p>
        <p>Big moves in the stock market are also driven by de-leveraging: if you purchased
        stock <a href="https://en.wikipedia.org/wiki/Margin_(finance)">on margin</a>, a sudden price drop forces you to sell stock to maintain your
        <a href="https://www.firstrade.com/content/en-us/education/margin/marginrequirements/">margin requirements</a> and avoid <a href="https://en.wikipedia.org/wiki/Margin_(finance)#Margin_call">margin calls</a>. This is especially relevant
        since margin debt levels are historically high.</p>
        <p><img src="margin-debt.png" alt="picture: Margin debt chart"></p>
        <p>The margin debt level may be in line with the S&amp;P 500 price, but note that you
        would expect the debt ratio to decrease as stock prices go up. If you buy 5k$
        worth of stock at 5:1 leverage (so fronting 1k$ of your own cash, taking a 4k$
        margin debt), and the stock goes up 20%, your stock is now worth 6k$ and your
        leverage ratio is now 3:1 (stock worth 6k$, of which 2k$ is not debt). One
        <em>possible</em> interpretation of the chart is that as stock prices go up investors
        reinvesting the profits with leverage (i.e. they maintain a constant leverage
        ratio). Note that the chart also does not say where the leverage is deployed
        (across the stock market? or is it concentrated in certain stocks?). In the end,
        it seems that leverage will accentuate any &quot;natural&quot; price move, both in the up
        and down directions.</p>
        <h2 id="conclusion">Conclusion</h2>
        <p>So, what happened? What have we learned?</p>
        <p>Bond prices decreases and the yield rose, driven by inflation expectations. A
        series of events catalyzed (the 7-year bond auction) and amplified (the
        butterfly trade, convexity hedging) this change.</p>
        <p>The effect spilled over to the stock market, where it was mostly driven by
        <a href="https://www.investopedia.com/terms/m/marketsentiment.asp">sentiment</a>, reflecting both the increased risk-free rate and the lowered return
        expectations due to inflation. Because growth stocks&#39; valuations were stretched,
        that was all it took to tip this segment of the market into a correction.</p>
        <p>When these events transpired, I did not get how inflation and the bond market
        could influence stock valuation to this extent. In fact, some of my intuitions
        were to the opposite. For instance, since companies will keep making money in
        the future, shouldn&#39;t inflation push the stock price up to reflect the future
        revenue increase due to higher prices?</p>
        <p>I was also looking for a technical explanation (based on some mechanics of the
        financial markets), whereas the move seems to have mostly been driven by
        <a href="https://www.investopedia.com/terms/m/marketsentiment.asp">sentiment</a> and risk-reward considerations. This happened on the heels of the
        <a href="/gamestop">Gamestop gamma squeeze</a>, which had a straightforward technical explanation, so
        there might be some <a href="https://en.wikipedia.org/wiki/Availability_heuristic">availability bias</a> there.</p>
        <hr>
        <p>If you enjoyed this article, you might enjoy other articles about <a href="/finance">finance</a>.</p>
      ]]>
      </description>
      <pubDate>2021-06-05T16:00:00.000Z</pubDate>
      <link>https://norswap.com/bonds-2</link>
      <guid isPermaLink="true">https://norswap.com/bonds-2</guid>
    </item>
    <item>
      <title>Freaking blockchains: How do they work?</title>
      <description>
      <![CDATA[
        <p>in <a href="/finance">Finance</a></p>
        <hr>
        <p>Cryptocurrency hype is at its peak, blockchains are on every lips. Since I
        started writing this, Bitcoin &amp; assorted cryptocurrencies hit multiple all-time
        highs then crashed 50%.</p>
        <p>Besides all the sound and fury, I think I have something interesting and nuanced
        to say about blockchains and cryptocurrencies.</p>
        <p>I also believe that to understand the topic, one has to understand the basics of
        the technology, more precisely than most articles make allowance for.</p>
        <p>Contrary to popular belief, blockchain technology is not that complicated. I
        dare say it&#39;s even quite simple.</p>
        <p>So, in this article I explain the technology. I will tell you what it does, but
        not what the practical applications are, nor whether I think the technology has
        a future, whether it&#39;s a scam, or whether cryptocurrency prices are justified. I
        will, however, tackle all these topics in a follow-up article.</p>
        <h2 id="whats-a-blockchain">What&#39;s a blockchain?</h2>
        <p>A blockchain is a decentralized ledger of transactions. It&#39;s a kind of permanent
        log: once a transaction makes it into the log, it will remain there forever.
        Note that the concept can be extended to log more than financial transactions,
        but we&#39;ll use transactions as an example in this write-up, where users can
        transfer digital coin currency, also called <em>tokens</em>.</p>
        <p>What makes blockchains special is that they are truly decentralized in the sense
        that anybody can join <em>the network</em> that monitors and mirrors the state of the
        blockchain ‚Äî such participants are called <em>nodes</em>. Some nodes additionally
        participate in the consensus process to verify the transactions that make it
        onto the ledger. In the <em>proof-of-work</em> scheme used by Bitcoin, such nodes are
        called <em>miners</em>. And again, everybody can become a miner. We&#39;ll also tackle the
        main alternative, <em>proof-of-stake</em>, later in this article.</p>
        <p>A &quot;blockchain&quot; is called so because the ledger is composed of a chain of
        &quot;blocks&quot;, each of which encodes many transactions. Miners in the network collect
        transactions, verify their validity, pack them in a block, then try to validate
        this block. In proof-of-work, this is calling <em>mining</em> the block (in
        proof-of-stake, it&#39;s simply called <em>proposing</em> or <em>creating</em> the block).
        Whenever a node mines/proposes a block that is accepted by the network, it
        receives a reward.</p>
        <p><a href="blockchain.png" target="_blank"><img src="blockchain.png" alt="proof-of-work overview" /></a></p>
        <p>(Click to open bigger version in a new page. Image source:
        <a href="https://www.bitpanda.com/academy/fr/lecons/comment-fonctionne-une-blockchain/">Bitpanda</a>)</p>
        <blockquote>
        <p>As an aside, a transaction is considered valid if it is signed by the
        cryptographic key associated with the source&#39;s address (a crypto address is a
        little bit like a bank account number), if it&#39;s legal with respect to the
        address&#39; token balance, and if the transaction did not previously appear in
        another block.</p>
        <p>Cases where an address spends the same tokens twice is called a
        <em>double-spend</em>. As we&#39;ll see in a subsequent article, this is the principal
        attack vector against blockchains. This is distinct from duplicating a
        transaction, which might still be legal with respect to balances, but if
        allowed, would allow miners to siphon off the funds from an address that
        previously sent them tokens.</p>
        </blockquote>
        <p>To mine/validate a block, it is not sufficient to create and verify the block ‚Äî
        it must also be accepted as part of the blockchain. This is achieved through a
        consensus protocol.</p>
        <p>In computer science, we call a <a href="https://en.wikipedia.org/wiki/Consensus_(computer_science)">consensus protocol</a> a protocol that lets a set
        of nodes make a decision that is eventually accepted by the whole network. This
        is typically based on some form of majority voting. We also know, to some
        extent, how to guard against malicious nodes who lie to try to get their own
        choice selected.</p>
        <p>However, this only works if the network participants are pre-established. In an
        open network, a malicious actor could just create a huge number of nodes to get
        a de facto majority ‚Äî this is called a <a href="https://en.wikipedia.org/wiki/Sybil_attack">sibyl attack</a>. To tackle this issue,
        blockchains must make it &quot;expensive&quot; to validate blocks. In reality, validation
        must be profitable: that&#39;s the incentive for miners/validators to participate in
        securing the network. But when we say that validation should be &quot;expensive&quot;, we
        mean it must be <em>capital-intensive</em>. Because it costs money to validate blocks,
        it becomes much more difficult to assemble enough mining or staking power to
        mount a sibyl attack.</p>
        <p>In proof-of-work blockchains, miners compete against each other to be the first
        to validate a block. There is a sort of number-guessing contest going on based
        on expensive computations (we&#39;ll explain it shortly), and the winner gets to
        mine the block and collect a reward. Miners buy specialized mining devices to be
        able to run the expensive computations as fast as possible. Statistically
        speaking, if you control X% of the mining power, you&#39;ll get X% of the mining
        rewards.</p>
        <blockquote>
        <p>The &quot;number guessing game&quot; in question is made computationally expensive
        through the use of <em>cryptographic hash functions</em> (details will follow). To
        the best of my knowledge, this is the reason for the <em>crypto</em> in
        <em>cryptocurrencies</em>. It could also refer to the use of cryptographic keys to
        sign transactions, but this is a fairly old technology whose use was already
        pervasive when blockchains were introduced.</p>
        </blockquote>
        <p>In proof-of-stake, validators must lock some amount of on-chain currency (their
        <em>stake</em>). The protocol then selects which validator gets to validate the next
        block. If you control X% of the total stake, you&#39;ll be select with X%
        probability. Note that this is not the only way to implement proof-of-stake, but
        it is the simplest to understand, and it gives the right idea.</p>
        <p>I haven&#39;t mentionned where these rewards come from. In both cases, they&#39;re a
        combination of both currency creation where the miner/validator might be granted
        some amount of newly minted tokens, and transactions fees paid by the users
        whose transactions end up on the block. Bitcoin famously has a supply limit,
        where eventually only transactions fees will remain.</p>
        <p>Currently, most blockchains use proof-of-work, including #1 and #2
        cryptocurrencies Bitcoin and Ethereum. A few minor blockchains use
        proof-of-stake, and Ethereum has planned to transition to proof-of-stake. We
        will now give more details about them, starting with proof-of-work.</p>
        <h2 id="proof-of-work---hashing">Proof of Work - Hashing</h2>
        <p>In proof-of-work, mining is done by solving a cryptographic problem. In
        particular, miners have to calculate a valid hash for the block. You can think
        of a hash as a fingerprint for the block. More precisely, a hash is the result
        of applying a hash function to some data (here, the block). Such a fingerprint
        is really nothing else than a (potentially very large) number, encoded on 256
        bits (which allows to represent 2^256 values, which is 1 followed by 77 zeroes).</p>
        <p>For blockchains, we use a <em>cryptographic hash function</em>. Those have the
        requirement that they should be irreversible (it is impossible to guess the
        block content from the hash), and in general &quot;look random&quot; ‚Äî it&#39;s very important
        that knowing the hash for a block does not give us any advantage in finding the
        hash for a very slightly different block. Finally, a cryptographic function
        should also be somewhat expensive to compute, so that it is difficult to guess
        the data (e.g. the block, or the password) that generated the hash.</p>
        <blockquote>
        <p><strong>Crypto Trivia 1</strong>: Did you know that most websites do not store your password?
        Instead they store a hash of your password. When you login, they hash the
        password you submit, and compare it to the hash they stored. That way, if the
        website is compromised, the attacker only gets the hash of your password.
        Since he can&#39;t invert the hash, your password is safe, and the attacker can&#39;t
        use the hash to log on other websites. ... Or at least that&#39;s what we&#39;d hope.
        In reality, getting the hash makes it easier to guess a password through the
        use of <a href="https://en.wikipedia.org/wiki/Rainbow_table">rainbow tables</a>, which is why the website should hash your password
        along with a <a href="https://en.wikipedia.org/wiki/Salt_(cryptography)">salt</a>.</p>
        </blockquote>
        <blockquote>
        <p><strong>Crypto Trivia 2</strong>: Since the block is much bigger than the hash (in
        Bitcoin&#39;s case, most blocks are 1MB and a hash is 256 bits), it means that
        there can exist many more different blocks than different hashes. This means
        that, by <a href="https://en.wikipedia.org/wiki/Pigeonhole_principle">the pigeonhole principle</a>, it is possible for two blocks to hash to
        the same value. This is fine here, and is fine for most uses of hashing. Just
        note that our &quot;fingerprints&quot; are not necessarily unique. However such a
        collision has a probability of 1/(2 followed by 59 zeros). It&#39;s pretty rare.</p>
        </blockquote>
        <p>So proof-of-work consists of finding the hash of the block. Normally this is an
        easy task. But in blockchains it involves a guessing component. The block&#39;s data
        contains all the transactions, but also a reference to the previous block
        (actually, the <strong>hash</strong> of the previous block) and a random number called
        <em>nonce</em>.</p>
        <p><img src="block-format.png" alt="Bitcoin block format"></p>
        <p>(Image source: <a href="https://blog.scottlogic.com/2016/04/04/jenny-from-the-blockchain.html">Scott Logic</a>)</p>
        <p>The <em>problem</em> proof-of-work has to solve is as follows:</p>
        <pre><code>nonce = random 32 bit number
        h1 = hash(block including nonce)
        h2 = hash(h1 concatenated with nonce)
        ... such that h2 &gt; difficulty
        </code></pre>
        <p>So we pick a nonce and hash the block which contains this nonce. Then we append
        the nonce to this first hash, and hash that to get a second hash. The problem is
        solved only this second hash is higher than a set number, called <em>the
        difficulty</em>. If the condition is not fulfilled, the process starts again with
        another nonce, until the problem is solved or someone else mined a block ‚Äî in
        which case we need to update the previous block&#39;s hash, as well as the list of
        transactions.</p>
        <p>The difficulty is set by the protocol, and determines how difficult it is to
        solve the problem. For instance, Bitcoin adjusts it so that the average time
        between each mined block remains around 10 minutes. Because a hash is a 256-bit
        string, it can be interpreted as a number between 0 and 2^256. So if the
        difficulty was 3/4 * 2^256 and hashes are uniformly distributed (which a
        cryptographic hash function should ensure), this would exclude 3/4 of the valid
        hashes. In reality, the difficulty is much much higher than that. A <a href="https://news.bitcoin.com/clocking-terahash-three-next-generation-bitcoin-mining-rigs-launched-during-the-last-quarter/">bitcoin
        mining machine</a> that can perform about 100 tera-hash per second (*) costs about
        4000$!</p>
        <p>(*) That&#39;s 100 trillion ‚Äî or about 2^47 ‚Äî hashes per second. I&#39;m not sure if
        that number designates actual hash function calls or attempted nonces.</p>
        <blockquote>
        <p><strong>Math Trivia</strong>: Assuming the difficult is indeed 3/4 * 2^256, how many
        nonce would we have to try to find a valid hash, on average?</p>
        <p>You can use <a href="https://math.stackexchange.com/questions/206798/">this formula</a> to answer the question, and the answer
        happens to be approximately 4.</p>
        <p>(Thanks Andrew Gord Stewart for catching a mistake in this section!)</p>
        </blockquote>
        <p>So proof-of-work mining takes a lot of computational power to perform all these
        hashes. This costs a lot of money, both as upfront machine costs and as energy
        costs. This is all by design.</p>
        <p>Now, consuming a lot of energy is not ideal in a world where we&#39;re trying to
        stop global warming. <a href="https://cbeci.org/cbeci/comparisons">At the time of writing</a>, the energy expended
        annually on mining bitcoin is greater than the annual energy expenditure of
        Sweden, and account for 0.6% of the globe&#39;s total energy production. I&#39;ve also
        read that every Ethereum transaction currently consumes enough energy to power
        an average household for 24 hours.</p>
        <p>This can be caveated a little bit by saying that miners are after cheap energy,
        and excess energy is the cheapest energy. It&#39;s also possible for miners to build
        renewable energy plants to power their mining rigs ‚Äî though this also comes with
        an environmental cost.</p>
        <p>The energy consumption <em>might</em> not turn out to be a deal-breaker, but it&#39;s far
        from ideal. That&#39;s one of the issues addressed by <em>proof-of-stake</em>. But first,
        let&#39;s talk about consensus.</p>
        <h2 id="proof-of-work---consensus">Proof of Work - Consensus</h2>
        <p>Okay, so miners compete in a hashing contest and, generally speaking, the first
        miner to find a valid nonce for his block &quot;wins&quot;. Now we need to explain how
        that happen, i.e. how this valid block is disseminated and eventually accepted
        on the network.</p>
        <p>In a simple scenario, the winning miner sends the block to all the other nodes
        he knows. These will verify that the block is valid: all the transactions have
        valid signatures, there are no double-spends, and the hash of the block
        satisfies the difficulty requirement. Once this is done, they further
        disseminate the block, and they append it at the end of their local chain. If
        the node is a miner, he will also restart its mining efforts by creating a new
        candidate block ‚Äî the block he is currently attempting to mine does include the
        hash of a block that is no longer the last in the chain, as well as transactions
        that might have already been included in the block submitted by the winning
        miner.</p>
        <p>At this point, one could have a security question: what prevents miners from
        completely ignoring blocks from their competitors in an attempt to mine their own
        block? There is a neat game-theoretic incentive not to do this: If you assume
        everyone else is honest, they will append this competitor block to their chain.
        That means that even if you manage to mine your alternative block, other nodes
        will reject it because it does not contain the hash of what they consider to be
        the latest block in the chain (the block submitted by your competitor). What if
        everyone cheats? We&#39;ll explain later, but there is no incentive to do this, as
        that makes all the profits go to the biggest miner.</p>
        <p>Let&#39;s tackle the hard case: what if two miners mine a valid block at more or
        less the same time? Only one of the two blocks can win, since they include the
        hash of the same previous block, and their set of transactions might overlap.</p>
        <p>In this case, the rule used by nodes is to always favor the longest chain. Of
        course, initially, the two blocks create two competing chains of equal length.
        Miners will have to decide which block to use as base for the next block they
        will attempt to mine (most likely they will select the block they saw first,
        reasoning that other miners are more likely to also have seen this block first ‚Äî
        though that might not be the case because of network delays). Once a miner comes
        up with a valid block on one of the two chains, that chain gains the upper hand,
        and everyone converges on the same chain. Of course, it&#39;s possible for the
        scenario to repeat and the two chains to grow at about the same time, but this
        is very unlikely and grows more unlikely as the competing chains grow. Remember
        that the Bitcoin protocol adapts so that a new block is mined on average every
        10 minutes: it should be rare for two blocks to be mined mere seconds away from
        one another, and it will be exponentially rarer for that to happen multiple
        times in a row.</p>
        <p>This longest-chain rule is also why it is irrational for miners to just
        ignore other blocks: if everybody mined their own chain, the largest miner would
        always be able to overtake the others with a longer chain, and so all the
        non-mining nodes would converge on that chain.</p>
        <p>The longest-chain rule is not infaillible: if an entity can get control of 51%
        of the mining power, they&#39;re able to mount a <em>51% attack</em> which allows them to
        double spend. We&#39;ll talk about those in details in a subsequent article. Note
        that 51% attacks are at least fairly easy to spot on non-anonymized blockchains
        (which is most of them).</p>
        <p><img src="51attack.png" alt="A 51% attack"></p>
        <p>Above, a schematic representation of a 51% attack, where the attacker conceals
        his mining and then release his blocks all at once to overtake the main chain.
        (source: <a href="https://ethresear.ch/t/timeliness-detectors-and-51-attack-recovery-in-blockchains/6925">Vitalik
        Buterin</a>)</p>
        <h2 id="proof-of-stake">Proof of Stake</h2>
        <p>As we said earlier, proof-of-stake is another scheme to make validating blocks
        capital-intensive enough so that it&#39;s impractical for any single actor to
        dominate the network, and impossible to mount a <a href="https://en.wikipedia.org/wiki/Sybil_attack">sibyl attack</a>.</p>
        <p>In proof-of-work, the hardware and energy costs make mining capital intensive.
        In proof-of-stake, we simply have validators put money on the line directly. And
        because cryptocurrencies are essentially money, that&#39;s rather simple.</p>
        <p>In proof-of-stake, validators engage a certain amount of currency, their
        <em>stake</em>, which becomes locked for as long as they participate in the
        proof-of-stake mechanism.</p>
        <p>The incentive structure is identical to proof-of-work. If you control 10% of the
        mining power, you should validate 10% of the blocks and get 10% of the mining
        rewards. Similarly, if you control 10% of the total stake, you should do 10% of
        the verification work and you should get 10% of the validation rewards. The
        difference is that instead of using a hashing contest, the protocol must
        determine how to distribute rewards to validators according to this
        distribution.</p>
        <p>There are multiple ways to go about this, but the simplest is to use a
        pseudo-random scheme to select the next validator that will create a block. As
        an illustration, imagine that we filled an urn with 100 balls. On each ball the
        name of a validator is written, and each validator gets as many balls as his
        percentage of the total stake (of course in reality we need to accommodate many
        more validators and very fine-grained fractions). Then we use some data from the
        block (we need to make sure validators can&#39;t easily manipulate it), run it
        through a cryptographic hash function, and use the resulting hash to select a
        ball from the urn. The validator whose name is written on the ball gets to
        create the next block, and gets the validation reward.</p>
        <p>That&#39;s not quite enough. Other validators need to cosign on the block, otherwise
        the block&#39;s creator could double-spend, or even include transactions without a
        valid signature. The simplest scheme here is to have all validators verify each
        block, and to require a quorum of agreement (e.g. a simple majority, or a 2/3
        majority) to validate the block. We can&#39;t require consensus, because that would
        open the protocol to <a href="https://en.wikipedia.org/wiki/Denial-of-service_attack">Denial-of-Service (DoS)</a> attacks, and some validators might
        have temporary availability issues. If having every validator vote for every
        block is impractical, we can also form <em>committees</em> to validate individual
        blocks. Care must be taken that the validators are randomized properly and that
        committees are large enough to minimize the probability that all validators in
        the committee are controlled by the same entity. It is commonly required that
        this probability should be infinitesimal for validators controlling about 30% of
        the stake, and ideally up to 50%.</p>
        <p><img src="committees.png" alt="Committees in the Ethereum Beacon Chain"></p>
        <p>Pictured above: committees in the Ethereum beacon chain. Image source:
        <a href="https://ethos.dev/beacon-chain/">ethos.dev</a>.</p>
        <p>There&#39;s another issue: what if the validator designated to create the block
        doesn&#39;t answer? We must avoid stalling the chain in that case. One solution is
        to assign blocks to time slots. If the designated validator does not propose a
        block during its timeslot, the opportunity is lost and another validator gets to
        propose a block that will follow the previous valid block.</p>
        <blockquote>
        <p><strong>Distributed Systems Trivia</strong>: The above is not as easy as it sounds, even if
        we assume that nodes are able to get highly accurate time information outside
        of the blockchain (for instance using the <a href="https://en.wikipedia.org/wiki/Network_Time_Protocol">NTP</a> protocol). This is due to
        network delays, which makes the timeslot boundaries blurry. Some nodes may
        consider a proposed block to be within its timeslot while others may not.
        Therefore, the protocol must take care to handle these boundary conditions so
        that the network always converges. It must also avoid unduly penalizing honest
        actors because of network latency.</p>
        <p>If you want to avoid relying on out-of-chain time information, <a href="https://ethresear.ch/t/network-adjusted-timestamps/4187">things get
        even more difficult</a>.</p>
        </blockquote>
        <p>Nevertheless, we&#39;d like to avoid the scenario where a block is skipped, if only
        for reasons of throughput (how many transactions get validated each second).
        Ethereum proof-of-stake incentivizes validators to be responsive by imposing a
        fine on the stake of absentee validators.</p>
        <p>That&#39;s more or less how proof-of-stake works. Unlike proof-of-work, there is a
        lot of disparity between the various proposed proof-of-stake designs. This
        article offers only a high-level overview, and elides a lot of the details. For
        instance, we didn&#39;t even talk about how stakes can be confiscated (&quot;slashed&quot;)
        when a validator is caught attempting to cheat.</p>
        <p>These missing details are best examined in the light of potential attacks
        against the protocol, which we will examine in a subsequent blog post.</p>
        <h2 id="coda">Coda</h2>
        <p>In this article, I presented an incomplete yet detailed technical overview of
        the proof-of-work and proof-of-stake protocols used to implement most
        blockchains, including the Bitcoin and Ethereum blockchains.</p>
        <p>The most important take-away is that blockchains are distributed ledgers built
        on top of a network that is open to everyone ‚Äî this is their main selling point.
        Because of this, they must guard against <a href="https://en.wikipedia.org/wiki/Sybil_attack">sibyl attacks</a> by making validation
        capital-intensive so that any single actor is unlikely to control a majority of
        the validation capacity. Proof-of-work makes mining capital-intensive by making
        validation computationally expensive, while proof-of-stake has validators put
        money (in the form of crypto tokens) on the line directly. Both methods must
        contend with a series of challenges that involve concerns from distributed
        systems, security, and game theory.</p>
        <p>Stay tuned for further posts. Next post will take a step back and look at the
        potential and applications of blockchain technologies. A subsequent post will
        take a look at the security model and potential attacks against proof-of-work
        and proof-of-stake. See you next time!</p>
        <hr>
        <p>Enjoyed this? Check out <a href="/finance">more finance articles</a>.</p>
      ]]>
      </description>
      <pubDate>2021-05-26T16:00:00.000Z</pubDate>
      <link>https://norswap.com/blockchain-how</link>
      <guid isPermaLink="true">https://norswap.com/blockchain-how</guid>
    </item>
  </channel>
</rss>
