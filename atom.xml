<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:dc="http://purl.org/dc/elements/1.1/">
  <channel>
    <title>norswap</title>
    <description></description>      
    <link>http://norswap.com/</link>
    <atom:link href="http://norswap.com/atom.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>What We (Don&#39;t) Know About Nutrition: Red Meat</title>
      <description>
&lt;p&gt;While I was writing another article related to nutrition (coming out soon), I
found myself plunging rather deep in a particular nutritional rabbit-hole.
Namely: is red meat consumption bad for you?&lt;/p&gt;
&lt;p&gt;The commonly accepted idea is that it is. But as we&amp;#39;ll see, there actually is
little evidence that it is the case.&lt;/p&gt;
&lt;p&gt;I think my investigation of this is an excellent way to demonstrate quite a few
interesting ideas:&lt;/p&gt;
&lt;h4&gt;It&#39;s incredibly difficult to link diet to health outcomes, and the impact
variations in reasonable diets have is fairly small.&lt;/h4&gt;

&lt;p&gt;This was the original point I was trying to make with the red meat litterature
example.&lt;/p&gt;
&lt;p&gt;If you have no egregious nutrient deficiencies and you keep your bodyfat
percentage in check, I believe the impact of nutrition on your long-term health
will be a couple percents (at best) change in the chance to get or not get some
kind of cancer, etc.&lt;/p&gt;
&lt;p&gt;You should also sleep well and do some exercise, but those are
non-nutrition-related.&lt;/p&gt;
&lt;h4&gt;You shouldn&#39;t necessarily trust the consensus in some branches of science (like nutrition).&lt;/h4&gt;

&lt;p&gt;However, that doesn&amp;#39;t mean you should just stick to whatever opinion you had
before, which is probably not based on facts, or merely on anecdote.&lt;/p&gt;
&lt;p&gt;Instead, you should research the topic yourself (preferrably) or find people
whose scientific judgement you trust (not easy, people tend to pick a camp).&lt;/p&gt;
&lt;h4&gt;It&#39;s hard to do good science.&lt;/h4&gt;

&lt;p&gt;Even the published litterature is rife with confounders and bias. And people
forget that correlation doesn&amp;#39;t imply causation.&lt;/p&gt;
&lt;p&gt;There&amp;#39;s also some bad faith going on in some higher instances.&lt;/p&gt;
&lt;p&gt;Bonus: cool Slate Star Codex articles about confounders: &lt;a href=&quot;https://slatestarcodex.com/2014/04/26/stop-confounding-yourself-stop-confounding-yourself/&quot;&gt;one&lt;/a&gt;,
&lt;a href=&quot;https://slatestarcodex.com/2019/06/24/you-need-more-confounders/&quot;&gt;two&lt;/a&gt;.&lt;/p&gt;
&lt;h4&gt;Absence of evidence is evidence of absence.&lt;/h4&gt;

&lt;p&gt;I stole this one from &lt;a href=&quot;https://www.lesswrong.com/posts/mnS2WYLCGJP2kQkRn/absence-of-evidence-is-evidence-of-absence&quot;&gt;LessWrong&lt;/a&gt;, but basically it means that if you try to
find evidence of X (e.g. red meat increases mortality), and you find none or
very little, that&amp;#39;s evidence that X is probably not true.&lt;/p&gt;
&lt;p&gt;And last but not least:&lt;/p&gt;
&lt;h4&gt;Relax, that ribeye steak is probably not going to kill you.&lt;/h4&gt;

&lt;p&gt;So let&amp;#39;s get right into it.&lt;/p&gt;
&lt;h2 id=&quot;anecdotes-and-confounders&quot;&gt;Anecdotes and Confounders&lt;/h2&gt;
&lt;p&gt;It&amp;#39;s easy to find exemples of people who&amp;#39;ve follow a non-conventional diet
(veganism, keto, carnivore) for a long time and seem to be doing quite fine.
It&amp;#39;s also easy to find the opposite, but if you dig, you&amp;#39;ll often find other
factors that can explain adverse health outcomes. The only way to link food and
health outcomes is to do studies with fairly large populations... and to do them
well. Your experience with your zombie-looking vegan neighbour and y our fat
meathead friend don&amp;#39;t prove anything.&lt;/p&gt;
&lt;p&gt;To give an example how studies can go astray, let&amp;#39;s talk about red meat. Red
meat gets a bad rap as a cause of cancer and heart diseases, but no studies has
ever found that red meat &lt;em&gt;causes&lt;/em&gt; those. Instead, quite a few studies have found
that high red meat consumption is &lt;em&gt;correlated&lt;/em&gt; with these issues (and
&lt;a href=&quot;https://en.wikipedia.org/wiki/Correlation_does_not_imply_causation&quot;&gt;correlation does not imply causation&lt;/a&gt;).&lt;/p&gt;
&lt;p&gt;This is still pretty bad... excepted if the study fail to control relevant
variables. The first that they should look for is bodyfat percentage. If you eat
more meat but you also eat more of everything, yes, your health outcomes are
going to look much gloomier, no surprise. Maybe it means you eat less vegetables
and your gut flora suffers, also an issue. Unfortunately, poor control of
confounders is the norm.&lt;/p&gt;
&lt;h2 id=&quot;an-outrageous-guideline&quot;&gt;An Outrageous Guideline&lt;/h2&gt;
&lt;p&gt;Something interesting occurred recently (November 2019). The prestigious &amp;quot;Annals
of Internal Medicine&amp;quot; journal published some &lt;a href=&quot;https://annals.org/aim/fullarticle/2752328/unprocessed-red-meat-processed-meat-consumption-dietary-guideline-recommendations-from&quot;&gt;dietary guidelines&lt;/a&gt; for red meat
consumption:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;The panel suggests that adults continue current unprocessed red meat
consumption (weak recommendation, low-certainty evidence). Similarly, the
panel suggests adults continue current processed meat consumption (weak
recommendation, low-certainty evidence).&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;The panel&amp;#39;s recommendation was based on 5 meta-reviews (more properly
&amp;quot;systematic review and meta-analysis&amp;quot;). Three of those (&lt;a href=&quot;https://annals.org/aim/fullarticle/2752320/red-processed-meat-consumption-risk-all-cause-mortality-cardiometabolic-outcomes&quot;&gt;1&lt;/a&gt;, &lt;a href=&quot;https://annals.org/aim/fullarticle/2752321/reduction-red-processed-meat-intake-cancer-mortality-incidence-systematic-review&quot;&gt;2&lt;/a&gt;,
&lt;a href=&quot;https://annals.org/aim/fullarticle/2752327/patterns-red-processed-meat-consumption-risk-cardiometabolic-cancer-outcomes-systematic&quot;&gt;3&lt;/a&gt;) looked at &amp;quot;observational studies&amp;quot; which study meat consumption in the
context of people&amp;#39;s existing habits. These tend to be highly-confounded, for the
reasons I explained above. In, in fact, the studies were found to be confounded:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Limitation: Inadequate adjustment for known confounders, residual confounding
due to observational design, and recall bias associated with dietary
measurement.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;!-- --&gt;

&lt;blockquote&gt;
&lt;p&gt;Limitations: Limited causal inferences due to residual confounding in observational
studies, risk of bias due to limitations in diet assessment and adjustment for
confounders, recall bias in dietary assessment, and insufficient data for
planned subgroup analyses&lt;/p&gt;
&lt;/blockquote&gt;
&lt;!-- --&gt;

&lt;blockquote&gt;
&lt;p&gt;Limitations: Observational studies are prone to residual confounding, and
these studies provide low- or very-low-certainty evidence according to the
GRADE criteria.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;A &lt;a href=&quot;https://annals.org/aim/fullarticle/2752323/health-related-values-preferences-regarding-meat-consumption-mixed-methods-systematic&quot;&gt;fourth review&lt;/a&gt; just considered people&amp;#39;s preference and concludes they
really like meat, even when faced with potential health consequences.&lt;/p&gt;
&lt;p&gt;The &lt;a href=&quot;https://annals.org/aim/fullarticle/2752326/effect-lower-versus-higher-red-meat-intake-cardiometabolic-cancer-outcomes&quot;&gt;fifth meta-review&lt;/a&gt; (&lt;a href=&quot;https://www.gwern.net/docs/longevity/2019-zeraatkar.pdf&quot;&gt;pdf&lt;/a&gt;) is more interesting, as it reviews
&lt;em&gt;randomized&lt;/em&gt; trials. Instead of observing people&amp;#39;s existing diet, diets are
assigned to people randomly, which reduces confounding with other factors. But
unfortunately, there are very few studies who did this over a long period of
time (which is necessary to assess health outcomes), for ethical reasons. The
conclusion ends being up based on a single study, which found no adverse health
outcomes. Unfortunately, it&amp;#39;s not a low-red-meat study, but a low-fat-diet study
in which the low-fat group ended up consuming less red meat than the control
group: on average 1.4 less &amp;quot;servings&amp;quot; per week, which is not huge.&lt;/p&gt;
&lt;h2 id=&quot;from-ignorance-to-knowledge&quot;&gt;From Ignorance to Knowledge&lt;/h2&gt;
&lt;p&gt;All this may sound silly ‚Äî do we actually know anything?&lt;/p&gt;
&lt;p&gt;Well, yes we do! What this tells us is that there is no blatant evidence (or not
even &lt;em&gt;much&lt;/em&gt; evidence) for the hypothesis that red meat increases mortality.&lt;/p&gt;
&lt;p&gt;From the data we have (and the goal of these studies is to be relatively
comprehensive, including all studies whose data can be exploited which are not
methodologically hopeless), we know that:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;It is highly unlikely that eating more red meat decreases mortality.&lt;/li&gt;
&lt;li&gt;It is unlikely that eating less red meat increases mortality.&lt;/li&gt;
&lt;li&gt;It is highly unlikely that eating more red meat &lt;em&gt;significantly&lt;/em&gt; increases
mortality.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;(1) is already consensus. As for (2), it is certainly &lt;em&gt;possible&lt;/em&gt; that red meat
increases mortality (though (1) is &lt;em&gt;possible&lt;/em&gt; too) but if that were the case,
we&amp;#39;d expect to see much stronger evidence. Regarding (3), even if there is an
increase in mortality, it is unlikely to be high.&lt;/p&gt;
&lt;p&gt;To distinguish (2) and (3), let&amp;#39;s think about them in another way. The paucity
of evidence that we see means that either red meat doesn&amp;#39;t increase mortality at
all (2), or that it does increase mortality, but ever so slightly so that it&amp;#39;s
hard to distinguish the mortality of red-meat-eaters compared to that of
non-red-meat-eaters.&lt;/p&gt;
&lt;p&gt;It&amp;#39;s important to note that we learned something: we went from a state of not
having evidence to a state of having evidence, with the evidence favoring the
null hypothesis: that red meat consumption matters very little.&lt;/p&gt;
&lt;p&gt;If you draw a line representing a continuum of hypotheses, from -100 = &amp;quot;red meat
consumption decreases mortality&amp;quot; to 0 = &amp;quot;red meat consumption doesn&amp;#39;t change
morality&amp;quot; to 100 = &amp;quot;red meat consumption increases mortality, the evidence we
have puts us at around 1.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;                 üëá evidence points here
-100 ---------- 0 ---------- 100
meat üëº      meat ü§∑     meat ‚ò†Ô∏è &lt;/code&gt;&lt;/pre&gt;&lt;h2 id=&quot;controversy-and-the-shills&quot;&gt;Controversy and The Shills&lt;/h2&gt;
&lt;p&gt;The good people at the Harvard School of Public Health weren&amp;#39;t too happy with
the Annals of Internal Medicine&amp;#39;s guidelines, as evidenced by &lt;a href=&quot;https://www.hsph.harvard.edu/nutritionsource/2019/09/30/flawed-guidelines-red-processed-meat/&quot;&gt;this article&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;I should probably warn you, I&amp;#39;m going to say bad things about the good people of
the Harvard School of Public Health.&lt;/p&gt;
&lt;p&gt;In my opinion, their most egregious statement is the following:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;The publication of these studies and the meat guidelines in a major medical
journal is unfortunate because following the new guidelines may potentially
harm individuals‚Äô health, public health, and planetary health. It may also
harm the credibility of nutrition science and erode public trust in scientific
research. In addition, it may lead to further misuse of systematic reviews and
meta-analyses, which could ultimately result in further confusion among the
general public and health professionals.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;You should the (pretty short) article yourself. Essentially it tries to convince
you that these guidelines are &lt;em&gt;a bad thing&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;One of their better argument is that the recommendations are bad because it says
environmental considerations are out of scope. That is a whole other can of
worm, and I personally don&amp;#39;t have an opinion on what the environmental impact of
meat production is. This also veers political. But personally, I&amp;#39;m not very
interested in the recommendation but rather in the question: &amp;quot;Is red meat bad
for your health?&amp;quot;.&lt;/p&gt;
&lt;p&gt;It&amp;#39;s here that Harvard sins, because they try to say that it is bad for your
health. In the Q&amp;amp;A section of the article, they give a mostly accurate and fair
criticism of the meta-reviews. But then they try to spin this by saying that the
meta-reviews show that red meat consumption is bad for you. Except, as we
already said, it shows very very weak evidence of that.&lt;/p&gt;
&lt;p&gt;Let&amp;#39;s update our graph from before:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;                 üëá evidence points here
-100 ---------- 0 ---------- 100
meat üëº      meat ü§∑    | meat ‚ò†Ô∏è 
                       üëÜ
                    where Harvard SPH says the evidence points&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;And that&amp;#39;s why they&amp;#39;re being disingenuous.&lt;/p&gt;
&lt;p&gt;Let&amp;#39;s also plug &lt;a href=&quot;https://old.reddit.com/r/gwern/comments/dbw577/effect_of_lower_versus_higher_red_meat_intake_on/f266lfq/&quot;&gt;the reaction of Gwern Branwern&lt;/a&gt; on that article:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;You don&amp;#39;t see any problem with the Noble Lie? &amp;#39;They should not publish these
results showing our nutrition research is bullshit, because it may justifiably
erode public trust to know that nutrition research is bullshit, and it might
spark further research which would lead to &amp;quot;further confusion&amp;quot; as the bullshit
is further exposed; we don&amp;#39;t think there is any downside to lying to the
public about meat consumption, damaging lifestyles and ignore the possibility
that our own mistaken results are themselves damaging public health but will
pretend it&amp;#39;s a one-sided wager - &amp;quot;heads we win tails meat loses&amp;quot;.&amp;#39;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;By the way, remember I spoke about people whose scientific judgement you trust?
Gwern is someone like that, he has great in-depth research up &lt;a href=&quot;https://www.gwern.net/&quot;&gt;on his
website&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Is Harvard really anti-meat? Well...&lt;/p&gt;
&lt;h2 id=&quot;tmao--the-red-scare&quot;&gt;TMAO &amp;amp; The Red Scare&lt;/h2&gt;
&lt;p&gt;Harvard is a big entity, which is probably not anti-meat as a whole.&lt;/p&gt;
&lt;p&gt;That being said, Harvard Medical School did publish &lt;a href=&quot;https://www.health.harvard.edu/staying-healthy/red-meat-tmao-and-your-heart&quot;&gt;this online article&lt;/a&gt;.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;A substance called trimethylamine N-oxide, which is produced when your body
digests red meat, may raise the risk of cardiovascular problems.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Finally! A causal link from red meat to harm. Hallelujah!&lt;/p&gt;
&lt;p&gt;Well they only reference (and not even link) is to &lt;a href=&quot;https://jamanetwork.com/journals/jama/article-abstract/2734678&quot;&gt;a paywalled editorial&lt;/a&gt;, but
there is actually &lt;a href=&quot;https://academic.oup.com/eurheartj/article-abstract/40/7/583/5232723&quot;&gt;pretty solid research&lt;/a&gt; linking red meat with high TMAO. Case
solved?&lt;/p&gt;
&lt;p&gt;Well no, because the link between TMAO and cardiovascular problems is shaky, see
for instance &lt;a href=&quot;https://www.sciencedirect.com/science/article/abs/pii/S1043276016301448&quot;&gt;this paper&lt;/a&gt; and this &lt;a href=&quot;https://lesslikely.com/nutrition/tmao-mendelian-randomization/&quot;&gt;quite nicely written
article&lt;/a&gt; titled &amp;quot;How TMAO Fooled Us&amp;quot;.&lt;/p&gt;
&lt;p&gt;Apparently, fish increases TMAO even more than red meat, but everyone knows that
fish is healhty! Some people really aren&amp;#39;t bothered by apparent contradictions.&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;Well that&amp;#39;s it for today. I hope this was entertaining/interesting.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Psst, if you&amp;#39;re looking for the conclusions, they&amp;#39;re actually at the &lt;a href=&quot;#&quot;&gt;top&lt;/a&gt;
of the article!&lt;/em&gt;&lt;/p&gt;
      </description>
      <pubDate>2020-01-25T23:00:00.000Z</pubDate>
      <link>http://norswap.com/red-meat</link>
      <guid isPermaLink="true">http://norswap.com/red-meat</guid>
    </item>
    <item>
      <title>Models of Generics and Metaprogramming Article</title>
      <description>
&lt;p&gt;I recently came accross this page:&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://thume.ca/2019/07/14/a-tour-of-metaprogramming-models-for-generics/&quot;&gt;Models of Generics and Metaprogramming: Go, Rust, Swift, D and More&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;It is in a similar vein as the article I wrote earlier on &lt;a href=&quot;/polymorphism&quot;&gt;polymorphism&lt;/a&gt; (though
probably better written). It&amp;#39;s pretty nice, go check it out.&lt;/p&gt;
      </description>
      <pubDate>2019-11-25T23:00:00.000Z</pubDate>
      <link>http://norswap.com/generics-models</link>
      <guid isPermaLink="true">http://norswap.com/generics-models</guid>
    </item>
    <item>
      <title>Wrangling Fitbit&#39;s and Google Sheets&#39; API</title>
      <description>
&lt;p&gt;In my post about &lt;a href=&quot;/weight-training-4/&quot;&gt;my cut phase&lt;/a&gt; I showcased &lt;a href=&quot;https://docs.google.com/spreadsheets/d/1kwGo8YRcEdPJotxaWLlc72pz6YvdU2ymKw_gFa_dKkY/edit?usp=sharing&quot;&gt;the spreadsheet&lt;/a&gt; I used to track my
calorie deficit, my weight, as well as the predicted weight based on the
deficit.&lt;/p&gt;
&lt;p&gt;The big downside of the spreadsheet was having to manually input the value, and
this is something I wanted to automate using Fitbit&amp;#39;s and Google Sheets&amp;#39;
respective APIs.&lt;/p&gt;
&lt;p&gt;This is now done, and I&amp;#39;ve published it as an &lt;a href=&quot;https://observablehq.com/@norswap/fitbit/2&quot;&gt;Observable notebook&lt;/a&gt; (for
posterity&amp;#39;s sake, the code is also &lt;a href=&quot;fitbit_google_sheets.tgz&quot;&gt;archived here&lt;/a&gt;).&lt;/p&gt;
&lt;p&gt;The notebook has some explanations (and full setup instructions) but I&amp;#39;ll give a
few details.&lt;/p&gt;
&lt;p&gt;Basically you specify the ID of a new spreadsheet in the notebook, as well as a
time period of interest, and then you can hit a button that will populate the
spreadsheet with calories in / calories out / weight / caloric surplus or
deficit / smoothed weight.&lt;/p&gt;
&lt;p&gt;I had initially planned for this project to do much more ‚Äî basically recreate
&lt;a href=&quot;https://docs.google.com/spreadsheets/d/1kwGo8YRcEdPJotxaWLlc72pz6YvdU2ymKw_gFa_dKkY/edit?usp=sharing&quot;&gt;the whole spreadsheet&lt;/a&gt;, but I realized this was overkill and
would add a lot of complication.&lt;/p&gt;
&lt;p&gt;One particularly thorny issue is that the app I use to track my weight sometimes
desyncs from Fitbit, and it doesn&amp;#39;t seem possible to sync older measurement
after the fact. These can be added to the sheet manually, but then any logic
that re-creates the sheet must be able to identify &amp;amp; preserve these manually
entered entries!&lt;/p&gt;
&lt;p&gt;Ultimately, this is enough. I can just hit the button and then copy/paste the
entries to the real spreadsheet instead of entering them manually.&lt;/p&gt;
&lt;p&gt;Of course, I spent way more time on building this thing than I would have
manually copying values in the foreseeable future. But I learned things! Namely:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The Google Sheet and Fitbit API&lt;/li&gt;
&lt;li&gt;Implementing a simple OAuth 2.0 flow&lt;/li&gt;
&lt;li&gt;Using Observable notebooks&lt;/li&gt;
&lt;li&gt;Some finer points of Javascript (e.g. how promises relate to &amp;quot;thenables&amp;quot;)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;I found Observable to be particularly interesting. Of course I could have
trivially built the same thing as a local webpage, but Observable makes it
easier to share with people and easier to access from other devices (including
phones). It&amp;#39;s also nice to be able to do good looking literate programming.&lt;/p&gt;
&lt;p&gt;I didn&amp;#39;t really need the spreadsheet-like reactive/update-on-change quality of
Observable, but that&amp;#39;s certainly interesting too.&lt;/p&gt;
      </description>
      <pubDate>2019-11-07T23:00:00.000Z</pubDate>
      <link>http://norswap.com/fitbit-google-sheets</link>
      <guid isPermaLink="true">http://norswap.com/fitbit-google-sheets</guid>
    </item>
    <item>
      <title>Animes, Shows &amp; Movies Reviews 4</title>
      <description>
&lt;p&gt;Previously: Previously: &lt;a href=&quot;/every-anime/&quot;&gt;One&lt;/a&gt; / &lt;a href=&quot;/more-anime/&quot;&gt;Two&lt;/a&gt; / &lt;a href=&quot;/even-more-anime/&quot;&gt;Three&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&quot;parasyte&quot;&gt;Parasyte&lt;/h2&gt;
&lt;p&gt;Parasyte is a semi-recent (2015) anime adapting an old manga (1988-1995). The
fact that the manga is both old and finished (and obviously good enough to
deserve an adaptation so long after the fact) lends the anime a tone I found
quite refreshing when compared to contemporary productions.&lt;/p&gt;
&lt;p&gt;In particular, I enjoyed the maturity of the show, its restraint and subtetly in
how it dealt with its relatively deep themes: empathy, loss, identity, just to
name a few.&lt;/p&gt;
&lt;p&gt;But what is it about? Earth gets invaded by a large handful of worm-like
creatures called &amp;quot;parasytes&amp;quot; ‚Äî these infect human hosts, controlling and
enhancing them in different ways. The protagonist, Shinichi, gets infected but
the parasyte fails to assume control of the brain and a tense co-habitation
ensues.&lt;/p&gt;
&lt;p&gt;This is not a particularly fast-paced anime, but it tells an interesting story
with compelling characters.&lt;/p&gt;
&lt;h2 id=&quot;attack-on-titans-season-3-part-2&quot;&gt;Attack on Titans Season 3 (Part 2)&lt;/h2&gt;
&lt;p&gt;It&amp;#39;s pretty much what I said &lt;a href=&quot;/even-more-anime/#attack-on-titans-season-3-part-1&quot;&gt;last time&lt;/a&gt;: AoT is not as gripping
as it was, but stays worthwhile. A lot of mystery get resolved, and the show
might be tipping towards the start of a conclusion.&lt;/p&gt;
&lt;h2 id=&quot;the-rising-of-the-shield-hero&quot;&gt;The Rising of the Shield Hero&lt;/h2&gt;
&lt;p&gt;It&amp;#39;s another &lt;a href=&quot;https://en.wikipedia.org/wiki/Isekai&quot;&gt;isekai&lt;/a&gt;! The twist in this one is that the protagonist, which at
first seems like a special chosen one, gets cast down and trampled on. The story
then tells of how he picks himself up, helped by a few fortunate encounters.&lt;/p&gt;
&lt;p&gt;The twist works, it&amp;#39;s visceral, and the first few episodes are quite gripping.
Later on, the show becomes a bit filler-y, and then occasionally downright dumb.
Mostly, that&amp;#39;s because some characters are dumber or eviler than they should,
which I think is just lazy writing.&lt;/p&gt;
&lt;p&gt;The show has been renewed for two more seasons, and I&amp;#39;m interesting to see if
these followup seasons can be as good as the first occasionally was, now that
the main emotional trigger is unavailable. I&amp;#39;m not too optimistic, honestly.&lt;/p&gt;
&lt;h2 id=&quot;carole--tuesday&quot;&gt;Carole &amp;amp; Tuesday&lt;/h2&gt;
&lt;p&gt;A very wholesome anime about two girls starting a band. Compared to something
like &lt;a href=&quot;/more-anime/#k-on&quot;&gt;K-On!&lt;/a&gt;, this is not a slice of life show ‚Äî there is an overarching plot.
Though, of course, some episodes are not essential to the plot at all. In fact,
the show (mysteriously) hypes its eventual conclusion at the start of each
episode.&lt;/p&gt;
&lt;p&gt;On a side note, this is an anime produced by Netflix.&lt;/p&gt;
&lt;p&gt;I&amp;#39;m not entirely sure what else to say about it, but I liked what I saw of it. I
dropped it at about half because I had too much things to watch, but I might
come back to it. I&amp;#39;m not really in the mood for that sort of show currently
though.&lt;/p&gt;
&lt;h2 id=&quot;demon-slayer&quot;&gt;Demon Slayer&lt;/h2&gt;
&lt;p&gt;A shonen anime about a boy who slay demons.&lt;/p&gt;
&lt;p&gt;Yeah, the premise is very simple, and no time is wasted on it. In fact the whole
thing progresses rather quickly, which I think is smart given the content.
Mostly, it&amp;#39;s a &amp;quot;monster of the week&amp;quot; format with a background overarching plot.
Generally speaking, it&amp;#39;s pretty solid, but pretty standard.&lt;/p&gt;
&lt;p&gt;But damn, it&amp;#39;s pretty. I like the visual style, the contrasting colors and the
clean lines. And the use of 3D animation is really top-notch, allowing for the
same kind of dynamic combats that awed me in Attack on Titans.&lt;/p&gt;
&lt;p&gt;But don&amp;#39;t take my word for it. You can go watch &lt;a href=&quot;https://www.youtube.com/watch?v=6iGBTioovQw&quot;&gt;Gigguk gushing about
it&lt;/a&gt; or read this &lt;a href=&quot;https://blog.sakugabooru.com/2019/08/15/kimetsu-no-yaiba-the-power-of-ufotables-harmony/&quot;&gt;super technical analysis by Sakugabooru&lt;/a&gt;
(thanks Gorby!). Mild spoiler warning for episode 20 in both theses things.&lt;/p&gt;
&lt;h2 id=&quot;danmachi-sword-oratoria&quot;&gt;DanMachi: Sword Oratoria&lt;/h2&gt;
&lt;p&gt;In preparation for the second season of DanMachi (&lt;a href=&quot;/more-anime/#is-it-wrong-to-try-to-pick-up-girls-in-a-dungeon&quot;&gt;review for season 1&lt;/a&gt;, the
review for season 2 follows), I tried to watch the spinoff &amp;quot;Sword Oratoria&amp;quot;.&lt;/p&gt;
&lt;p&gt;Well, I gave up after two episodes, which gave me an overwhelming sense of
&amp;quot;meh-ness&amp;quot;. Nobody really seems to love this, and the plot outline of &lt;a href=&quot;https://danmachi.fandom.com/wiki/Sword_Oratoria&quot;&gt;this wiki
page&lt;/a&gt; has me flaccid.&lt;/p&gt;
&lt;p&gt;Despite all this negativity, I&amp;#39;m guessing this isn&amp;#39;t an offensively bad show,
just a boring one.&lt;/p&gt;
&lt;h2 id=&quot;danmachi-season-2&quot;&gt;DanMachi Season 2&lt;/h2&gt;
&lt;p&gt;&lt;a href=&quot;/more-anime/#is-it-wrong-to-try-to-pick-up-girls-in-a-dungeon&quot;&gt;Review for Season 1&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Let&amp;#39;s recall that DanMachi is a shorthand for &amp;quot;Is It Wrong to Try to Pick Up
Girls in a Dungeon?&amp;quot;, a title that has no actually relationship to anything that
actually happens in the plot.&lt;/p&gt;
&lt;p&gt;I relatively enjoyed the first season, as a kind of lazy comfort show.&lt;/p&gt;
&lt;p&gt;There were many good anime airing during the summer season, and the comparison
was not too favorable to DanMachi. The plot also shifted from dungeon
shenanigans to inter-familia conflicts. A familia is a group of adventurers
headed by a god ‚Äî yes, the DanMachi lore is profoundly &lt;em&gt;weird&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;The story is a bit weak sauce and ad-hoc, there&amp;#39;s no Game of Thrones levels of
realpolitik to be found here. Notably, the story proceeds in arcs, with no
overarching/intertwining plot elements. Honestly, I liked the dungeon stuff much
better.&lt;/p&gt;
&lt;p&gt;I dropped the show after maybe 8 or 9 episodes. Not really recommended unless
you were a rabid fan of the first season.&lt;/p&gt;
&lt;h2 id=&quot;cop-craft&quot;&gt;Cop Craft&lt;/h2&gt;
&lt;p&gt;This cop show takes place on Earth, after humans have made contact with an
elf-like extraterrestrial species (given this premise, I like what they did with
the name). These aliens arrived through a dimensional gate, and the show takes
place in the &amp;quot;border city&amp;quot; close to the gate. The protagonist are Kei Matoba, a
gruff experienced cop and Tilarna, a young elven (actually: Semanian) knight
Matoba gets saddled with.&lt;/p&gt;
&lt;p&gt;And, it&amp;#39;s not bad! It&amp;#39;s mostly episodic or featuring 2-3 episodes arc, but
elements form before come back.&lt;/p&gt;
&lt;p&gt;I dropped it fairly late (I saw maybe 9 out of 13 episodes), because there was
too damn many things to watch during the summer anime season, and I was pretty
busy with my thesis. I&amp;#39;ll probably finish it at some point.&lt;/p&gt;
&lt;p&gt;It&amp;#39;s not a masterpiece, but you&amp;#39;re interested in the premise and you like cop
duos that love each other but don&amp;#39;t always get along, give this a try.&lt;/p&gt;
&lt;h2 id=&quot;arifureta-from-commonplace-to-worlds-strongest&quot;&gt;Arifureta: From Commonplace to World&amp;#39;s Strongest&lt;/h2&gt;
&lt;p&gt;I didn&amp;#39;t intend to watch this at first, but there was a &lt;a href=&quot;https://www.youtube.com/watch?v=cOA75AAp9xM&quot;&gt;Digibro
review&lt;/a&gt; saying it was &amp;quot;awesomely bad&amp;quot; so I gave a try.&lt;/p&gt;
&lt;p&gt;It&amp;#39;s indeed not the best, and features some funny bad CG.&lt;/p&gt;
&lt;p&gt;The story is ham-fisted but, unexpectedly, I found the character aesthetics cool
and some of the ideas in the show (the protagonist can eat monsters to gain
their powers) interesting enough to keep watching.&lt;/p&gt;
&lt;p&gt;Briefly, it&amp;#39;s an isekai where the whole classroom was transported to another
world. The protagonist got a shitty skillset, gets somehow betrayed and left for
dead, but &lt;em&gt;conveniently&lt;/em&gt; acquires the aforementioned monster-eating power. Also,
apparently he&amp;#39;s a genius that can craft anything? You get the idea.&lt;/p&gt;
&lt;p&gt;I dropped it after the hero makes it back to the surface (he was stuck at the
bottom of a pit) and some annoying comic-relief characters are introduced.&lt;/p&gt;
&lt;p&gt;It&amp;#39;s too bad, because a good show could have come out of the same premises
(something like &lt;a href=&quot;/even-more-anime/#that-time-i-got-reincarnated-as-a-slime&quot;&gt;the slime isekai&lt;/a&gt;). Some of the designs (like the guy&amp;#39;s outfit)
are really cool.&lt;/p&gt;
&lt;p&gt;Still, I don&amp;#39;t recommend watching this one.&lt;/p&gt;
&lt;h2 id=&quot;dumbbell-nan-kilo-moteru-how-heavy-are-the-dumbells-you-lift&quot;&gt;Dumbbell Nan Kilo Moteru? (How Heavy are the Dumbells you Lift?)&lt;/h2&gt;
&lt;p&gt;An anime about weightlifting? Of course I had to watch it.&lt;/p&gt;
&lt;p&gt;Surprise, surprise, it&amp;#39;s actually not bad.&lt;/p&gt;
&lt;p&gt;It does a decent job at explaining basic gym movements. In fact the series
almost feels like a public service show to get you to work out.&lt;/p&gt;
&lt;p&gt;There isn&amp;#39;t really a story to speak of, but I found I actually like the humor a
whole lot. It&amp;#39;s one of the funniest anime I&amp;#39;ve seen (it&amp;#39;s even funnier than
&lt;a href=&quot;/even-more-anime#briefly-zombie-land-saga--sakamoto-desu-ga&quot;&gt;Sakamoto&lt;/a&gt;).&lt;/p&gt;
&lt;p&gt;Like Cop Craft, I also dropped it fairly late, for the same reasons (too many
good things). And there wasn&amp;#39;t really a reason to watch besides the laughs, but
then I haven&amp;#39;t finished even the first season of &lt;a href=&quot;https://en.wikipedia.org/wiki/Brooklyn_Nine-Nine&quot;&gt;Brooklyn 99&lt;/a&gt; and that&amp;#39;s even
more funny.&lt;/p&gt;
&lt;h2 id=&quot;anohana-the-flower-we-saw-that-day&quot;&gt;Anohana: The Flower We Saw That Day&lt;/h2&gt;
&lt;p&gt;Anohana is about a high school dropout that suddenly starts seeing (and
interacting with) the &amp;quot;ghost&amp;quot; of a childhood friend who died. It turns out he
has the fullfill the &amp;quot;wish&amp;quot; of his friend in order to lay her soul to rest,
which leads their old band of friend ‚Äî that grew apart after the death of their
friend ‚Äî to come back together once more.&lt;/p&gt;
&lt;p&gt;It&amp;#39;s a nice and short (11 episodes) heartwarming story. It reminded me of &lt;a href=&quot;https://myanimelist.net/anime/32281/Kimi_no_Na_wa&quot;&gt;Kimi
no Na wa&lt;/a&gt; a lot, as it mixes relationships with the supernatural.&lt;/p&gt;
&lt;p&gt;I binge-watched it over an evening this with some friends ‚Äî we chose Anohana
because it had the highest score on My Anime List from all the suggestions.&lt;/p&gt;
&lt;p&gt;It&amp;#39;s a nice fuzzy experience, I recommend it.&lt;/p&gt;
&lt;h2 id=&quot;fate-grand-order---absolute-demonic-front-babylonia&quot;&gt;Fate Grand Order - Absolute Demonic Front: Babylonia&lt;/h2&gt;
&lt;p&gt;I only watched the first two episodes of this out of curiosity. I have never
watched anything else in the Fate series, but this seemd to stand apart. It&amp;#39;s
based on a &lt;a href=&quot;https://en.wikipedia.org/wiki/Gacha_game&quot;&gt;gacha&lt;/a&gt; game taht was itself spin-off from the original game/series.&lt;/p&gt;
&lt;p&gt;I wasn&amp;#39;t very impressed. The first episode is about 40 minutes and there is a
lot of explaining going on. Too much? At least in the narrative-style, yes. Not
enough? It&amp;#39;s not that obvious if you don&amp;#39;t know the context that the series
adapts the 7th chapter from the game.&lt;/p&gt;
&lt;p&gt;The basic premise seems to be that they predicted the end times in a year&amp;#39;s
time, and the only way to prevent it would be to retrieve a &amp;quot;Graal&amp;quot; in some past
period (time travel, yay). I&amp;#39;m actually not quite sure about that, they might
have to do something else in the past, but it&amp;#39;s Graal-connected somehow.&lt;/p&gt;
&lt;p&gt;The whole ordeal involves some master-servant dynamic which is also not really
explained ‚Äî apparently it assumes you&amp;#39;re familiar with either the game or the
series, even though this could easily stand alone.&lt;/p&gt;
&lt;p&gt;There are quite a few references (esp. in the first episodes) to the first 6
chapters (each chapter being a travel to a different time in the past). Good for
fans, but otherwise confusing.&lt;/p&gt;
&lt;p&gt;But the worst sin of what I&amp;#39;ve seen of the series is simply that it can&amp;#39;t manage
to make its story compelling. After the first recap episode, the second episode
introduces characters... but hardly gave me any reason to care.&lt;/p&gt;
&lt;p&gt;This is the impression I already had of the whole series (though apparently
Fate/Zero is worth watching?), so I left it at that.&lt;/p&gt;
&lt;h2 id=&quot;game-of-thrones-season-8&quot;&gt;Game of Thrones Season 8&lt;/h2&gt;
&lt;p&gt;This is the final season of Game of Thrones. By now, it won&amp;#39;t surprise anyone if
I say it&amp;#39;s bad and they really did a number on it.&lt;/p&gt;
&lt;p&gt;Some spoilers below.&lt;/p&gt;
&lt;p&gt;It being bad wasn&amp;#39;t really a surprise for me. I&amp;#39;ve read the books, and it was
quite clear from the earlier seasons that the writing team was just not quite up
to the task. Everything that diverged from the source material was bad in some
respect. Since they ran out of material a while back, the suffering had actually
started in season 6 already.&lt;/p&gt;
&lt;p&gt;But what really hit people in the gut with this final season is (a) how sloppily
they tied up the storylines and (b) how they completely betrayed the character
of some of the characters (and made many more basically irrelevant).&lt;/p&gt;
&lt;p&gt;Some examples: Jaime had a nice redemption arc going for him (even at the start
of the season), but then they had to make him into an asshole right at the end.
Daenerys is of course the one that gets the worse treatment, with an
unforeshadowed, 180 degrees personality flip. Arya, after her MVP moment against
the Night King, is utterly useless, dazed and confused in the final battle.&lt;/p&gt;
&lt;p&gt;It&amp;#39;s only that these are poor directions in which to take the characters, it&amp;#39;s
that they are poorly executed too. You could spin Jaime as a &amp;quot;we come back to
make the same mistakes again and again&amp;quot; story ‚Äî but please show some of the
moral struggle and dispense with the silly one-liner justification (&amp;quot;She&amp;#39;s
hateful... and so am I.&amp;quot; ... please). In the case of Daenerys, there is some
groundwork being laid for her turning ‚Äî losing dragons (in the least believable
manner possible for the second one, I should add) and her confidante Missandei.
But show that working on her psyche for fuck&amp;#39;s sake.&lt;/p&gt;
&lt;p&gt;I could have tremendously improved the story by making this simple change: have
her not burn innocent to the ground, but instead take some risky offensive
action (maybe even trying to do good to protect her men) and then triggering one
of the wildfyre cache. Those would then cause an &lt;strong&gt;unintended&lt;/strong&gt; chain reaction
killing a ton of innocent. Then her inner circle starts blaming her even though
she&amp;#39;s under a lot of stress and wanted none of that to happen. Then, and only
then, with her coming to the conclusion that no one will truly ever be on her
side, make her flip to the dark side.&lt;/p&gt;
&lt;p&gt;That being said, the producers know how to shoot. There&amp;#39;s a lot of good shots in
there ‚Äî budget helping too.&lt;/p&gt;
&lt;p&gt;In a sense, I think we&amp;#39;re lucky to have wrapped this whole affair with a short,
stupid, but good looking final season, instead of dragging the terrible ordeal
over three more full seasons. I don&amp;#39;t think the writing team would have done a
better job of it for all the time it would have given them.&lt;/p&gt;
&lt;h2 id=&quot;once-upon-a-time-in-hollywood&quot;&gt;Once Upon a Time in Hollywood&lt;/h2&gt;
&lt;p&gt;I want to say I liked this movie ... but eh.&lt;/p&gt;
&lt;p&gt;There are a lot of good scenes in it though, in classic Tarantino fashion
(though it&amp;#39;s not quite peak Tarantino either) and the actors do a terrific job,
especially Brad Pitt and Leonardo DiCaprio. Some will say Sharon Tate is
criminally underused. They&amp;#39;re not wrong.&lt;/p&gt;
&lt;p&gt;But I actually found the movie quite boring. There is no tension being built,
the story does not &amp;quot;advance&amp;quot;. There is no reason to really get invested in it,
no real stakes until the very end.&lt;/p&gt;
&lt;p&gt;You get the feeling that Tarantino is laying dominos, and indeed there is some
payload at the end of the movie. But it&amp;#39;s not worth the languishing wait to get
there ‚Äî and it&amp;#39;s not exactly a super clever ending that recontextualizes the
whole movie either.&lt;/p&gt;
&lt;p&gt;Watch if you&amp;#39;ve liked everything Tarantino has put out, otherwise give this one
a pass.&lt;/p&gt;
&lt;h2 id=&quot;maleficient-2&quot;&gt;Maleficient 2&lt;/h2&gt;
&lt;p&gt;I was convinced by my friend Nam to go see this together, as she had rather
enjoyed the first one.&lt;/p&gt;
&lt;p&gt;I had relatively low expectations going in. But in the end, I was entertained.&lt;/p&gt;
&lt;p&gt;It felt a bit like a Shrek movie that takes itself seriously, with much more
(PG-rated) combat. I swear there&amp;#39;s even a small metaphor for World War 2 in
there!&lt;/p&gt;
&lt;p&gt;Perhaps the most stupid part of the movie is how everyone is completely stupid
around the villain (who&amp;#39;s obviously villainous and full of shit) and unwilling
to stop/speak against them until too late.&lt;/p&gt;
&lt;p&gt;Final verdict: harmless entertainment, but entertainment nonetheless.&lt;/p&gt;
&lt;h2 id=&quot;the-good-place-season-1&quot;&gt;The Good Place Season 1&lt;/h2&gt;
&lt;p&gt;This one was a good surprise: it&amp;#39;s funny, it&amp;#39;s twisty, and the mystery is
masterfully woven through the story.&lt;/p&gt;
&lt;p&gt;I have started season 2 a while back but need to get back to it. I&amp;#39;m curious to
see how they manage to keep things interesting after the big reveal at the end
of season 1.&lt;/p&gt;
&lt;h2 id=&quot;avengers-infinity-war--endgame&quot;&gt;Avengers: Infinity War &amp;amp; Endgame&lt;/h2&gt;
&lt;p&gt;These two movies put a cap on the previous era of Marvel movies (of which I&amp;#39;ve
seen maybe 10 movies out of the 22-ish that came out).&lt;/p&gt;
&lt;p&gt;I only watched Infinity War right before Endgame came out and that was
definitely a wise decision ‚Äî that movie definitely feels like the first part of
something, lacking a conclusion (spoiler: something bad happens at the end).&lt;/p&gt;
&lt;p&gt;Endgame was surprisingly solid in its constructions, weaving together multiple
sub-stories and merging them together to reach the grand conclusion final
battle, while still leaving itself time to allow proper leave-taking with the
characters (at least some of them). It mostly hits the right notes.&lt;/p&gt;
&lt;p&gt;I enjoyed that the movies do take themselves a bit more seriously than previous
entries in the series, cutting on &lt;a href=&quot;https://www.youtube.com/watch?v=w-QhdzQo66o&quot;&gt;bathos&lt;/a&gt; (bathos being basically undercutting
dramatic moments with jokes).&lt;/p&gt;
&lt;p&gt;If you&amp;#39;ve enjoyed some entries in the Marvel film series and have some nominal
knowledge of who&amp;#39;s who in the Marvel universe (there are &lt;em&gt;a lot&lt;/em&gt; of characters),
then you ought to watch them. Otherwise don&amp;#39;t bother, it probably won&amp;#39;t feel the
same.&lt;/p&gt;
&lt;h2 id=&quot;la-casa-de-papel-part-1--2-from-2017&quot;&gt;La Casa de Papel (Part 1 &amp;amp; 2 from 2017)&lt;/h2&gt;
&lt;p&gt;This was fun, although it felt overhyped.&lt;/p&gt;
&lt;p&gt;I&amp;#39;m feeling lazy, so I&amp;#39;m giving you the Wikipedia premise summary:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;The first two parts revolve around a long-prepared, multi-day assault on the
Royal Mint of Spain in Madrid, in which a group of robbers take hostages as
part of their plan to print and escape with ‚Ç¨2.4 billion. It involves eight
robbers, code-named after cities and led by the Professor from an external
location.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;It&amp;#39;s nice to have something that watch that didn&amp;#39;t originate in the US, UK or
Japan. I enjoyed listening to some Spanish.&lt;/p&gt;
&lt;p&gt;And it&amp;#39;s definitely a good story. I didn&amp;#39;t find it to be &lt;em&gt;incredibly&lt;/em&gt; gripping
though, and mostly I watched it one episode at a time, with occasional binges of
two or three episodes. In that, it reminded me a bit of Breaking Bad ‚Äî it&amp;#39;s a
story that needs to breathe.&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;And that&amp;#39;s it for this time. Next time I&amp;#39;ll review some anime I&amp;#39;m currently
watching: Vinland Saga, Dr Stone, Fire Force, Gankutsuou, Ergo Proxy and
probably other things too.&lt;/p&gt;
      </description>
      <pubDate>2019-11-06T23:00:00.000Z</pubDate>
      <link>http://norswap.com/reviews-4</link>
      <guid isPermaLink="true">http://norswap.com/reviews-4</guid>
    </item>
    <item>
      <title>Thesis Done!</title>
      <description>
&lt;p&gt;I successfully defended my thesis &amp;quot;&lt;em&gt;Principled Procedural Parsing&lt;/em&gt;&amp;quot; on the 17th
of October!&lt;/p&gt;
&lt;p&gt;You can &lt;a href=&quot;/pubs/thesis.pdf&quot;&gt;download it here&lt;/a&gt;.&lt;/p&gt;
      </description>
      <pubDate>2019-11-06T23:00:00.000Z</pubDate>
      <link>http://norswap.com/thesis</link>
      <guid isPermaLink="true">http://norswap.com/thesis</guid>
    </item>
    <item>
      <title>Chosen Tidbits: June 2019</title>
      <description>
&lt;p&gt;As some may know, I read a whole lot. So I thought to start a series to
highlight the most interesting things I&amp;#39;ve read recently, along with some quotes
or explanations why I liked it.&lt;/p&gt;
&lt;p&gt;We&amp;#39;re starting with stuff I read in June. More to follow when I have more time
and enough material!&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;&lt;a href=&quot;https://www.ribbonfarm.com/2019/05/27/weirding-diary-8/&quot;&gt;Weirding Diary: 8&lt;/a&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;It doesn‚Äôt matter if everything else gets cheaper with Moore‚Äôs Law, if rent,
healthcare, and education costs race ahead of income. Those three costs drive
hard choices, and that is putting existential pressures on institutions.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;!-- --&gt;

&lt;blockquote&gt;
&lt;p&gt;In the near future, all schools at all levels will either be de facto
rentier-elite finishing schools, or indoctrination schools for socialist
revolutionaries.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;hr&gt;
&lt;p&gt;&lt;a href=&quot;http://visakanv.com/1000/0764-identify-the-valuable-squares-on-your-lifes-chessboard/&quot;&gt;Identify the valuable squares on your life‚Äôs chessboard&lt;/a&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;I know what to do. I need to step outside the day-to-day challenges and
struggles. I need to see the bigger picture and be clear about what my
priorities are. What do I want? What do I not need to care about? I‚Äôm thinking
of a conversation or exchange I had with someone about why people struggle to
cope with everyday life ‚Äì and I think that conversation went to a place that
was something like‚Ä¶ people are trying to do more than they can, instead of
focusing on what‚Äôs most important. It‚Äôs a sort of‚Ä¶ hedging. You hedge your
bets because you don‚Äôt know what‚Äôs important, and so you try to do a little
bit of everything. Better to score a few points in every bucket, than to put
all your points in the wrong bucket. But the best thing you can do is to put
most or all of your points in the right bucket. And can you know what the
right bucket is? In a sort of probablistic sense, yes! Imagine a sort of‚Ä¶
landscape, a grid. A chessboard, let‚Äôs say. 64 squares. That‚Äôs your life,
that‚Äôs the number of things you could theoretically possibly Every day you
have maybe 3-5 points you can assign to squares on the chessboard. You could
put all the points on one square, or you could distribute them across multiple
squares. The thing I think I ought to figure out is, which are the most
valuable squares? Do I know this? I think I know it subconsciously, and I
think I need to articulate it.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;hr&gt;
&lt;p&gt;&lt;a href=&quot;https://www.youtube.com/watch?v=Un3p614XExc&quot;&gt;A Master Class in Jazz Performance and Creativity with Pianist Kenny
Werner&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;This one is dense and packed with insight. If you do any kind of performance or
even just practice a trainable skill, it&amp;#39;s sure to resonate with you and give
you an idea or two.&lt;/p&gt;
&lt;p&gt;Here are some of the most striking insight for me, but again, yours will likely
be different:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Performance is about playing well within your zone of comfort.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Two reasons a performance doesn&amp;#39;t go well: lack of technique or not releasing
yourself to the zone. Don&amp;#39;t criticize yourself in performance.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Brainwash yourself to love every sound you make. When a musician enjoys what
he does, that&amp;#39;s half the attraction. Don&amp;#39;t react when you touch your
instrument ‚Äî that gets in the way.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;You don&amp;#39;t need to be unsatisfied in order to get better.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Practicing is not playing and enjoying. You should focus on the difficulties,
on what you can&amp;#39;t do yet. Specifically on those parts, don&amp;#39;t get side-tracked,
that&amp;#39;s not efficient.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;p&gt;&lt;a href=&quot;https://slatestarcodex.com/2019/06/03/repost-epistemic-learned-helplessness/&quot;&gt;Epistemic Learned Helplessness&lt;/a&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;A friend recently complained about how many people lack the basic skill of
believing arguments. That is, if you have a valid argument for something, then
you should accept the conclusion. Even if the conclusion is unpopular, or
inconvenient, or you don‚Äôt like it. He envisioned an art of rationality that
would make people believe something after it had been proven to them.&lt;/p&gt;
&lt;p&gt;And I nodded my head, because it sounded reasonable enough, and it wasn‚Äôt
until a few hours later that I thought about it again and went ‚ÄúWait, no, that
would be a terrible idea.‚Äù&lt;/p&gt;
&lt;/blockquote&gt;
&lt;hr&gt;
&lt;p&gt;&lt;a href=&quot;https://slatestarcodex.com/2019/06/06/asymmetric-weapons-gone-bad/&quot;&gt;Asymmetric Weapons Gone Bad&lt;/a&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Every day we do things that we can‚Äôt easily justify. If someone were to argue
that we shouldn‚Äôt do the thing, they would win easily. We would respond by
cutting that person out of our life, and continuing to do the thing.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;hr&gt;
&lt;p&gt;&lt;a href=&quot;https://meltingasphalt.com/social-status-down-the-rabbit-hole/&quot;&gt;Social Status: Down the Rabbit Hole&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;There are two hierarchies of social status: dominance and prestige.&lt;/p&gt;
&lt;blockquote&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Avoidance vs. approach. Dominance works by inspiring fear and other
&amp;quot;avoidance&amp;quot; instincts, so that low-status people try to steer clear of
dominant individuals. Prestige, on the other hand, inspires admiration and
other &amp;quot;approach&amp;quot; instincts, so low-status people actively seek out
prestigious individuals and enjoy spending time around them.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Taking vs. giving. The perks of dominance are taken by force by the
high-status (dominant) individual. The perks of prestige, on the other hand,
are given to the high-status (prestigious) individual, freely, by the
low-status admirer.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Entitlement vs. gratitude. Dominant individuals expect deference from others
and treat it as their natural right. Prestigious individuals, on the other
hand, often make an elaborate show of humility when accepting the deference
of others. Performers bow as they&amp;#39;re being applauded. Oscar-winners
profusely thank their supporters. Lay people often blush and smile awkwardly
when they&amp;#39;re being celebrated, e.g., at a birthday party. To do otherwise ‚Äî
to act entitled to admiration ‚Äî would risk alienating one&amp;#39;s supporters.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/blockquote&gt;
&lt;hr&gt;
&lt;p&gt;&lt;a href=&quot;https://www.gwern.net/MLP&quot;&gt;MLP: Immanetizing The Equestrian&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;(Note: MLP means &amp;quot;My Little Poney&amp;quot;. Yup.)&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;One of the ways in which MLP is unusual is, in addition to episodes
criticizing communism or egalitarianism, its implicit capitalist economy (in
contrast to most media where markets or capitalism are portrayed negatively
when any attention is paid to them); Equestria is not post-scarcity by magical
fiat but is capitalist to the core, and its prosperity is due the capitalism
and competition. And this capitalism contributes to the self-actualization of
ponies: to gain a sense of self-worth which is genuine and grounded in
reality, one must discover something one does well (finding one‚Äôs cutie-mark),
which is of value to one‚Äôs peers and society, and said value is only honestly
expressed when freely expressed against a background of genuinely competitive
options.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;!-- --&gt;

&lt;blockquote&gt;
&lt;p&gt;Is it an accident that Jordan B. Peterson appeals to a similar demographic as
MLP, or that he conveys a similar message in his books like 12 Rules for Life?
He retells the cliches with conviction inside a societal vacuum. There is
still hope, you can always change, if you start now, you can ‚Äú&amp;quot;clean your
room&amp;quot;‚Äù, and tame the chaos (Discord?) in your life to find a talent or niche
and develop into a valued social role that can provide a sense of self-worth‚Ä¶
There are some people who need to hear that specific message, just as there
are people who need to read Atlas Shrugged (while there are other people for
whom that‚Äôs the worst book possible‚Äîthe right book for the right person). Both
Peterson and MLP provide specific recommendations (if not necessarily
flowcharts). But the key step is to simply start. Sometimes it takes just a
word, an admission to oneself that one has made a mistake up until now, to
reach out: ‚ÄúI‚Äôm sorry‚Äù. ‚ÄúI was wrong.‚Äù ‚ÄúI can‚Äôt do this any longer.‚Äù Saying
that it‚Äôs ‚Äútoo late‚Äù or that ‚Äúa leopard can‚Äôt change its spots‚Äù is an
abdication of freedom and personal responsibility; when there is a choice to
which one has always said ‚Äúno‚Äù before, the next time, one can say ‚Äúyes‚Äù. The
tragedy of Voldemort in Harry Potter and the Deathly Hallows is he succumbs,
like Walter in Breaking Bad, to the deadly sin of pride: not that he was a
neglected child or that his soul is mutilated by murder, but that at the end,
when he‚Äôs already lost, Harry gives him a final chance, and in front of
everypony, he is unable to swallow his pride and surrender, and cannot, will
not, choose to stop being Voldemort and become only Tom Riddle again; that is
when he is truly damned and the end of his story.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;hr&gt;
&lt;p&gt;&lt;a href=&quot;https://thezvi.wordpress.com/2017/07/20/change-is-bad/&quot;&gt;Change Is Bad&lt;/a&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;The more optimized things currently are, the less likely any given change is
to be good.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;hr&gt;
&lt;p&gt;&lt;a href=&quot;https://larspsyll.wordpress.com/2016/11/23/what-is-ergodicity-2/&quot;&gt;What is ergodicity?&lt;/a&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Suppose you are concerned with determining what the most visited parks in a
city are. One idea is to take a momentary snapshot: to see how many people are
this moment in park A, how many are in park B and so on. Another idea is to
look at one individual (or few of them) and to follow him for a certain period
of time, e.g. a year. Then, you observe how often the individual is going to
park A, how often he is going to park B and so on.&lt;/p&gt;
&lt;p&gt;Thus, you obtain two different results: one statistical analysis over the
entire ensemble of people at a certain moment in time, and one statistical
analysis for one person over a certain period of time. The first one may not
be representative for a longer period of time, while the second one may not be
representative for all the people.&lt;/p&gt;
&lt;p&gt;The idea is that an ensemble is ergodic if the two types of statistics give
the same result. Many ensembles, like the human populations, are not ergodic.&lt;/p&gt;
&lt;p&gt;We trust that a good/bad experience at a restaurant will repeat, but not that
if more black persons commit crimes, no black person is to be trusted.&lt;/p&gt;
&lt;p&gt;The answer is that the ensemble of meal in a restaurant is more or less
ergodic, while the ensemble of black people is not at all ergodic.&lt;/p&gt;
&lt;/blockquote&gt;
      </description>
      <pubDate>2019-09-14T22:00:00.000Z</pubDate>
      <link>http://norswap.com/chosen-tidbits-1</link>
      <guid isPermaLink="true">http://norswap.com/chosen-tidbits-1</guid>
    </item>
    <item>
      <title>Weight Training: Cut Edition</title>
      <description>
&lt;p&gt;Previously: &lt;a href=&quot;/weight-training&quot;&gt;One&lt;/a&gt; / &lt;a href=&quot;/weight-training-2&quot;&gt;Two&lt;/a&gt; / &lt;a href=&quot;/weight-training-3&quot;&gt;Three&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;In &lt;a href=&quot;/weight-training-3&quot;&gt;my last post on the topic&lt;/a&gt;, I said I was going to go on a cut. Well,
now the cut is done, let&amp;#39;s discuss a bit!&lt;/p&gt;
&lt;p&gt;Was it a success? Well my stated goal was to acquire a six-pack, so in that
sense, no. But I learned a ton, and I did visibly lose a considerable amount of
fat and slimmed down from 90 kg to 83 kg over 15 weeks.&lt;/p&gt;
&lt;p&gt;I scrupulously transcribed my daily caloric expenditure and intake in a
&lt;a href=&quot;https://docs.google.com/spreadsheets/d/1kwGo8YRcEdPJotxaWLlc72pz6YvdU2ymKw_gFa_dKkY/edit?usp=sharing&quot;&gt;spreadsheet&lt;/a&gt;. All the numbers and metrics I discuss in this article are
recorded there!&lt;/p&gt;
&lt;h2 id=&quot;beginnings&quot;&gt;Beginnings&lt;/h2&gt;
&lt;p&gt;Initially, I went for a 700 kcal daily deficit. This would add up to a 4900 kcal
deficit per week, which represents about 630 grams of fat. As it turns out, this
is exactly 0.7% of my starting bodyweight of 90 kg, which is the recommended
weekly loss.&lt;/p&gt;
&lt;p&gt;I did struggle with the strict regimen initially. This was not an issue of will,
but rather an issue of organization. Too often I accidentally overshot my goal ‚Äî
in fact my average daily deficit in the first four weeks was a measly 385. Oops.&lt;/p&gt;
&lt;p&gt;A remark on my method here: while I&amp;#39;m a fan of using a Fitbit smartwatch to
track caloric expenditure, it does add a bit of logistical uncertainty, as you
must estimate what the expenditure will be by the end of the day. Mostly, I
adapted to cope with this by having very light dinner meals, and potentially a
snack before going to bed. I&amp;#39;ll have more to say about the Fitbit towards the
end of the article.&lt;/p&gt;
&lt;p&gt;After four weeks, I ran a &lt;em&gt;refeed&lt;/em&gt; week, where I ate at maintenance. This is
done to prevent &lt;em&gt;metabolic adaptation&lt;/em&gt; in which your body gets used to get less
calories and adapts to burn less of them. That week was also a deload week where
I decreased my weights at the gym (otherwise I kept training using the
&lt;a href=&quot;/weight-training-3&quot;&gt;previously outlined program&lt;/a&gt;).&lt;/p&gt;
&lt;p&gt;In the second four-week period, I was able to average between 600 and 700
kcal of deficit daily - yay!&lt;/p&gt;
&lt;h2 id=&quot;is-it-working&quot;&gt;Is It Working?&lt;/h2&gt;
&lt;p&gt;So we have our caloric deficit down. But is it actually working as expected?&lt;/p&gt;
&lt;p&gt;To do this I compared my recorded weight to two measures of the estimated weight
given the recorded caloric deficit. The first estimated weight is global: it&amp;#39;s
my starting weight minus the fat weight loss predicted from the cumulated
caloric deficit. The second estimated weight is local: it&amp;#39;s computed in the same
way but only for one week, starting from the starting weight just before that
week.&lt;/p&gt;
&lt;p&gt;In order to predict the fat loss from a caloric deficit, you simply need to know
that a kilogram of fat is equivalent to about 7700 kcal (or 3500 kcal to a
pound).&lt;/p&gt;
&lt;p&gt;To ascertain whether I was on track, I further computed two weekly metrics: the
&lt;em&gt;average local error&lt;/em&gt; is the difference between the average locally predicted
weight and my average weight for that week ; the &lt;em&gt;average global error&lt;/em&gt; is the
same, but using the average globally predicted weight instead.&lt;/p&gt;
&lt;p&gt;Taking these averages allows smoothing over the noise inherent to weight
measurements: there can be big variations in water weight from one day to the
other (even though I always weighed myself in the morning after going to the
bathroom and before drinking anything).&lt;/p&gt;
&lt;p&gt;Another thing I did to be able to track my progress was compute a &lt;em&gt;smoothed&lt;/em&gt;
weight measurement: the daily smoothed weight is the average of the the weight
in a 5 day window surrounding the day under consideration. This was also the
basis I used to compute the local weight estimation.&lt;/p&gt;
&lt;p&gt;After the initial 5 week period (4 weeks + refeed week), I had lost 1.3 kg.
That is slighty (about 200 g) more than the model predicted. In general, the
average local and global errors were small (&amp;lt;= 100 g, either above or under)
during this period.&lt;/p&gt;
&lt;p&gt;After the second 5 week period, I had lost 3.6 kg in total, a whole kilogram
more than the global prediction! The data was much more noisy here, mostly the
global error increases in the negatives (underestimation) but it shot back
towards zero because of a weight measurement bump that normalized quickly. The
local error varied between 0 and -500g (underestimation).&lt;/p&gt;
&lt;p&gt;There is only one remaining uncertainty: was this weight loss fat loss... or
muscle loss?&lt;/p&gt;
&lt;p&gt;This is quite tricky to measure. The impedance scale I bought isn&amp;#39;t worth shit.
Methods requiring a &lt;a href=&quot;https://www.amazon.fr/CZ-Store-Adipom%C3%A8tre-%E2%9C%AE%E2%9C%AE100-GARANTIE-ANS%E2%9C%AE%E2%9C%AE-Pince-grasse-%E2%9C%AEOFFERT/dp/B072MBCSXD/ref=sr_1_3?__mk_fr_FR=%EF%BF%BDM%EF%BF%BD%25u017D%EF%BF%BD%EF%BF%BD&amp;amp;keywords=fat+caliper&amp;amp;qid=1568237305&amp;amp;s=gateway&amp;amp;sr=8-3&quot;&gt;fat caliper&lt;/a&gt; are janky... They require multiple measurements,
sometimes in location you can&amp;#39;t access on your own (back of the arm, shoulder
blade). I bought a cheap one and it&amp;#39;s also not quite clear how much you need to
press.&lt;/p&gt;
&lt;p&gt;The impedance scale at my gym (Basic Fit) seems a bit more accurate though,
reporting 17% body fat somewhere within the second four-week period, and 14% at
the end of the cut.&lt;/p&gt;
&lt;p&gt;In my spreadsheet, I estimated my starting percentage at 18% (based on visual
comparison to some online reference), which ‚Äî assuming 100% of weight loss is
fat loss ‚Äî would put me at 16.7% at the end of the four weeks period and 11.2%
at the end of the cut.&lt;/p&gt;
&lt;p&gt;There is another method, which consists of taking measurements of your waist and
your neck (using a regular meter), and which is &lt;em&gt;reportedly&lt;/em&gt; relatively accurate ‚Äî
you can find a calculator &lt;a href=&quot;http://fitness.bizcalcs.com/Calculator.asp?Calc=Body-Fat-Navy&quot;&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;All the research points to the fact that, given a moderate deficit (the figure
of 0.7% of your starting bodyweight is often given), the overwhelming majority
of the weight loss should be fat ‚Äî if you keep doing resistance (weight)
training and intaking enough proteins, which I did.&lt;/p&gt;
&lt;p&gt;There is a theory that you can only mobilize so much calories from fat mass
daily. Let&amp;#39;s look into it.&lt;/p&gt;
&lt;h2 id=&quot;a-detour-how-fast-can-you-actually-lose-fat&quot;&gt;A Detour: How Fast Can You Actually Lose Fat?&lt;/h2&gt;
&lt;p&gt;There is a theory saying that there is a limit on the calories that can be made
available from fat over a given time period. However, it&amp;#39;s not quite clear what
that limit is.&lt;/p&gt;
&lt;p&gt;A &lt;a href=&quot;https://www.sciencedirect.com/science/article/pii/S0022519304004175&quot;&gt;2005 study&lt;/a&gt; in theoretical biology found it to be 31 kcal per pound of body
fat daily (about 68 kcal per kilo). However, the author &lt;a href=&quot;https://reddit.com/r/loseit/comments/fo07j/if_youre_trying_to_lose_weight_keep_in_mind_that/c1hd7q1/&quot;&gt;reportedly&lt;/a&gt; later
developped a better model that brought the number down to about 22 kcal per
pound (48.5 kcal per kilo).&lt;/p&gt;
&lt;p&gt;There are a couple of caveats here. First, this is only one study. Second, this
is theoretical biology: it&amp;#39;s not possible to measure the calories fat gives out
directly, so this was established using indirect measurements and a theoretical
model.&lt;/p&gt;
&lt;p&gt;Third, the data for this study was taken from a 1950 study that starved 36
military men over a period of six months. I wasn&amp;#39;t able to get a copy of &lt;a href=&quot;https://psycnet.apa.org/record/1951-02195-000&quot;&gt;the
original&lt;/a&gt;, but found &lt;a href=&quot;https://archive.wphna.org/wp-content/uploads/2016/01/2005-Mad-Science-Museum-Ancel-Keys-Starvation.pdf&quot;&gt;an informal report&lt;/a&gt; from a now-dead website called &lt;em&gt;Mad
Science Museum&lt;/em&gt; (yup, my hobbies lead me down weird rabbit holes). The report is
quite a &amp;quot;fun&amp;quot; read (the experiment would never by approved by any modern ethics
board):&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;The stress proved too much for one of the men, twenty-four-year-old Franklin
Watkins. He began having vivid, disturbing dreams of cannibalism in which he
was eating the flesh of an old man. On trips into town (before the buddy
system had been implemented),he cheated extravagantly, downing milk shakes and
sundaes. Finally Keys confronted him, and Watkins broke down sobbing. Then he
grew angry and threatened to kill Keys and take his own life.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;But the take-away for our purposes was that:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;He designed the meals to be carbohydrate rich and protein poor, simulating
what people in Europe might be eating, with an emphasis on potatoes, cabbage,
macaroni, and whole wheat bread (all in meager amounts). Despite the reduction
in food, Keys insisted the men maintain their active lifestyle, including the
22-miles of walking each week.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;From what I know this is the abolute worse you can do to preserve muscle mass.
An effective muscle-preserving mass diet should include plenty of proteins, as
well as resistance training (to actually use the muscles ‚Äî walking is no
substitute).&lt;/p&gt;
&lt;p&gt;This is not mentionned in the paper. On the whole, I&amp;#39;m not impressed with this
paper at all, and it&amp;#39;s kinda sad when a neophyte like myself can poke huge holes
in a paper that seems to hold such sway ‚Äî even the Stronger by Science guys
&lt;a href=&quot;https://www.strongerbyscience.com/realistic-training-goals/&quot;&gt;quote it&lt;/a&gt;. I must say, though, that for a result that seems this important, it
has preciously little citations (only 21 according to Google Scholar).&lt;/p&gt;
&lt;p&gt;The starvation experiment also had an extremely long duration (6 months). I
didn&amp;#39;t dig in the math of the 2005 paper, but I wouldn&amp;#39;t be surprised that this
ends up screwing up the results as well, as the body will necessarily go into
some kind of profundly weird dysfunction given such extreme conditions.&lt;/p&gt;
&lt;p&gt;This study was popularized in the fitness community by one &lt;a href=&quot;https://bodyrecomposition.com/&quot;&gt;Lyle McDonald&lt;/a&gt;, to
the point that the 31 kcal/lb figure is often quoted as &amp;quot;Lyle McDonald&amp;#39;s rule of
31&amp;quot;. However, Lyle McDonald himself now &lt;a href=&quot;https://web.archive.org/web/20130728210211/forums.lylemcdonald.com/showthread.php?t=12760&quot;&gt;says&lt;/a&gt; that dieters can blow right past
the 31 figure if they eat enough protein and perform resistance training. He
also advocates the effectiveness of a short-duration (two weeks or less) rapid
fat loss diet where the caloric intake is sometimes less than 1000 kcal per day.&lt;/p&gt;
&lt;p&gt;In general, the reasonable consensus seems that the 22 kcal/lb figure can be
taken as a safe lower bound for fat loss and that it is likely possible to
exceed it without eating into muscles much for trained individuals.&lt;/p&gt;
&lt;p&gt;In my case, given my starting weight of 90 kg and assuming 18% body fat, the
safe 22 kcal/lb figure would have come down to a 785 kcal daily deficit, which
is close to the 700 kcal deficit I got from the 0.7% body weight heuristic.&lt;/p&gt;
&lt;p&gt;The idea that you can only mobilize so much calories from fat mass has one
important consequence. Assuming you want to lose fat at the maximum &amp;quot;safe&amp;quot; rate,
you will have to reduce your caloric deficit as your fat mass decreases!&lt;/p&gt;
&lt;p&gt;But, on the other hand, there is the phenomenon of &lt;em&gt;metabolic adaptation&lt;/em&gt;
wherein your body becomes more efficient and is able to squeeze more calories
from nutrients. So keeping a fixed deficit might not be a bad idea. As we&amp;#39;ll see
later, some step can be taken to combat metabolic adaptation.&lt;/p&gt;
&lt;h2 id=&quot;getting-serious--the-diet&quot;&gt;Getting Serious &amp;amp; The Diet&lt;/h2&gt;
&lt;p&gt;But back to my cut. When we left off, I had completed 10 weeks of cut, including
two refeed weeks, and lost 3.6 kg.&lt;/p&gt;
&lt;p&gt;It&amp;#39;s funny how memory goes: I thought I recalled hardship from that period,
which is why I decided to increase my deficit to 1000 kcal per day. But this
is actually not borne out in the numbers: in fact, I lost one kilogram more than
estimated!&lt;/p&gt;
&lt;p&gt;It is true however that I wasn&amp;#39;t going as fast as I could have: I was generally
undershooting the 700 kcal deficit goal by about 50 kcal, and the first
four weeks I had vastly undershot the goal. I was hoping that the cut would not
take much more than 3 months, and 9 weeks in, this meant only one month left!&lt;/p&gt;
&lt;p&gt;Hence, the next two weeks I ran a 1000 kcal deficit... and nothing bad happened.&lt;/p&gt;
&lt;p&gt;However, the increased deficit made my diet start being difficult. My daily
energy expenditure (as reported by the Fitbit smartwatch) will vary between 2400
and 3800 kcal daily. If I sit in a chair all day with no activity at all, it
will tend towards 2400. A lot of walking around or other activity assorted with
an intense 2 hours training session will push sometimes push it in the 3600-4000
range (interestingly, there is a lot more variation at the top than at the
bottom).&lt;/p&gt;
&lt;p&gt;With a 1000 kcal deficit, it means that in a low-activity day, I could end up
with a 1400 kcal budget at worst. This was problematic because I didn&amp;#39;t
alter my diet all that much: I kept eating the same kind of food I did before,
making sure to get about 2g of proteins per kg of lean mass. So when you eat a 1200
kcal burrito for lunch, that doesn&amp;#39;t leave a whole lot more calories for the
rest of the day. &lt;/p&gt;
&lt;p&gt;Regarding that 2g of proteins per kg of lean mass? I frequently undershot that
goal, but I think I got at least 140g per day, which is already plenty and is
&lt;em&gt;said&lt;/em&gt; to be enough to prevent muscle loss. That being said, with the 1000 kcal
deficit, it was clearly becoming difficult to even hit that diminished protein
goal.&lt;/p&gt;
&lt;p&gt;My answer to that challenge was to do something I hadn&amp;#39;t done yet: add cardio to
my training regimen on non-workout days. This ensured that every day saw a
minimum of physical activity, making it easier to hit my protein goals.&lt;/p&gt;
&lt;p&gt;After these two weeks, my weight loss was now 5.32kg. I also decided to have
another refeed week. Again, I&amp;#39;m kind of puzzled as to why I did this. Sure, a
1000 kcal deficit is not nothing, but going by the numbers, everything was going
according to plan.&lt;/p&gt;
&lt;p&gt;I followed this last refeed week by two final dieting week, one at a target 700
deficit (effectively: 635 average) and one at a target 1000 deficit
(effectively: 715). But for that last one I had the good excuse that it was the
final week before my thesis&amp;#39; deadline...&lt;/p&gt;
&lt;p&gt;Final tally: 7.02 kg lost in 14 weeks, including 3 refeed weeks.&lt;/p&gt;
&lt;h2 id=&quot;metabolic-adaptation--supplements&quot;&gt;Metabolic Adaptation &amp;amp; Supplements&lt;/h2&gt;
&lt;p&gt;As promised, a short discussion of metabolic adaptation. Metabolic adaptation is
&lt;a href=&quot;https://www.strongerbyscience.com/metabolic-adaptation/&quot;&gt;difficult&lt;/a&gt; because it does not have any single cause. When in significant
caloric deficit, your body will silmultaneously become more conservative in its
energy use, lowering your base metabolic rate (BMR) but it will also become more
efficient and effectively squeeze out more calories out of the food you consume
(you could say it &amp;quot;waste less&amp;quot; calories instead).&lt;/p&gt;
&lt;p&gt;What can you do about it? There are many things you can do to mitigate the
potential for metabolic adaptation that are basically good recommendations at
any time t: eat enough proteins, get enough sleep, don&amp;#39;t be too stressed. But
there are two more active interventions.&lt;/p&gt;
&lt;p&gt;The first is to break your diet and run a &amp;quot;refeed&amp;quot;.&lt;/p&gt;
&lt;p&gt;The idea is akin to that of a &amp;quot;cheat day&amp;quot; or &amp;quot;cheat meal&amp;quot;, but ran over a longer
period of time. The term can apparently reference different things, but in the
kind of refeed I have in mind here, you eat at maintenance ‚Äî so very different
from a cheat meal where you&amp;#39;re allowed to gorge on whatever food you like.&lt;/p&gt;
&lt;p&gt;Cheat days apparently not enough to offset metabolic adaptation, hence the
recommendation of running a whole refeed week.&lt;/p&gt;
&lt;p&gt;Another important benefit of refeed weeks is that they offer a psychological
reprieve in a months-long dieting process.&lt;/p&gt;
&lt;p&gt;I should add that ‚Äî having implemented ample refeeds ‚Äî I saw no metabolic
adaptation effects. Would there have been some if I hadn&amp;#39;t done the refeed? Hard
to say. These problems are known to be much more prevalent when you get to lower
body fat levels (towards or beyond the 10% boundary for men).&lt;/p&gt;
&lt;p&gt;If you want know much, much more about metabolic adaptation, check out &lt;a href=&quot;https://www.strongerbyscience.com/metabolic-adaptation/&quot;&gt;The
Metabolic Adaptation Manual&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;The second intervention you can run is through use of supplements. There aren&amp;#39;t
really any magical fat loss supplements, with maybe the exception of caffeine. I
managed to get my hand on the &lt;a href=&quot;https://examine.com/supplements/fat-loss/&quot;&gt;Examine&amp;#39;s fat loss supplement
guide&lt;/a&gt; and implemented what they recommended: caffeine,
synephedrine, white willow extract and yohimbine.&lt;/p&gt;
&lt;p&gt;I wasn&amp;#39;t always consistent with it ‚Äî I ran out of white willow extract at some
point and had to reorder. Same with Yohimbine for the end of the cut.&lt;/p&gt;
&lt;p&gt;Honestly, I&amp;#39;m not sure these did much, and my inconsistencies certainly didn&amp;#39;t
impact the data. The only thing that did seem to have an effect was increasing
my caffeine consumption (through coffee). Caffeine has also other benefits for
weight training that are well supported (&lt;a href=&quot;https://www.strongerbyscience.com/caffeine/&quot;&gt;one&lt;/a&gt;, &lt;a href=&quot;https://examine.com/supplements/caffeine/&quot;&gt;two&lt;/a&gt;).&lt;/p&gt;
&lt;p&gt;Caveats: given that I&amp;#39;m a relatively tall man, I might have needed to increase
the recommended doses (which are given irrespective of gender, size or weight).
I also &lt;a href=&quot;https://examine.com/supplements/yohimbine/&quot;&gt;read later&lt;/a&gt; that Yohimbine works better fasted and before workout ‚Äî
which is not at all how I used it.&lt;/p&gt;
&lt;h2 id=&quot;results--intepretation&quot;&gt;Results &amp;amp; Intepretation&lt;/h2&gt;
&lt;p&gt;Okay, so I already gave the results, and much of the interpretation above. But
there are still things to highlight.&lt;/p&gt;
&lt;p&gt;So I lost 7 kilos. The final average global error was a mere -161 g ‚Äî meaning
that I lost 161 g more than predicted based on the recorded caloric deficit.
During the process, the average global error went as high as -1000 g. Such
variance is not necessarily unexpected.&lt;/p&gt;
&lt;p&gt;The big question: was it all fat? Quite clearly (and visibly) fat was a big part
of it. As for whether muscle was part of the equation, that&amp;#39;s hard to tell as I
didn&amp;#39;t measure body fat during the process, except twice at they gym (once
during on May 3rd (second week) at 17.2% and once on August 17th (two weeks
after the end of the cut) at 14%.&lt;/p&gt;
&lt;p&gt;We can also use the spreadsheet data to compute the bodyfat reached when
assuming that 100% of the weight loss was fat. Supposing a 18% starting bodyfat
percentage, the end result is 11.15%. This seems too low (mostly visually), but
an alternative explanation to muscle loss is that part of this is water weight
due to diminished carbs intake. I don&amp;#39;t buy that explanation though ‚Äî I weighted
82.7 on 17th August, about the same than at the end of the cut, and by then any
carbs restriction effect should have been gone.&lt;/p&gt;
&lt;p&gt;Another explanation: I didn&amp;#39;t set my initial body fat percentage high enough.
Setting the initial percentage at 20% brings the final percentage to 13.32% ‚Äî
closer to the 14% impedance scale measurement.&lt;/p&gt;
&lt;p&gt;Another potential confounder here is muscle gain. When I started the cut, I was
still making steady strength gains in the program I outlined &lt;a href=&quot;/weight-training-3&quot;&gt;last time&lt;/a&gt;
‚Äî it&amp;#39;s not unconceivable to have made some small gains here even in a deficit.&lt;/p&gt;
&lt;p&gt;More relevant, I started training my abs and glutes much more vigorously (I
wasn&amp;#39;t targetting them at all before) during the last three weeks of the cut.
There, I clearly made some muscle gains ‚Äî at least a little bit of which I
expect to have been made during those weeks.&lt;/p&gt;
&lt;p&gt;Two more signs we can look at for muscle loss is fatigue and what happened after
the cut. Regarding fatigue, I didn&amp;#39;t really progress my heavy pre-existing lifts
(deadlift, bench press, squat, etc) during the cut ‚Äî but that was expected. In
reality, I had to deload the squat and the deadlift them fairly early in the
cycle for technique reasons (a &lt;a href=&quot;#the-exercise-corner&quot;&gt;further section&lt;/a&gt; of this article will talk about
that ‚Äî it&amp;#39;s not connected to the cut). The bench and overhead press plateaued,
while the rest of the program progressed rather nicely. I didn&amp;#39;t feel tired at
all.&lt;/p&gt;
&lt;p&gt;Regarding what happened after the cut, my weight did not shot back up. I
actually only had one week of training after the cut, and then a full week of
holiday with no weight training (but a lot of walking). But even after, my
weight didn&amp;#39;t suddenly shot up even when I started running a caloric excess.
This means there probably wasn&amp;#39;t some easily recoverable &amp;quot;muscle memory&amp;quot; ‚Äî but
also that the body didn&amp;#39;t overcompensate by storing lots of fat after the end of
the diet.&lt;/p&gt;
&lt;p&gt;So yeah... it worked rather well, but the jury is still split on whether it
worked optimally (no muscle lost) or not.&lt;/p&gt;
&lt;p&gt;Lazy Edit: So, if we ignore the issue of gained muscles AND if we assume that
the caloric trackins is accurate, there might be a way to know, which is to
solve the equations &lt;code&gt;WL = FL + ML&lt;/code&gt;, &lt;code&gt;CD = FL * 7700 + ML * 1540&lt;/code&gt;, where &lt;code&gt;WL&lt;/code&gt;,
&lt;code&gt;FL&lt;/code&gt; and &lt;code&gt;ML&lt;/code&gt; are weight loss, fat loss and muscle loss, while &lt;code&gt;CD&lt;/code&gt; is the
caloric deficit. 7700 is the number of kcal in a kg of fat, while 1540 is the
number of kcal in a kg of muscle (thanks &lt;a href=&quot;http://www.coltondillion.com/&quot;&gt;Colton&lt;/a&gt; for finding &lt;a href=&quot;https://thestrongkitchen.com/blog/post/how-many-calories-does-it-take-to-build-a-pound-of-muscle&quot;&gt;that info&lt;/a&gt;).&lt;/p&gt;
&lt;p&gt;I might try to run this upon my data, but I&amp;#39;m not optimistic, given that the
assumptions are pretty damn huge, and that the global error for the 100% fat
model is pretty low.&lt;/p&gt;
&lt;h2 id=&quot;lessons&quot;&gt;Lessons&lt;/h2&gt;
&lt;p&gt;What would I do differently next time?&lt;/p&gt;
&lt;p&gt;First off, be much more careful with my tracking and discipline (knowing full
well the occasional slip-up will happen).&lt;/p&gt;
&lt;p&gt;Next, I would try running a ~900 kcal deficit immediately. Mind you, I&amp;#39;m not
100% convinced that this is the right idea, but I think it&amp;#39;s worth trying for a
4 week duration. The benefit is obviously a shorter diet. The risk is that this
is too much and muscle loss results.&lt;/p&gt;
&lt;p&gt;Given my current body fat percentage and weight, a 900 kcal deficit is
equivalent to requiring 77 kcal per kilo of muscle (35 kcal per pound) ‚Äî which
many people believe is safe. What is especially annoying here is that it will be
hard to tell fat loss apart from muscle loss. I could use the neck-waist
measurement method and the gym&amp;#39;s impedance scale to try and estalish trends
here, however.&lt;/p&gt;
&lt;p&gt;I would also keep the refeeds after each 4 week period.&lt;/p&gt;
&lt;p&gt;I can imagine playing with the length of the cut too. Assuming my body fat
percentage doesn&amp;#39;t increase (tall order), doing 4 weeks of cutting with a 900
kcal deficit would bring me to 10.5% body fat (assuming 100% fat loss). Two
weeks would bring me down to 12.3%.&lt;/p&gt;
&lt;p&gt;I would maybe drop the supplements, except caffeine. I might want to try to use
Yohimbine &amp;quot;properly&amp;quot;, i.e. in a mostly fasted state and before a workout.&lt;/p&gt;
&lt;p&gt;Regarding caffeine, I would cycle off of it from for a few weeks before the cut,
and then progressively ramp it up during the cut: drink something like one daily
cup of robusta the first week, two the second, etc.&lt;/p&gt;
&lt;p&gt;I&amp;#39;m excited to see if the second time is the charm for the six-pack :D&lt;/p&gt;
&lt;h2 id=&quot;the-exercise-corner&quot;&gt;The Exercise Corner&lt;/h2&gt;
&lt;p&gt;How&amp;#39;d I do on my program meanwhile? &lt;/p&gt;
&lt;p&gt;Let&amp;#39;s first tackle the big lifts. The deadlift progressed to 185 kg until June.
The squat was deloaded almost immediately, and kept being deloaded for poor
form. In both of these lifts, I&amp;#39;d come to realize I had progressively adopted
terrible form. I was desegmenting the deadlift: shooting my ass up and then
pulling instead of pushing through the ground. I was doing something similar on
the squat: bending forward too much so that my ass could go up and finally
contribute to the lift. Both of these put a lot of strain on my lower back who
had dutifully adapted. Symptomatically, deloading these lifts did not made them
seem much easier after a bit.&lt;/p&gt;
&lt;p&gt;After a bit of diagnostic, the issues seemed to be that my glutes and my abs
were too weak. So in went &lt;a href=&quot;https://www.youtube.com/watch?v=qk97w6ZmV90&quot;&gt;a new regimen of ab training&lt;/a&gt; as well as
glute-specific exercises, most notably the &lt;a href=&quot;https://www.youtube.com/watch?v=xDmFkJxPzeM&quot;&gt;hip thrust&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;These have worked wonder to strengthen these muscles, but I haven&amp;#39;t had time to
reload the lifts yet. And since I&amp;#39;m switching program for now, it might be a
while before I see my old records (which I&amp;#39;m invalidating anyway, because of
poor form).&lt;/p&gt;
&lt;p&gt;The bench mostly stagnated, never really going much over that 100kg barrier, I
managed 3x102 at times and then had to deload. The overhead press also stagnated
and I also deloaded it. The problem there is arching the back too much, though
I&amp;#39;m not entirely sure how to get rid of that ‚Äî I&amp;#39;m hoping stronger abs will
help.&lt;/p&gt;
&lt;p&gt;The rest of the program mostly saw progress as some movements were still fairly
new when I started the cut. Nothing went down, anyhow. Triceps, in particular,
saw a lot of progress.&lt;/p&gt;
&lt;h2 id=&quot;whats-next&quot;&gt;What&amp;#39;s Next?&lt;/h2&gt;
&lt;p&gt;The wise man said: after each cut must come a bulk. And so it is.&lt;/p&gt;
&lt;p&gt;I&amp;#39;m taking it somewhat more seriously than I did before. It feels like the
careful attention to my calories during the cut as motivated me to be more
serious now. I&amp;#39;m particularly attentive at ingesting more than enough proteins,
and making an effort at timing them right too (something I started doing during
the cut already).&lt;/p&gt;
&lt;p&gt;Since I started reliably eating more than maintenance calories (aiming for
100-300 more), I sometimes overshot my calories goal whenever my caloric
expenditure is a bit lower or on rest days. I must be careful with that. I think
I have taken too much fat at the start of the year before the start of my cut by
overeating. At that time, quite puzzlingly, I aimed to eat a certain amount of
calories per day instead of basing it on the fitbit data. No idea why I did it
like that &lt;code&gt;¬Ø\_(„ÉÑ)_/¬Ø&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;I must also pay attention to my sleep more. I&amp;#39;ve tended to push my sleep time
further and further away and only my determination to at least get up for lunch
has saved me. But often, sleep time ends up suffering in the process. I&amp;#39;ve been
&lt;strong&gt;damn busy&lt;/strong&gt; towards and since the end of the cut (you&amp;#39;d think handing in the
thesis would mean work was over, but then you have to tackle everything that
fell by the wayside on the way there).&lt;/p&gt;
&lt;p&gt;I&amp;#39;m also trying out the &lt;a href=&quot;https://my.builtwithscience.com/p/intermediate-build-program&quot;&gt;Intermediate Build&lt;/a&gt; program from Jeremy Ethier. Since I
got quite a bit of value from his &lt;a href=&quot;https://builtwithscience.com/best-full-body-workout/&quot;&gt;free full-body program&lt;/a&gt; and his
content in general, it seemed a safe value proposition. I&amp;#39;m currently tackling
the first week and so far I&amp;#39;m enjoying it. We&amp;#39;ll see come result time!&lt;/p&gt;
&lt;p&gt;Finally, if I find the time I&amp;#39;d like to analyse my cut data a bit more. In
particular, I&amp;#39;d like to run a multivariable linear regression on my data in
order to see if I can find a systematic bias in the caloric intake or
expenditure estimations. I&amp;#39;m not too optimistic here either: a non-naive model
would include things like the hours classified by Fitbit as workout every day as
well as their caloric estimations, as well as a labelling of how certain I am of
my caloric intake measurements (things that come in a box are easy to measure,
restaurant food is a wild guess).&lt;/p&gt;
&lt;h2 id=&quot;a-note-on-the-fitbit&quot;&gt;A Note on The Fitbit&lt;/h2&gt;
&lt;p&gt;It is known that the Fitbit is not the most accurate means of measuring energy
expenditure. If you look at the figures, this &lt;a href=&quot;https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6107736/&quot;&gt;literature review&lt;/a&gt; paints a
rather appalling picture, with many studies finding that the Fitbit under- or
overestimates calories spent in activity by as much as 60% (and even more, in a
few cases).&lt;/p&gt;
&lt;p&gt;Of course, the fact that studies have such varied results is a big red flag.
Either the Fitbit is totally random, or some studies are crap. Well, in my
experience (and as can be seen in my data), the Fitbit is far from random. On
the other hand, I have seen my share of crap studies.&lt;/p&gt;
&lt;p&gt;If anything, the Fitbit was consistent ‚Äî the same activity (in my case workouts
and walking) tends to yield similar caloric estimations. If it does happen to be
biased in certain cases, it looks like I was fortunate enough to have the biases
cancel each other out.&lt;/p&gt;
&lt;p&gt;Returning to the literature review, things look better when you look at the
details:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Findings suggested that Fitbit was more likely to markedly overestimate energy
expenditure when worn on the wrist and when walking at normal adult walking
speeds on flat surfaces. On the contrary, Fitbit was more likely to
underestimate energy expenditure when worn on the torso, with a tendency to
markedly underestimate energy expenditure during inclined ambulation, during
activities with constrained or variable body motion throughout the activity,
and during simulated household or sporting activities that involve
stop-and-start ambulation. Findings from 1 study for measures of energy
expenditure in free-living settings suggested that Fitbit and doubly labelled
water may provide similar measures of total energy expenditure over a 2-week
period. However, findings from a few studies in free-living settings suggested
that Fitbit devices may provide notable underestimations of daily energy
expenditure compared with a SenseWear accelerometer.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Given my relatively high caloric expenditure numbers, I&amp;#39;m not too worried about
underestimations.&lt;/p&gt;
&lt;p&gt;Also apparently &lt;a href=&quot;https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5360603/&quot;&gt;SenseWear overestimates energy expenditure&lt;/a&gt;?&lt;/p&gt;
&lt;p&gt;I kept saying &amp;quot;the Fitbit&amp;quot;, but of course there is no such thing:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Most of the studies included in this review were published in the last 2
years, with studies primarily examining measurement accuracy for models of
Fitbit activity trackers introduced prior to 2015.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;I used the Charge 2 (2016) until June and the Charge 3 (2018) after. It&amp;#39;s
possible things improved since 2015. I saw no difference in measurements between
the Charge 2 and the Charge 3 however.&lt;/p&gt;
&lt;p&gt;So what? Well, obviously take what the Fitbit says (and what everybody says
about the Fitbit) with a pinch of salt. The best thing is to do like I did:
collect your own data and come to your own conclusions.&lt;/p&gt;
&lt;p&gt;Personally, I find the Fitbit super helpful to set a proper caloric intake.&lt;/p&gt;
&lt;p&gt;What&amp;#39;s the alternative? Using a macro calculator &lt;a href=&quot;https://www.calculators.tech/macro-calculator&quot;&gt;like this one&lt;/a&gt;. The caloric
recommendation really depends on what goal (I chose &amp;quot;muscle gain&amp;quot;) and &amp;quot;activity
level&amp;quot; you set. With &amp;quot;lightly active&amp;quot; (true of me outside of workouts ‚Äî and I
did say I wanted to gain muscle, they don&amp;#39;t build themselves), I get a 3185 kcal
recommendation. Using my working hypothesis that the Fitbit is accurate, the
average daily expenditure &lt;em&gt;during my cut&lt;/em&gt; was 3190, and building muscle means I
have to add 200-300 kcal on top of that. Oops.&lt;/p&gt;
&lt;p&gt;On the other hand, choosing &amp;quot;very active&amp;quot; puts me at 4000 daily kcal. That&amp;#39;s
likely too much ‚Äî I only hit 3700 kcal expenditure on workout days, and then not
each time. So you have to choose &amp;quot;moderately active&amp;quot; to get a more reasonable
3591 kcal recommendation. How could I know this?&lt;/p&gt;
&lt;p&gt;A promising avenue is the aformentioned Jeremy Ethier&amp;#39;s program, which includes
a nutrition spreadsheet. The initial estimate is wildly off (saying I should eat
3113 kcal for muscle gain) but it automatically uses your recorded weight and
caloric intake to adjust the TDEE (total daily energy expenditure). I might try
to use that and see if it gives good results.&lt;/p&gt;
&lt;p&gt;And with these final comments, I&amp;#39;m done. This turned out much longer than I
expected. Hopefully, someone will be able to get some useful information out of
this!&lt;/p&gt;
      </description>
      <pubDate>2019-09-12T22:00:00.000Z</pubDate>
      <link>http://norswap.com/weight-training-4</link>
      <guid isPermaLink="true">http://norswap.com/weight-training-4</guid>
    </item>
    <item>
      <title>Y Combinator and Trampolines in Javascript</title>
      <description>
&lt;p&gt;In &lt;em&gt;&lt;a href=&quot;http://raganwald.com/2018/09/10/why-y.html&quot;&gt;Why Y? Deriving the Y Combinator in JavaScript&lt;/a&gt;&lt;/em&gt;, Reginald
Braithwaithe (aka Raganwald) explains, step by step, how the fixed-point Y
combinator and the long-tailed widowbird can be implemented in Javascript.&lt;/p&gt;
&lt;p&gt;At this point, you&amp;#39;re probably wondering &lt;strong&gt;What the hell are we talking about?&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Essentially, these are tools that we can use to achieve two very useful things:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Inject code at each recursive call in a recursive function.&lt;/li&gt;
&lt;li&gt;Make a &lt;a href=&quot;https://en.wikipedia.org/wiki/Tail_call&quot;&gt;tail-recursive&lt;/a&gt; function use a fixed amount of stack space, preventing
the fabled &lt;a href=&quot;https://en.wikipedia.org/wiki/Stack_overflow&quot;&gt;stack overflow&lt;/a&gt;.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Sometimes, achieving the second item is called &lt;em&gt;using a &lt;a href=&quot;https://en.wikipedia.org/wiki/Trampoline_(computing)&quot;&gt;trampoline&lt;/a&gt;&lt;/em&gt;, because
we enter the recursive function but on &amp;quot;&lt;em&gt;recursion&lt;/em&gt;&amp;quot;, we jump right back out.&lt;/p&gt;
&lt;p&gt;The technique is also called &amp;quot;tail-recursion elimination&amp;quot; or &amp;quot;tail call
optimization&amp;quot;.&lt;/p&gt;
&lt;p&gt;In this post I want to offer a very condensed version of this story that focuses
on the results. A motivation, really. You should read &lt;a href=&quot;http://raganwald.com/2018/09/10/why-y.html&quot;&gt;Reginald&amp;#39;s article&lt;/a&gt;
to know about the gory details.&lt;/p&gt;
&lt;p&gt;I also &lt;a href=&quot;https://github.com/raganwald/raganwald.github.com/issues/134&quot;&gt;simplified&lt;/a&gt; the combinators&amp;#39; implementation ‚Äî to make them more idiomatic,
and, in my opinion, easier to understand.&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&quot;the-mockingbird-code-injection&quot;&gt;The Mockingbird (Code Injection)&lt;/h2&gt;
&lt;p&gt;Let&amp;#39;s start with a recursive (JavaScript) function:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;language-javascript&quot;&gt;const is_even = n =&amp;gt;
    (n === 0) || !is_even(n - 1);&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This implement a very inefficient way to check if a number is even. It&amp;#39;s a toy
example, obviously.&lt;/p&gt;
&lt;p&gt;Let&amp;#39;s take our first goal first: &amp;quot;inject code at each recursive call in a
recursive function&amp;quot;.&lt;/p&gt;
&lt;p&gt;To achieve this, we need to rewrite the function in a different form. Here is
the so-called &amp;quot;mockingbird form&amp;quot;:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;language-javascript&quot;&gt;const mock_is_even = (myself, n) =&amp;gt;
    (n === 0) || !myself(myself, n - 1);&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;code&gt;is_even&lt;/code&gt; now take a &lt;code&gt;myself&lt;/code&gt; function as argument, which it called recursively,
passing itself along.&lt;/p&gt;
&lt;p&gt;We can call &lt;code&gt;mock_is_even(mock_is_even, 10)&lt;/code&gt;, and it will behave just like
&lt;code&gt;is_even(10)&lt;/code&gt;. So far that&amp;#39;s pretty useless.&lt;/p&gt;
&lt;p&gt;We can re-implement &lt;code&gt;is_even&lt;/code&gt; in terms of &lt;code&gt;mock_is_even&lt;/code&gt; using the &amp;quot;mockingbird&amp;quot;
combinator:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;language-javascript&quot;&gt;const mockingbird =
    fn =&amp;gt;
        (...args) =&amp;gt;
            fn(fn, ...args);

const is_even = mockingbird(mock_is_even);&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Okay, that works: when we call &lt;code&gt;is_even(10)&lt;/code&gt;, the call becomes
&lt;code&gt;mock_is_even(mock_is_even, 10)&lt;/code&gt;, exactly what we wanted.&lt;/p&gt;
&lt;p&gt;What&amp;#39;s the point?&lt;/p&gt;
&lt;p&gt;Well, now we can inject code. Assume we want to memoize the function. After all,
the result of &lt;code&gt;is_even(X)&lt;/code&gt; will always be the same for a given &lt;code&gt;X&lt;/code&gt;.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;language-javascript&quot;&gt;const memoized = fn =&amp;gt; {
    const map = new Map();
    return (...args) =&amp;gt; {
        const key = JSON.stringify(args);
        return map[key] || (map[key] = fn(args));
    }
}

const is_even_memo = mockingbird(memoized(mock_is_even));&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We can verify it&amp;#39;s working by measuring the run time:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;language-javascript&quot;&gt;console.time(&amp;#39;slow&amp;#39;);
is_even_memo(100); // not memoized yet
console.timeEnd(&amp;#39;slow&amp;#39;);

console.time(&amp;#39;fast&amp;#39;);
is_even_memo(100); // memoized
console.timeEnd(&amp;#39;fast&amp;#39;);&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&quot;the-y-combinator-better-code-injection&quot;&gt;The Y Combinator (Better Code Injection)&lt;/h2&gt;
&lt;p&gt;This &lt;code&gt;myself(myself, ...)&lt;/code&gt; business is ugly. Can we do better? Yes.&lt;/p&gt;
&lt;p&gt;Instead of the mockingbird form:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;language-javascript&quot;&gt;const mock_is_even = (myself, n) =&amp;gt;
    (n === 0) || !myself(myself, n - 1);&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We can write our function in Y form:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;language-javascript&quot;&gt;const Y_is_even = (myself, n) =&amp;gt;
    (n === 0) || !myself(n - 1);&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;And here is how we derive the &lt;code&gt;is_even&lt;/code&gt; from the Y combinator:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;language-javascript&quot;&gt;const Y = fn =&amp;gt; {
    const wrapper = (...args) =&amp;gt; fn(wrapper, ...args);
    return wrapper;
}

const is_even = Y(Y_is_even);&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Injection is done the same way as before:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;language-javascript&quot;&gt;const is_even_memo = Y(memoized(Y_is_even));&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Let&amp;#39;s explain: the Y combinator is similar to the mockingbird, but takes care of
passing the function to itself, so that we don&amp;#39;t need to do it in Y-form
functions, unlike in mockingbird-form.&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;http://raganwald.com/2018/09/10/why-y.html&quot;&gt;Reginald&amp;#39;s post&lt;/a&gt; provides the traditional way to express the combinator,
using only function parameters, whereas we &amp;quot;cheat&amp;quot; by using a variable inside
the function. If you want to understand the Y combinator&amp;#39;s root in &lt;a href=&quot;https://en.wikipedia.org/wiki/Lambda_calculus&quot;&gt;lambda
calculus&lt;/a&gt;, give the post a read!&lt;/p&gt;
&lt;h2&gt;The Longtailed Widowbird&lt;br/&gt; (Tail Recursion Elimination / Trampolines)&lt;/h2&gt;

&lt;p&gt;Let&amp;#39;s move on to our second goal: &amp;quot;Make a &lt;a href=&quot;https://en.wikipedia.org/wiki/Tail_call&quot;&gt;tail-recursive&lt;/a&gt; function use a fixed
amount of stack space, preventing the fabled &lt;a href=&quot;https://en.wikipedia.org/wiki/Stack_overflow&quot;&gt;stack overflow&lt;/a&gt;.&amp;quot;&lt;/p&gt;
&lt;p&gt;This process will work with functions written in Y-form ‚Äî but only as long as
they are &lt;em&gt;tail-recursive&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;Our &lt;code&gt;Y_is_even&lt;/code&gt; function is not tail recursive, pecause of that pesky &lt;code&gt;!&lt;/code&gt;
operator, which is applied after the call to &lt;code&gt;myself&lt;/code&gt; returns.&lt;/p&gt;
&lt;p&gt;Fortunately, we can rewrite it to be tail-recursive:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;language-javascript&quot;&gt;const Y_is_even_tailrec = (myself, n) =&amp;gt;
    n === 0 ? true
    n === 1 ? false
    : myself(n - 2);&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The idea behind the longtailed widowbird is that, instead of injecting code
around the recursive function call, we will &lt;em&gt;replace&lt;/em&gt; the recursive call by code
that returns a function (which executes the &amp;quot;recursive&amp;quot; function call).&lt;/p&gt;
&lt;p&gt;Once we get this function, we can call it. If it does another recursive call, it
will return another function, which we can call as well. And so on and so forth.
We call the returned functions in a loop, until we get the final result.
Recursion has been eliminated in favor of iteration!&lt;/p&gt;
&lt;p&gt;Here is the longtailed widowbird combinator:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;language-javascript&quot;&gt;const longtailed = fn =&amp;gt; (...args0) =&amp;gt; {

    class Thunk {
        constructor (delayed) {
            this.delayed = delayed;
        }

        evaluate() {
            return this.delayed();
        }
    }

    const wrapper = (...args) =&amp;gt;
        new Thunk(() =&amp;gt; fn(wrapper, ...args));

    let value = fn(wrapper, ...args0);

    while (value instanceof Thunk)
        value = value.evaluate();

    return value;
}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Let&amp;#39;s go over this.&lt;/p&gt;
&lt;p&gt;The &lt;code&gt;Thunk&lt;/code&gt; class is just a way to identify the functions we need to execute in
the loop (it&amp;#39;s used in the &lt;code&gt;value instancceof Thunk&lt;/code&gt; test). If we didn&amp;#39;t have
this class and just tested for JavaScript&amp;#39;s &lt;code&gt;Function&lt;/code&gt; class, our combinator
wouldn&amp;#39;t work with recursive functions that return functions!&lt;/p&gt;
&lt;p&gt;We do the same &lt;code&gt;wrapper&lt;/code&gt; trick as in the Y combinator, but this time we also
wrap the call in a function we store in a &lt;code&gt;Thunk&lt;/code&gt; instance.&lt;/p&gt;
&lt;p&gt;Then we get the initial value and we start iterating, until a result is
obtained!&lt;/p&gt;
&lt;p&gt;Let&amp;#39;s try this!&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;language-javascript&quot;&gt;const iter_is_even = longtailed(Y_is_even_tailrec);

// No problem!
iter_is_even(1000000);

// Maximum call stack size exceeded
is_even(1000000);
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Can we still memoize? Of course:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;language-javascript&quot;&gt;const iter_is_even_memo = longtailed(memoized(Y_is_even_tailrec));&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;And that&amp;#39;s it folks! Code injection in recursive functions, and tail call
optimization in JavaScript, easy as pie!&lt;/p&gt;
&lt;p&gt;You can find all the code in this article collected &lt;a href=&quot;https://gist.github.com/norswap/be5fa7938f8331a252d3ff79e61e5834&quot;&gt;in this gist&lt;/a&gt;.&lt;/p&gt;
      </description>
      <pubDate>2019-08-31T22:00:00.000Z</pubDate>
      <link>http://norswap.com/js-trampolines</link>
      <guid isPermaLink="true">http://norswap.com/js-trampolines</guid>
    </item>
    <item>
      <title>The Expression Problem in Java (Litterature Review)</title>
      <description>
&lt;link href=&quot;https://cdnjs.cloudflare.com/ajax/libs/prism/1.16.0/themes/prism.css&quot; rel=&quot;stylesheet&quot; /&gt;

&lt;!-- &lt;link href=&quot;https://cdnjs.cloudflare.com/ajax/libs/prism/1.16.0/themes/prism-tomorrow.min.css&quot; rel=&quot;stylesheet&quot; /&gt; --&gt;

&lt;p&gt;Previously: &lt;a href=&quot;/java-visitor-pattern&quot;&gt;The Visitor Pattern in Java 8&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;/java-visitor-pattern&quot;&gt;Last time&lt;/a&gt; I presented a way to implement the visitor pattern, by
taking advantage of Java 8&amp;#39;s &lt;code&gt;default&lt;/code&gt; interface methods.&lt;/p&gt;
&lt;p&gt;In the process I said this was a partial solution to the &lt;a href=&quot;https://en.wikipedia.org/wiki/Expression_problem&quot;&gt;expression problem&lt;/a&gt;,
which was defined as:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;The goal is to define a datatype by cases, where one can add new cases to the
datatype and new functions over the datatype, without recompiling existing
code, and while retaining static type safety (e.g., no casts).&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Recall that in the context of Java, we can think of a &lt;em&gt;datatype&lt;/em&gt; as an interface
or parent class, and of a &lt;em&gt;case&lt;/em&gt; as a class implementing/extending the interface
or parent. When using this interpretation we will call the &lt;em&gt;cases&lt;/em&gt; &amp;quot;&lt;em&gt;data
classes&lt;/em&gt;&amp;quot;, which is a bit less awkward.&lt;/p&gt;
&lt;p&gt;On the other hand, some of the papers we will review will take another
interpretation in order to produce an interesting solution.&lt;/p&gt;
&lt;p&gt;The solution I presented last time is partial, because it is not strictly
type-safe: it uses a cast.&lt;/p&gt;
&lt;p&gt;Today, I want to look at the solutions that have been proposed in the
litterature, and try to extract their guiding insights, and show their
respective strengths and shortcomings.&lt;/p&gt;
&lt;h2 id=&quot;the-contenders&quot;&gt;The Contenders&lt;/h2&gt;
&lt;p&gt;While the litterature on the expression problem in Java-like object-oriented
languages is surprisingly rich, I want to focus specifically on three papers
which I think covers the space of interesting solutions:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;The Expression Problem Revisited: Four new solutions using generics&lt;/strong&gt;, Mads
Torgersen, &lt;em&gt;ECOOP 2004&lt;/em&gt; &lt;a href=&quot;http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.85.2323&quot;&gt;[link with pdf]&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Extensibility for the Masses: Practical Extensibility with Object
Algebras&lt;/strong&gt;, Bruno C. d. S. Oliveira &amp;amp; William R. Cook, &lt;em&gt;ECOOP 2012&lt;/em&gt; &lt;a href=&quot;https://i.cs.hku.hk/~bruno/oa/&quot;&gt;[link with pdf]&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;The expression problem, trivially!&lt;/strong&gt;, Yanlin Wang &amp;amp; Bruno C. d. S. Oliveira,
&lt;em&gt;Modularity 2016&lt;/em&gt;, &lt;a href=&quot;https://i.cs.hku.hk/~bruno/papers/Modularity2016.pdf&quot;&gt;[pdf]&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Since the first paper actually presents four solutions, that gives us 6
solutions to review. I&amp;#39;ll also throw my partial solution into the mix for
comparison&amp;#39;s sake.&lt;/p&gt;
&lt;h2 id=&quot;the-problems-raison-d√™tre-ambiguous-call-sites&quot;&gt;The Problem&amp;#39;s Raison d&amp;#39;√ätre: Ambiguous Call Sites&lt;/h2&gt;
&lt;p&gt;For the expression problem to be interesting &lt;em&gt;at all&lt;/em&gt;, it has to involve
ambiguous call sites: the same piece of code has to perform a method call which
could be dispatched to a specialized method for any of datatype cases.&lt;/p&gt;
&lt;p&gt;Said otherwise, if every piece of code is statically typed and doesn&amp;#39;t involve
any kind of &lt;a href=&quot;/polymorphism/&quot;&gt;polymorphism&lt;/a&gt; (e.g. inheritance or generics), then plain static
overloading is enough, and you don&amp;#39;t have a &lt;em&gt;problem&lt;/em&gt; in the first place.&lt;/p&gt;
&lt;p&gt;Therefore, to build a type-safe solution to the expression problem, two big
avenues are open.&lt;/p&gt;
&lt;p&gt;The first one has to be built into the compiler: the compiler will check that
implementations of operations (which can be added by anyone, not just the
original author of the datatype) exist for every data class. But this doesn&amp;#39;t
seem to exist. I said as much in &lt;a href=&quot;/java-visitor-pattern&quot;&gt;the previous post&lt;/a&gt;:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;In theory, there is nothing that prevents solving the expression problem at
the language level. In an ideal world, we&amp;#39;d just be able to add abstract
extension methods that have to be implemented for all classes implementing the
interface. The linker would then verify that these methods were implemented
for all such classes, and generate the proper virtual method tables. But no
such object-oriented language exists.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;The second avenue is to somehow &lt;em&gt;carry&lt;/em&gt; the specialized implementation to the
call sites. This is what every solution in the litterature does, each in its own
way.&lt;/p&gt;
&lt;p&gt;That is also how &lt;a href=&quot;https://en.wikipedia.org/wiki/Type_class&quot;&gt;typeclasses&lt;/a&gt; work in Haskell. In this case, it&amp;#39;s the typeclass
instances that carry the operation&amp;#39;s implementation to the call site.&lt;/p&gt;
&lt;p&gt;In light of this, the statement of the expression problem is somewhat
problematic, because it doesn&amp;#39;t specify which shape the ambiguous call sites can
take.&lt;/p&gt;
&lt;p&gt;But I can think of two very interesting examples.&lt;/p&gt;
&lt;p&gt;The first one is to apply one of the specialized methods on a list of data class
instances, &lt;em&gt;whose exact type is not known&lt;/em&gt; (said otherwise, which just know they
are instances of the datatype).&lt;/p&gt;
&lt;p&gt;Sadly, no type-safe solution in the litterature can do that. Our solution can,
but again, it isn&amp;#39;t type safe.&lt;/p&gt;
&lt;p&gt;Interestingly, Haskell can do this only if using a compiler extension
introducing &lt;a href=&quot;https://wiki.haskell.org/Existential_type&quot;&gt;existential types&lt;/a&gt;. An existential type is basically just a pair of
a type and its associated typeclass instance for a given typeclass. The
existential type just says &amp;quot;here is an instance of &lt;em&gt;something&lt;/em&gt; that has an
instance for the given typeclass&amp;quot;. Then you have to use a list of
existentially-typed values ‚Äî which crucially you mean you can&amp;#39;t reuse a
pre-existing list that isn&amp;#39;t existentially-typed. There has to be a way to
(statically) retrieve the correct typeclass instance when constructing the list.&lt;/p&gt;
&lt;p&gt;The second example is, fortunately, the one that is always used as a benchmark
in the litterature: a tree structure where each node is a data class instance.&lt;/p&gt;
&lt;p&gt;This example is easier because it is possible to inject type information while
building the tree ‚Äî something that is not possible with plain lists, but is
exactly what we&amp;#39;re doing when we&amp;#39;re building an existentially-typed list.&lt;/p&gt;
&lt;h2 id=&quot;the-benchmark-problem&quot;&gt;The Benchmark Problem&lt;/h2&gt;
&lt;p&gt;In particular, the typical example uses trees that represent arithmetic
expressions.&lt;/p&gt;
&lt;p&gt;This benchmark example was there since the beginning, and is certainly partially
responsible for the name of the &lt;em&gt;expression&lt;/em&gt; problem.&lt;/p&gt;
&lt;p&gt;Our datatype is an &lt;code&gt;Exp&lt;/code&gt; type.&lt;/p&gt;
&lt;p&gt;The cases for the datatype are:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;Lit&lt;/code&gt;: an integer literal&lt;/li&gt;
&lt;li&gt;&lt;code&gt;Add&lt;/code&gt;: addition of two expression&lt;/li&gt;
&lt;li&gt;&lt;code&gt;Neg&lt;/code&gt;: negation of an expression ‚Äî which is added as an extension&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Initially, we&amp;#39;ll have a single operation: &lt;code&gt;Print&lt;/code&gt; which prints a string
representation of the expression to standard output. Later we&amp;#39;ll add &lt;code&gt;Eval&lt;/code&gt;,
which evaluates the expression.&lt;/p&gt;
&lt;h2 id=&quot;norswaps-solution&quot;&gt;Norswap&amp;#39;s Solution&lt;/h2&gt;
&lt;p&gt;To ease us into the problem, let&amp;#39;s see a type-unsafe solution to the problem
using my formulation of the &lt;a href=&quot;/java-visitor-pattern&quot;&gt;visitor pattern&lt;/a&gt;.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;https://gist.github.com/norswap/9d4dd9ae5c0fd2ef652a1f41778467ea#file-norswapep-java&quot;&gt;Norswap&amp;#39;s Solution Code&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Compared to the previous post, the solution has been simplified/crippled a
little bit for the sake of brevity and better comparison. We no longer use
&lt;em&gt;implementation interfaces&lt;/em&gt;, which allow the composition of independently
developped extensions (i.e. new data classes or operations).&lt;/p&gt;
&lt;p&gt;None of Torgersen&amp;#39;s solutions can handle composition. This is excusable, as our
trick (using &lt;code&gt;default&lt;/code&gt; methods in interfaces) wasn&amp;#39;t available at the time the
paper was written.&lt;/p&gt;
&lt;h2 id=&quot;the-choice-for-data-structure-solutions&quot;&gt;The Choice for Data-Structure Solutions&lt;/h2&gt;
&lt;p&gt;The nature of the expression problem is that each time we add a new data class,
we need to add corresponding implementations for the existing operations.
Conversely, each time we add a new operation, we need to implement it for all
existing data classes.&lt;/p&gt;
&lt;p&gt;Unfortunately, it&amp;#39;s not as simple as just writing them. The &amp;quot;compiler&amp;quot; solution
that neatly composes everything for us isn&amp;#39;t available. Therefore, we will have
to take care of the plumbing ourselves.&lt;/p&gt;
&lt;p&gt;As long as we keep one dimension fixed, everything is easy. If we have a fixed
set of operations, they can be encoded as an interface which we can just
implement. If we have a fixed set of data classes, the simple visitor pattern
suffices, and we can just implement the visitor interface to add new operations.&lt;/p&gt;
&lt;p&gt;Things become tricky when we need to add both new operations and new data
classes.&lt;/p&gt;
&lt;p&gt;There are fundamentally two ways to do this.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Option 1&lt;/strong&gt;: replacing the data classes. Each time we add a new operation, we
need to extend all data classes so that they may handle the new operation.
Operation&amp;#39;s implementation will live inside the data classes.&lt;/p&gt;
&lt;p&gt;This option means we need to control/parameterize the creation of our data
structure. Whenever we add a new operation, we need to swap the classes that are
being instantiated!&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Option 2&lt;/strong&gt;: replacing the operations. Each time we add a new data class, we
need to extend all existing operations so that they may handle the new data
class. Operation&amp;#39;s implementation will typically live in some kind of visitor
implementation.&lt;/p&gt;
&lt;p&gt;This options means we need to control/parameterized the operation&amp;#39;s call sites.
Whenever we add a new data class, we need to swap the object that holds the
operation&amp;#39;s implementations, lest it doesn&amp;#39;t work for the new data class.&lt;/p&gt;
&lt;p&gt;My solution uses option 2.&lt;/p&gt;
&lt;h2 id=&quot;torgersens-1st-solution-data-centered&quot;&gt;Torgersen&amp;#39;s 1st Solution: Data-Centered&lt;/h2&gt;
&lt;p&gt;This is the first solution in the &amp;quot;&lt;em&gt;The Expression Problem Revisited: Four new
solutions using generics&lt;/em&gt;&amp;quot; (&lt;a href=&quot;http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.85.2323&quot;&gt;link&lt;/a&gt;) paper by Mads Torgersen. Discussion of
the other three solutions will follow.&lt;/p&gt;
&lt;p&gt;This is a solution that takes &lt;em&gt;option 1&lt;/em&gt; from the last section: replacing the
data classes. When adding a new operation, we subclass all existing data
classes. The code that create data strutures needs to be parameterized.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;https://gist.github.com/norswap/9d4dd9ae5c0fd2ef652a1f41778467ea#file-torgersendataep-java&quot;&gt;Torgersen&amp;#39;s Data-Centered Solution Code&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;There are two difficulties in this solution that not readily apparent when
&lt;em&gt;option 1&lt;/em&gt; is stated briefly.&lt;/p&gt;
&lt;p&gt;First, in order to make the solution type-safe, it is necessary to know which
operations the nodes in the expression tree implement. This means there needs to
be someway to &amp;quot;carry the type&amp;quot; to the nodes that are down in the tree. &lt;/p&gt;
&lt;p&gt;In this solution, this is done via generics, and in particular the use of a
F-bound: &lt;code&gt;C extends Exp&amp;lt;C&amp;gt;&lt;/code&gt;. F-bounds are a crude way to encode &amp;quot;self-types&amp;quot; in
Java. Basically it lets us use &lt;code&gt;C&lt;/code&gt; as though it meant &amp;quot;the type of this class&amp;quot;
(or, like here, the type of one of its superclasses or superinterfaces).
However, to use an F-bound, you need to &amp;quot;fix&amp;quot; &lt;code&gt;C&lt;/code&gt;. This is the role of all the
classes whose name end with &lt;code&gt;F&lt;/code&gt;, such as &lt;code&gt;class LitF extends Lit&amp;lt;ExpF&amp;gt;
implements ExpF&lt;/code&gt;. Unfortunately, that makes the solution more verbose as we need
to actually add in all of these &lt;code&gt;F&lt;/code&gt; classes.&lt;/p&gt;
&lt;p&gt;The second difficulty ‚Äî which is only hinted at in the paper ‚Äî is the need to
carry the node creation logic to the places where you would normally call a data
class constructor. Since there may be a lot of different types of nodes, it
makes sense to collect the creators in a factory.&lt;/p&gt;
&lt;p&gt;The issue with that is that each time you add a new data case you need to extend
the existing factory. Each time you add a new operation, you not only need to
extend every data class, but also to create a whole new factory that return
instances of these new classes.&lt;/p&gt;
&lt;p&gt;So this works, but it&amp;#39;s quite verbose and it&amp;#39;s relatively annoying that we
actually need to change the data classes being used when we add new operations.&lt;/p&gt;
&lt;h2 id=&quot;torgersens-2nd-solution-operation-centered&quot;&gt;Torgersen&amp;#39;s 2nd Solution: Operation-Centered&lt;/h2&gt;
&lt;p&gt;This solution takes &lt;em&gt;option 2&lt;/em&gt; outlined above. Each time we add a new data
class, we need to extend all existing operations so that they may handle the new
data class. Operation&amp;#39;s implementation live in a visitor implementation.&lt;/p&gt;
&lt;p&gt;This is also what my own solution does, I will explain the difference below.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;https://gist.github.com/norswap/9d4dd9ae5c0fd2ef652a1f41778467ea#file-torgersenoperationep-java&quot;&gt;Torgersen&amp;#39;s Operation-Centered Solution Code&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;However, there is a big pitfall that comes from the need to be type-safe. For
the initial data classes, there are no issues. But when a new data class is
added, it is necessary to add a new visitor interface. This is as expected.&lt;/p&gt;
&lt;p&gt;However, each data class instance has to know the requirements on the visitors
it can handle. To use our previous examples, a &lt;code&gt;Neg&lt;/code&gt; node can only handle
visitors that implement &lt;code&gt;NegVisitor&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;But it doesn&amp;#39;t stop there. If an &lt;code&gt;Add&lt;/code&gt; node has a &lt;code&gt;Neg&lt;/code&gt; child, it too should
only accept visitors that implement &lt;code&gt;NegVisitor&lt;/code&gt; ‚Äî since they can invoke the
visitor on their children.&lt;/p&gt;
&lt;p&gt;Again, generics come to the rescue: we parameterize all data classes with &lt;code&gt;&amp;lt;V
extends Visitor&amp;gt;&lt;/code&gt; (for the initial data classes) or &lt;code&gt;&amp;lt;V extends NegVisitor&amp;gt;&lt;/code&gt;
(for &lt;code&gt;Neg&lt;/code&gt; ‚Äî same principle would apply if we added new data classes).&lt;/p&gt;
&lt;p&gt;This doesn&amp;#39;t entirely fix the problem. In the &lt;code&gt;visit&lt;/code&gt; methods, it wouldnt work
to call, for instance, &lt;code&gt;add.left.accept(this)&lt;/code&gt;. Why? Because there is no
guarantee that &lt;code&gt;this&lt;/code&gt; has type &lt;code&gt;V&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;Torgersen comes up with a really neat trick to solve this issue, which is to let
the visitor accept itself as an extra parameter of type &lt;code&gt;V&lt;/code&gt;. This parameter will
be supplied by the &lt;code&gt;accept&lt;/code&gt; methods: &lt;code&gt;visitor.visit(visitor, this)&lt;/code&gt; (where
&lt;code&gt;this&lt;/code&gt; is a an instance of a data class such as &lt;code&gt;Add&amp;lt;V&amp;gt;&lt;/code&gt;). Since &lt;code&gt;visitor&lt;/code&gt; has
type &lt;code&gt;V&lt;/code&gt; there, this type-checks ok.&lt;/p&gt;
&lt;p&gt;The cost? Once again, we can&amp;#39;t reuse our expression trees. They now have to be
parameterized differently depending on added data classes. So creation logic has
to be parameterized by the proper visitor interface (note you can&amp;#39;t really see
this is our simplistic demo code). At least, we don&amp;#39;t need verbose factories
this time.&lt;/p&gt;
&lt;h2 id=&quot;torgersens-3rd-solution-operation-centered-with-object-level-extensibility&quot;&gt;Torgersen&amp;#39;s 3rd Solution: Operation-Centered with Object-Level Extensibility&lt;/h2&gt;
&lt;p&gt;This solution is an extension of the second solution. The goal is to relax the
requirement on the control of all instantiation sites.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;https://gist.github.com/norswap/9d4dd9ae5c0fd2ef652a1f41778467ea#file-torgersenoperationep-java&quot;&gt;Torgersen&amp;#39;s Operation-Centered with Object-Level Extensibility Solution Code&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;From the perspective of the previous solution, the goal here is to make it
possible to reuse old &lt;code&gt;Add&amp;lt;Visitor&amp;gt;&lt;/code&gt; and &lt;code&gt;Lit&amp;lt;Visitor&amp;gt;&lt;/code&gt; trees that were
instantiated without knowing that &lt;code&gt;Neg&lt;/code&gt; existed. These node will still work if
passed a &lt;code&gt;NegVisitor&lt;/code&gt; (which extends &lt;code&gt;Visitor&lt;/code&gt;)!&lt;/p&gt;
&lt;p&gt;The author calls this ability to reuse old trees &lt;em&gt;object-level extensibility&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;And since the old trees were created before we added &lt;code&gt;Neg&lt;/code&gt;, they couldn&amp;#39;t
contain &lt;code&gt;Neg&lt;/code&gt; nodes, and so using plain &lt;code&gt;Visitor&lt;/code&gt; implementations is fine as
well.&lt;/p&gt;
&lt;p&gt;Achieving object-level extensibility is actually pretty easy. In the data
classes, just change the node&amp;#39;s children type to &lt;code&gt;Exp&amp;lt;? super V&amp;gt;&lt;/code&gt;. Without
entering into the details, this means that &lt;code&gt;Add&amp;lt;NegVisitor&amp;gt;&lt;/code&gt; may have children
that with type &lt;code&gt;Exp&amp;lt;Visitor&amp;gt;&lt;/code&gt; or &lt;code&gt;Exp&amp;lt;NegVisitor&amp;gt;&lt;/code&gt;. On the other hand
&lt;code&gt;Add&amp;lt;Visitor&amp;gt;&lt;/code&gt; may not have a child of type &lt;code&gt;Exp&amp;lt;NegVisitor&amp;gt;&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;This effectively enables reusing old trees in newer trees. &lt;/p&gt;
&lt;p&gt;There is only one catch: your ability to rewrite the trees becomes limited.
Since &lt;code&gt;Add&amp;lt;Visitor&amp;gt;&lt;/code&gt; may not have children of type &lt;code&gt;Exp&amp;lt;NegVisitor&amp;gt;&lt;/code&gt; this may
hamper your ability to write involved tree rewrite logic that would need to
assign a newer tree as a child of an older tree.&lt;/p&gt;
&lt;p&gt;However, as the author correctly notes, there are plenty of use-cases (maybe
even most of them) that do not involve such kind of tree rewriting.&lt;/p&gt;
&lt;p&gt;If type-safety is a must-have for you and you don&amp;#39;t need tree rewrites, this is
pretty good. You&amp;#39;ll still pay a cost of sorts by having to carry these annoyings
type parameters everywhere.&lt;/p&gt;
&lt;h2 id=&quot;torgersens-4th-solution-type-unsafe-hybrid&quot;&gt;Torgersen&amp;#39;s 4th Solution: Type-Unsafe Hybrid&lt;/h2&gt;
&lt;p&gt;This one is interesting too.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;https://gist.github.com/norswap/9d4dd9ae5c0fd2ef652a1f41778467ea#file-torgersenhybridep-java&quot;&gt;Torgersen&amp;#39;s Hybrid Solution&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://gist.github.com/norswap/9d4dd9ae5c0fd2ef652a1f41778467ea#file-torgersenbetterhybridep-java&quot;&gt;Torgersen&amp;#39;s Hybrid Solution, Without Generics&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Torgersen starts from the an operation-centered visitor solution (much like his
second solution) but pairs each operation (i.e. visitor implementation) with an
interface that defines the signature of the operation. Data classes can choose
to implement this interface. If they do so, the operation will notice (via an
&lt;code&gt;instanceof&lt;/code&gt; check) and call the implementation ‚Äî otherwise it falls back on the
visitor pattern.&lt;/p&gt;
&lt;p&gt;The solution isn&amp;#39;t type-safe because Torgersen opts not to force the children of
each data class node to encode their visitor interface. So instead of being
typed as &lt;code&gt;Exp&amp;lt;V&amp;gt;&lt;/code&gt; or &lt;code&gt;Exp&amp;lt;? extends V&amp;gt;&lt;/code&gt; as in solution 2 and 3 respectively,
they are simply typed as &lt;code&gt;Exp&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;The payload of foregoing type-safety here is that control over the creation
logic is no longer necessary. You can finally have data classes whose types and
implementations don&amp;#39;t change depending on subsequent extensions. In that, it is
similar to my solution.&lt;/p&gt;
&lt;p&gt;If you know in advance all operations you need to implement, you can also avoid
extending existing operations when you introduce a new data class, by having the
data class implement the operations&amp;#39; associated interfaces.&lt;/p&gt;
&lt;p&gt;Because the lack of type safety, when an expression accepts a visitor, it must
verify that this visitor actually can handle the expression&amp;#39;s data class or fall
back on some general behaviour (at worse, throw a runtime exception, which is
what my solution does).&lt;/p&gt;
&lt;p&gt;To make all of this work, the solution involves some helper super-classes, which
can be slightly confusing.&lt;/p&gt;
&lt;p&gt;I&amp;#39;d also argue that the most use of generics in this solution is woefully
unecessary ‚Äî it just saves on inlining two lines of logic into every visitor,
which you sort of have to do &lt;em&gt;anyway&lt;/em&gt; because Java doesn&amp;#39;t support &lt;code&gt;instanceof&lt;/code&gt;
on generic type arguments (which are &lt;a href=&quot;https://www.baeldung.com/java-type-erasure&quot;&gt;erased&lt;/a&gt;). Hence I made a &lt;a href=&quot;https://gist.github.com/norswap/9d4dd9ae5c0fd2ef652a1f41778467ea#file-torgersenbetterhybridep-java&quot;&gt;simplified
solution&lt;/a&gt; that eliminates non-essential generics use, and
simplifies the scaffolding considerably, making it &lt;strong&gt;much&lt;/strong&gt; easier to
understand, in my humble opinion.&lt;/p&gt;
&lt;p&gt;Compared to my solution, this one is more complicated, but has the important
benefit that data classes can be added without extending all operations
individually, greatly reducing verbosity in that scenario.&lt;/p&gt;
&lt;h2 id=&quot;object-algebras&quot;&gt;Object Algebras&lt;/h2&gt;
&lt;p&gt;We now discussion the solution from the &amp;quot;Extensibility for the Masses: Practical
Extensibility with Object Algebras&amp;quot; paper (&lt;a href=&quot;https://i.cs.hku.hk/~bruno/oa/&quot;&gt;link&lt;/a&gt;). This one is quite
different from those we discussed previously, and conforms to neither of our two
options ‚Äî because it doesn&amp;#39;t encode data as a data structure at all!&lt;/p&gt;
&lt;p&gt;Instead, data is encoded as a tree of method calls. Here is an example:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;language-java&quot;&gt;interface Algebra&amp;lt;E&amp;gt; {
    E lit (int value);
    E add (E left, E right);
}

public static &amp;lt;E&amp;gt; E expression (Algebra&amp;lt;E&amp;gt; a) {
    return a.add(a.lit(1), a.lit(2)); // 1 + 2
}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The &lt;code&gt;expression&lt;/code&gt; method encodes the expression tree &lt;code&gt;1 + 2&lt;/code&gt; made of an &amp;quot;add
node&amp;quot; with two &amp;quot;literal node&amp;quot; child. Of course, there are no such nodes ‚Äî it&amp;#39;s
just a method!&lt;/p&gt;
&lt;p&gt;To do anything useful with &lt;code&gt;expression&lt;/code&gt;, we need to supply an &lt;code&gt;Algebra&amp;lt;E&amp;gt;&lt;/code&gt; where
&lt;code&gt;E&lt;/code&gt; is an (unconstrainted) type used to represent the result of an operation on
one of our &amp;quot;nodes&amp;quot;. So for instance, &lt;code&gt;a.lit(1)&lt;/code&gt; will return a value of type &lt;code&gt;E&lt;/code&gt;.
The &lt;code&gt;add&lt;/code&gt; method returns a value of type &lt;code&gt;E&lt;/code&gt;, but also takes as parameter two
values of type &lt;code&gt;E&lt;/code&gt;, corresponding to the result of &amp;quot;evaluating&amp;quot; its two
operands.&lt;/p&gt;
&lt;p&gt;To define an operation, we need to implement &lt;code&gt;Algebra&amp;lt;E&amp;gt;&lt;/code&gt;. Here is a full
implementation that uses the same example as previously:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;https://gist.github.com/norswap/9d4dd9ae5c0fd2ef652a1f41778467ea#file-objectalgebraep-java&quot;&gt;Object Algebra Solution&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;So there our operations are printing and evaluation. We actually use two
different techniques for these two operations.&lt;/p&gt;
&lt;p&gt;In the case of &lt;code&gt;PrintAlgebra&lt;/code&gt;, we implement &lt;code&gt;Algebra&amp;lt;Print&amp;gt;&lt;/code&gt; where &lt;code&gt;Print&lt;/code&gt; is a
functional interface we defined with a &lt;code&gt;print()&lt;/code&gt; method. Therefore, calling
&lt;code&gt;expression(new PrintAlgebra())&lt;/code&gt; will return an object that can be used to print
the expression.&lt;/p&gt;
&lt;p&gt;This is not the most direct avenue ‚Äî we could have opted to implement
&lt;code&gt;Algebra&amp;lt;String&amp;gt;&lt;/code&gt; instead and have &lt;code&gt;lit&lt;/code&gt; and &lt;code&gt;add&lt;/code&gt; return their string
representation directly. In fact, we take this approach with &lt;code&gt;EvalAlgebra&lt;/code&gt; which
implements &lt;code&gt;Algebra&amp;lt;Integer&amp;gt;&lt;/code&gt; ‚Äî there, &lt;code&gt;lit&lt;/code&gt; and &lt;code&gt;add&lt;/code&gt; directly return the
integer they evaluate to.&lt;/p&gt;
&lt;p&gt;Finally, a really neat trick not mentionned in the paper is that we can build an
actual data structure from the functional encoding. For this, simply make an
algebra that implements &lt;code&gt;Algebra&amp;lt;Exp&amp;gt;&lt;/code&gt; or &lt;code&gt;NegAlgebra&amp;lt;Exp&amp;gt;&lt;/code&gt; (depending on your
needs, and assuming &lt;code&gt;Exp&lt;/code&gt; is the parent class) and have each method return the
node it corresponds to.&lt;/p&gt;
&lt;p&gt;Turning these data structures back into an algebra encoding is unfortunately not
possible. One could imagine that &lt;code&gt;Exp&lt;/code&gt; has a &lt;code&gt;E visit(Algebra&amp;lt;E&amp;gt;)&lt;/code&gt; method that
is overriden in data classes to simply call the corresponding algebra method.
The problem happens when you have introduced new data cases. If you added a
&lt;code&gt;neg&lt;/code&gt; method in &lt;code&gt;NegAlgebra&amp;lt;E&amp;gt;&lt;/code&gt;, now you need the signature to be &lt;code&gt;E
visit(NegAlgebra&amp;lt;E&amp;gt;)&lt;/code&gt;. This is &lt;em&gt;almost&lt;/em&gt; feasible, supposing we could
parameterize &lt;code&gt;Exp&lt;/code&gt; as follow: &lt;code&gt;Exp&amp;lt;A extends Algebra&amp;gt;&lt;/code&gt; and then define the
method &lt;code&gt;E visit (A&amp;lt;E&amp;gt;)&lt;/code&gt;. Unfortunately that would make &lt;code&gt;A&lt;/code&gt; a &lt;a href=&quot;https://en.wikipedia.org/wiki/Type_constructor&quot;&gt;higher-order type&lt;/a&gt;
(i.e. a type that takes a parameter, here &lt;code&gt;E&lt;/code&gt;) and Java doesn&amp;#39;t have those.&lt;/p&gt;
&lt;p&gt;Of course, you could just use &lt;code&gt;Algebra&amp;lt;E&amp;gt;&lt;/code&gt; as a bound and add a cast in there,
type-unsafe but effective.&lt;/p&gt;
&lt;p&gt;When dealing with object algebra, one may be concerned that it&amp;#39;s no longer
possible to &amp;quot;build a data structure dynamically&amp;quot;, i.e. that all data must be
statically defined like in our &lt;code&gt;expression&lt;/code&gt; method.&lt;/p&gt;
&lt;p&gt;That is fortunately not the case. Since the algebra encoding of an expression is
just method calls, any execution flow that calls algebra methods can yield
expressions. And execution can contain conditions, loops, etc. One potential
pitfall is that the whole construction logic needs to be re-run each time we
want to run an operation of our data. If the construction logic is expensive,
this can be a problem. Fortunately there is a solution: simply return a function
object that encodes the expression:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;language-java&quot;&gt;
public E expr1 (NegAlgebra&amp;lt;E&amp;gt; a) {
    return expensive_predicate()
        ? a.add(a.lit(1), a.lit(2))
        : a.add(a.lit(1), a.neg(a.lit(2)));
}

// use: expr1(my_algebra);
// slow!

public E Function&amp;lt;NegAlgebra&amp;lt;E&amp;gt;, E&amp;gt; expr2() {
    return expensive_predicate()
        ? a -&amp;gt; a.add(a.lit(1), a.lit(2))
        : a -&amp;gt; a.add(a.lit(1), a.neg(a.lit(2)));
}

// use: expr2.apply(my_algebra);
// fast!
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;When we pass an algebra to &lt;code&gt;expr2&lt;/code&gt;, &lt;code&gt;expensive_predicate()&lt;/code&gt; is not run ‚Äî it is
only run once when the &lt;code&gt;expr2&lt;/code&gt; is created.&lt;/p&gt;
&lt;p&gt;Finally, object algebra make &amp;quot;tree reuse&amp;quot; easy. You can compose an expression
built with an &lt;code&gt;Algebra&amp;lt;E&amp;gt;&lt;/code&gt; and one built with a &lt;code&gt;NegAlgebra&amp;lt;E&amp;gt;&lt;/code&gt; pretty easily:
the trick is that they only interface using &lt;code&gt;E&lt;/code&gt;, so as long as &lt;code&gt;E&lt;/code&gt; is the same,
anything goes. Of course, this means you have to use &lt;em&gt;compatible&lt;/em&gt; algebras. It
could be argued that is not type-safe (or that it is another advantage): nothing
prevents you from using two algebra with different semantics together, passing
the result of one to the other... as long as &lt;code&gt;E&lt;/code&gt; is the same.&lt;/p&gt;
&lt;p&gt;The paper mentions other interesting possibilities: multi-parameter algebra
(mimicking &lt;a href=&quot;https://en.wikipedia.org/wiki/Type_family&quot;&gt;type families&lt;/a&gt;), combinators for automatic combination of multiple
algebra, as well as allowing extension of the &lt;code&gt;E&lt;/code&gt; parameter (e.g. &lt;code&gt;Eval&amp;lt;E
extends Number&amp;gt; implements Algebra&amp;lt;E&amp;gt;&lt;/code&gt;), ...&lt;/p&gt;
&lt;p&gt;There is a lot to like about object algebra, it&amp;#39;s a really elegant technique ‚Äî
in fact it&amp;#39;s the shortest implementation, and one of the most readable. It has
many advantages, from the possibility of building a real data structure to &amp;quot;tree
reuse&amp;quot;. Perhaps its main weakness is being a bit &lt;em&gt;too&lt;/em&gt; alien to be integrated in
many code bases, where one will &lt;em&gt;need&lt;/em&gt; to have actual data structures. For
instance, in my &lt;a href=&quot;https://github.com/norswap/autumn&quot;&gt;Autumn&lt;/a&gt; parsing library, the parser combinators can&amp;#39;t be
canonically represented as function calls ‚Äî while it is possible to implement
parsing that way (by using objects similar to &lt;code&gt;Print&lt;/code&gt; in our example), it would
be incredibly slow. However it is possible to use an object algebra to build the
parser combinator graph, and to reuse the encoding for visiting it. However,
this is only possible because this graph is immutable (and so will always stay
in sync with its functional encoding).&lt;/p&gt;
&lt;p&gt;It&amp;#39;s definitely a technique to keep in the back of your mind.&lt;/p&gt;
&lt;h2 id=&quot;covariant-return-types&quot;&gt;Covariant Return Types&lt;/h2&gt;
&lt;p&gt;Finally, we look at our last solution, from the paper &amp;quot;The Expression Problem,
Trivially!&amp;quot; (&lt;a href=&quot;https://i.cs.hku.hk/~bruno/papers/Modularity2016.pdf&quot;&gt;link&lt;/a&gt;).&lt;/p&gt;
&lt;p&gt;This solution is very very close to Torgersen&amp;#39;s &lt;a href=&quot;https://gist.github.com/norswap/9d4dd9ae5c0fd2ef652a1f41778467ea#file-torgersendataep-java&quot;&gt;first (data-driven) solution&lt;/a&gt;,
but the essential differences between both is that this solution foregoes the
use of generics in favor of covariant return types. What are covariant return
types? In Java, you can override a method by a method with a different return
type, but only if that type is a subtype of the original return type, for
instance:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;language-java&quot;&gt;abstract class A {
    abstract Object foo();
}

abstract class B extends A {
    @Override String foo();
}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This works because &lt;code&gt;String&lt;/code&gt; is a subclass of &lt;code&gt;Object&lt;/code&gt;. And if you didn&amp;#39;t know,
yes you can override an abstract method without implementing it ‚Äî that&amp;#39;s an
essential feature needed in the covariant solution.&lt;/p&gt;
&lt;p&gt;Let&amp;#39;s have a look at the solution:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;https://gist.github.com/norswap/9d4dd9ae5c0fd2ef652a1f41778467ea#file-covariantep-java&quot;&gt;Covariant Return Type Solution&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Whereas Torgersen&amp;#39;s solution encodes the expression type as an F-shape bounded
generic type parameter (&lt;code&gt;C extends Exp&amp;lt;C&amp;gt;&lt;/code&gt;), and subsequently types children
using this type (e.g. &lt;code&gt;C left, right;&lt;/code&gt; in the &lt;code&gt;Add&lt;/code&gt; class; the covariant
solution defines the children as abstract method whose return type is &lt;code&gt;Exp&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;Both solution need a &amp;quot;fix class&amp;quot;: in Torgersen&amp;#39;s solution, the class fixes &lt;code&gt;C&lt;/code&gt;:
&lt;code&gt;AddF extends Add&amp;lt;ExpF&amp;gt;&lt;/code&gt; and later &lt;code&gt;EvalAddF extends EvalAdd&amp;lt;EvalExpF&amp;gt;&lt;/code&gt;. In the
covariant solution, the methods are overriden with the actual expression type:
simply &lt;code&gt;Exp&lt;/code&gt; in the base case, but &lt;code&gt;EvalExp&lt;/code&gt; in the &amp;quot;eval&amp;quot; extension.&lt;/p&gt;
&lt;p&gt;This is rather neat, and absent some issue I didn&amp;#39;t think of, seems strictly
superior Torgersen&amp;#39;s solution. It does however come with that solution&amp;#39;s other
pitfalls, including the need to parameterize the construction logic. You&amp;#39;ll note
we didn&amp;#39;t include factories in our code for this solution, but we did in
Torgersen&amp;#39;s solution. Don&amp;#39;t let this fool you: they are equally needed (or can
equally be dispensed with) in both cases.&lt;/p&gt;
&lt;h2 id=&quot;discussion--recommendations&quot;&gt;Discussion &amp;amp; Recommendations&lt;/h2&gt;
&lt;p&gt;I came out of this article having learned a lot more than I expected going in.
The impetus for this article was that I couldn&amp;#39;t clearly articulate how the
different solutions worked and how they related to each other.&lt;/p&gt;
&lt;p&gt;I also wanted to make the point that they were needlessly complex and that my
solution was better. Having done the research, I wouldn&amp;#39;t say that this is
necessarily true. Hence the little discussion now to be had about what should be
used when.&lt;/p&gt;
&lt;p&gt;First off, you should try to determine your requirements as precisely as
possible. In particular:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Do you need strict type safety? How do you define that? (What is not allowed
to happen?)&lt;/li&gt;
&lt;li&gt;Do you care about independent extensibility: if two different developers
extend the base framework and redistribute their exensions, can a third
developer come along and compose their extensions without resorting to
modifying the code written by the two first developers?&lt;/li&gt;
&lt;li&gt;Who is going to use the solution? What is its area of surface?&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;With that in mind...&lt;/p&gt;
&lt;p&gt;First off, if you care about independent extensibility, you have no choice but
to use my solution. The others &lt;em&gt;might&lt;/em&gt; be modified to accomodate it, by using
Java 8&amp;#39;s &lt;code&gt;default&lt;/code&gt; interface methods ‚Äî but you&amp;#39;ll have to figure that yourself.
Do keep in mind that this aspect of it wasn&amp;#39;t shown in &lt;a href=&quot;https://gist.github.com/norswap/9d4dd9ae5c0fd2ef652a1f41778467ea#file-norswapep-java&quot;&gt;the example
code&lt;/a&gt; but is explained in &lt;a href=&quot;/java-visitor-pattern&quot;&gt;the previous post&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Beware that independent extensibility does add a lot of boilerplate, and likely
will in other solutions too. And remember my solution isn&amp;#39;t type-safe.&lt;/p&gt;
&lt;p&gt;If you need perfect type safety (do you really?) &lt;strong&gt;and&lt;/strong&gt; you&amp;#39;re using immutable
trees, I would go for Torgensen&amp;#39;s 3rd solution (operation-centered with
object-level extensibility).&lt;/p&gt;
&lt;p&gt;In general, I would try to think hard about whether object algebras can be used
in your use case. In a sense, they&amp;#39;re the most elegant solution. One big caveat:
I would think twice about using them to build a data structure ‚Äî now you have
two representations to keep in sync, and double duties.&lt;/p&gt;
&lt;p&gt;In general, I feel like the sweet spot for them is either small localized
things, or a central paradigm around which everything revolves. I&amp;#39;d be uneasy
about making an object algebra one of many big moving parts in a program. My
programmer&amp;#39;s intuition say this way lay clunky mixed-metaphors.&lt;/p&gt;
&lt;p&gt;I would avoid using the data-centered solutions (Torgersen&amp;#39;s 1st and the
covariant solution) &lt;strong&gt;unless&lt;/strong&gt; object instantiation is very tightly controlled
or centralized in your program. Playing with factories is not super fun.&lt;/p&gt;
&lt;p&gt;A few more observations:&lt;/p&gt;
&lt;p&gt;My solution and Torgersen&amp;#39;s 4th (hybrid) solution are pretty much tied. Mine is
guaranteed to work with independent extensibility (with the proper boilerplate),
but Torgersen&amp;#39;s will also work fairly often. But for instance, it won&amp;#39;t work if
two people introduce new data classes and implement an old visitor for these
classes ‚Äî there is no easy/safe way to &amp;quot;merge&amp;quot; the two implementations. However,
it would more natural to implement the operations directly into the data class
in this case! Torgersen&amp;#39;s solution can also lead to less boilerplate in the case
where you never have to deal with independent extensibility.&lt;/p&gt;
&lt;p&gt;The covariant solution strictly dominates Torgersen&amp;#39;s 1st (data-centered)
solution.&lt;/p&gt;
      </description>
      <pubDate>2019-08-20T22:00:00.000Z</pubDate>
      <link>http://norswap.com/expression-problem-java</link>
      <guid isPermaLink="true">http://norswap.com/expression-problem-java</guid>
    </item>
    <item>
      <title>The Intuition For React</title>
      <description>
&lt;p&gt;The other day, I found &lt;a href=&quot;https://svelte.dev/blog/virtual-dom-is-pure-overhead&quot;&gt;this article&lt;/a&gt; (&amp;quot;Virtual DOM is pure overhead&amp;quot;) on
&lt;a href=&quot;https://news.ycombinator.com/item?id=19950253&quot;&gt;Hacker News&lt;/a&gt; and started reading it. Halfway through, &lt;a href=&quot;https://reactjs.org/&quot;&gt;React&lt;/a&gt; finally clicked
for me.&lt;/p&gt;
&lt;p&gt;See, I don&amp;#39;t do web programming, but I keep abreast of tech news, notably via
hacker news and web frameworks always feature heavily. If you had asked me
before what React was I could have given a generic answer (&amp;quot;something something
fronted framework something something state&amp;quot;), but I couldn&amp;#39;t have explaine why
we actually needed React, what it improved compared to using vanilla Javascript.&lt;/p&gt;
&lt;p&gt;Well, basically, the idea is that when some event occurs (e.g. the user performs
some input) the state of the page/application is going to change (probably
through the effect of an event listener). When that happens, you might have to
redraw part of the page layout.&lt;/p&gt;
&lt;p&gt;That&amp;#39;s when things can start to become hairy. If your application is complex,
there might many possible configurations for the layout, and so many ways in
which the layout could change.&lt;/p&gt;
&lt;p&gt;A common approach to these kind of problems is to model the application as a
state machine, with each state change represented as a state transition. This
approach works, but doesn&amp;#39;t scale too well to complex applications ‚Äî the state
machine gets too complex, it doesn&amp;#39;t fit into your head anymore.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;The idea behind React then is&lt;/strong&gt;: stop &lt;em&gt;changing&lt;/em&gt; the layout. Instead,
re-render the whole layout from the state each time the state changes.&lt;/p&gt;
&lt;p&gt;That way, you don&amp;#39;t have to worry about handling each possible change in each
possible application state: instead you just write component that know how to
render themselves given the state they are given.&lt;/p&gt;
&lt;p&gt;Of course, re-rendering on every change would be pretty slow, so React uses a
&amp;quot;Virtual DOM&amp;quot; (just a tree mimicking the real &lt;a href=&quot;https://www.w3.org/TR/WD-DOM/introduction.html&quot;&gt;DOM&lt;/a&gt;) and compares that to the
real DOM, only replacing parts of the layout that have actually changed.&lt;/p&gt;
&lt;p&gt;That&amp;#39;s pretty simple. I thought: well isn&amp;#39;t that explained on &lt;a href=&quot;https://reactjs.org/&quot;&gt;the official
website&lt;/a&gt;?&lt;/p&gt;
&lt;p&gt;Well actually it does a pretty good job:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Declarative&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;React makes it painless to create interactive UIs. Design simple views for
each state in your application, and React will efficiently update and render
just the right components when your data changes.&lt;/p&gt;
&lt;p&gt;Declarative views make your code more predictable and easier to debug.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Component-Based&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Build encapsulated components that manage their own state, then compose them
to make complex UIs.&lt;/p&gt;
&lt;p&gt;Since component logic is written in JavaScript instead of templates, you can
easily pass rich data through your app and keep state out of the DOM.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;But it doesn&amp;#39;t explain that the purpose of this &amp;quot;efficient re-rendering&amp;quot; is to
avoid having to keep track of the current layout yourself and change it in a
legitimate way, which quickly becomes error prone.&lt;/p&gt;
&lt;p&gt;And that&amp;#39;s it for today!&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;&lt;strong&gt;Post Scriptum&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;The topic of the &lt;a href=&quot;https://svelte.dev/blog/virtual-dom-is-pure-overhead&quot;&gt;article&lt;/a&gt; itself is pretty interesting in its
own right. So is the discussion at &lt;a href=&quot;https://news.ycombinator.com/item?id=19950253&quot;&gt;Hacker News&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;In reeeal condensed, the article says that because the optimal manual change to
the DOM is going to be faster than diffing + a sub-optimal DOM change performed
by React, the virtual DOM is pure overhead. It&amp;#39;s right, but leaves out the fact
that all that is done for managing complexity.&lt;/p&gt;
&lt;p&gt;The article is written by Rich Harris, the author of &lt;a href=&quot;https://svelte.dev/&quot;&gt;the Svelte
framework&lt;/a&gt; ‚Äî and sell Svelte&amp;#39;s ability to basically manage complexity
but at the same time generate the optimal change at build-time.&lt;/p&gt;
&lt;p&gt;The discussion makes other interesting points regarding the genesis of React.
Because the algorithm is fickle I&amp;#39;m gonna be quoting the discussion here:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;em&gt;oraphalous&lt;/em&gt;:&lt;/p&gt;
&lt;p&gt;I think this article - and many of the comments on this thread are forgetting
the context of how DOM manipulation was typically done when the virtual DOM
approach was introduced.&lt;/p&gt;
&lt;p&gt;Here&amp;#39;s the gist of how folks would often update an element. You&amp;#39;d subscribe to
events on the root element of your component. And if your component is of any
complexity at all - first thing you&amp;#39;d probably do is ask jQuery to go find any
child elements that need updating - inspecting the DOM in various ways so as
to determine the component&amp;#39;s current state.&lt;/p&gt;
&lt;p&gt;If your component needed to affect components higher up, or sibling to the
current instance - then your application is often doing a search of the DOM to
find the nodes.. and yes if you architect things well then you could avoid a
lot of these - but let&amp;#39;s face it, front end developers weren&amp;#39;t typically
renown for their application architecture skills.&lt;/p&gt;
&lt;p&gt;In short - the DOM was often used to store state. And this just isn&amp;#39;t a very
efficient approach.&lt;/p&gt;
&lt;p&gt;This is what I understood the claim that VDOMs are faster than the real DOM
meant - and the article is pretty much eliding this detail.&lt;/p&gt;
&lt;p&gt;As far as I&amp;#39;m aware React and its VDOM approach was the framework that
deserves the credit for changing the culture of how we thought about state
management on the frontend. That newer frameworks have been able to build upon
this core insight - in ways that are even more efficient than the VDOM
approach is great - but they should pay homage to that original insight and
change in perspective React made possible.&lt;/p&gt;
&lt;p&gt;I feel this article and many of the comments here so far - fail to do that -
and worse, seem to be trying to present React&amp;#39;s claim of the VDOM faster than
the DOM as some kind of toddler mistake.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;jasonkester:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;the DOM was often used to store state.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Every once in a while I&amp;#39;m reminded that I&amp;#39;m mostly disconnected from the way
&amp;quot;most&amp;quot; people build things. Thanks for this insight. It finally explains why I
hear people talking down about &amp;quot;jQuery developers&amp;quot;, if that was something that
people actually did.&lt;/p&gt;
&lt;p&gt;But wow. I&amp;#39;ve been building javascript-heavy web stuff since the mid 90&amp;#39;s and it
had never occurred to me to do that. You have your object model, and each thing
had a reference back to its DOM node and some methods to update itself if
necessary. All jQuery did was make it less typing to initially grab the DOM node
(or create it), and give you some shorthand for setting classes on them.&lt;/p&gt;
&lt;p&gt;It also explains why people liked React, which has always seemed completely
overcomplicated to me, but which probably simplified things a lot if you didn&amp;#39;t
ever have a proper place to keep your data model.&lt;/p&gt;
&lt;p&gt;I can&amp;#39;t imagine I was the only one who had things figured out back then,
though. The idea you&amp;#39;re talking about sounds pretty terrible.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;onion2k:&lt;/p&gt;
&lt;p&gt;Bare in mind that most people using jQuery weren&amp;#39;t writing JavaScript
applications. They were writing backend-driven applications with jQuery
enhancements, so there was no real concept of frontend &amp;#39;state&amp;#39; that was
separate to the DOM itself. If your frontend code needed to work with &amp;#39;state&amp;#39;
like form values or element attributes you had to read them, and because there
could be multiple separate bits of code working with the same form or element
you had to write values back to the DOM so the next bit of code had the
correct &amp;#39;state&amp;#39;.&lt;/p&gt;
&lt;p&gt;The thing that changed to make frontend development improve dramatically was
hash based routing with ajax, and later the introduction of the history API.
That caused frontend development to have a need to retain state between
&amp;#39;pages&amp;#39;, so then was a need to find a better way to store it than using DOM
attributes.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;Udik:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;the thing that changed to make frontend development improve
dramatically was hash based routing with ajax...&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;I think that what&amp;#39;s changed is simply that people realized that it&amp;#39;s way less
messy to use the backend only as a data source (with ajax calls), and leave
everything else to the frontend. The cognitive overhead of having the server
producing html with some implicit state, then updating that state interactively,
and then losing everything again by posting the whole page to the server, was
simply unbearable.&lt;/p&gt;
&lt;p&gt;When I started building web applications in 2004 I had some experience in
writing desktop apps: I simply created a js library to create and destroy UI
elements, and wrote &amp;quot;desktop&amp;quot; apps running in the browser.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Isn&amp;#39;t all that positively enlightening?&lt;/p&gt;
      </description>
      <pubDate>2019-05-31T22:00:00.000Z</pubDate>
      <link>http://norswap.com/react-intuition</link>
      <guid isPermaLink="true">http://norswap.com/react-intuition</guid>
    </item>
  </channel>
</rss>
